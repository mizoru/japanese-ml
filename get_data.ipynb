{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/backend/utils.py:47: UserWarning: \"torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE\" flag is deprecated and will be removed in 0.9.0. Please remove the use of flag.\n",
      "  '\"torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE\" flag is deprecated and will be removed in 0.9.0. '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fastai.vision.all import *\n",
    "from fastaudio.core.all import *\n",
    "from fastaudio.augment.all import *\n",
    "from fastcore.xtras import untar_dir\n",
    "# import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='dataset/pitch_accent.tar.gz' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('dataset/pitch_accent.tar.gz').open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarfile.open(Path('dataset/pitch_accent.tar.gz'), \"r:gz\").extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('data/pitch_accent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>pattern</th>\n",
       "      <th>kana</th>\n",
       "      <th>morae</th>\n",
       "      <th>drop</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dict1ある.yomi000142BB_0596.mp3</td>\n",
       "      <td>頭高</td>\n",
       "      <td>アル</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dict1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dict1思う.yomi0006C617_043A.mp3</td>\n",
       "      <td>中高</td>\n",
       "      <td>オモウ</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>dict1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dict1など.yomi000240B7_0028.mp3</td>\n",
       "      <td>頭高</td>\n",
       "      <td>ナド</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dict1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dict1私.yomi00092F63_0072.mp3</td>\n",
       "      <td>平板</td>\n",
       "      <td>ワタくシ</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>dict1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dict1見る.yomi000A41BD_001E.mp3</td>\n",
       "      <td>頭高</td>\n",
       "      <td>ミル</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dict1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84477</th>\n",
       "      <td>立て-377_10_1_female.mp3</td>\n",
       "      <td>頭高</td>\n",
       "      <td>たて</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dict2 female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84478</th>\n",
       "      <td>立てる-377_11_1_male.mp3</td>\n",
       "      <td>中高</td>\n",
       "      <td>たてる</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>dict2 male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84479</th>\n",
       "      <td>立てる-377_11_1_female.mp3</td>\n",
       "      <td>中高</td>\n",
       "      <td>たてる</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>dict2 female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84480</th>\n",
       "      <td>立とう-377_12_1_male.mp3</td>\n",
       "      <td>中高</td>\n",
       "      <td>たとう</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>dict2 male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84481</th>\n",
       "      <td>立とう-377_12_1_female.mp3</td>\n",
       "      <td>中高</td>\n",
       "      <td>たとう</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>dict2 female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163966 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                path pattern  kana  morae  drop          type\n",
       "0      dict1ある.yomi000142BB_0596.mp3      頭高    アル      2     1         dict1\n",
       "1      dict1思う.yomi0006C617_043A.mp3      中高   オモウ      3     2         dict1\n",
       "2      dict1など.yomi000240B7_0028.mp3      頭高    ナド      2     1         dict1\n",
       "3       dict1私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0         dict1\n",
       "4      dict1見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1         dict1\n",
       "...                              ...     ...   ...    ...   ...           ...\n",
       "84477         立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "84478          立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "84479        立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "84480          立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "84481        立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "\n",
       "[163966 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1 = pd.read_csv(p/'dict1_labels.csv')\n",
    "labels1.path = 'dict1' + labels1.path\n",
    "labels2 = pd.read_csv(p/'dict2_labels.csv')\n",
    "labels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\n",
    "pd.concat([labels1, labels2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRECORDSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Open a tar archive for reading, writing or appending. Return\u001b[0m\n",
      "\u001b[0;34m           an appropriate TarFile class.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m           mode:\u001b[0m\n",
      "\u001b[0;34m           'r' or 'r:*' open for reading with transparent compression\u001b[0m\n",
      "\u001b[0;34m           'r:'         open for reading exclusively uncompressed\u001b[0m\n",
      "\u001b[0;34m           'r:gz'       open for reading with gzip compression\u001b[0m\n",
      "\u001b[0;34m           'r:bz2'      open for reading with bzip2 compression\u001b[0m\n",
      "\u001b[0;34m           'r:xz'       open for reading with lzma compression\u001b[0m\n",
      "\u001b[0;34m           'a' or 'a:'  open for appending, creating the file if necessary\u001b[0m\n",
      "\u001b[0;34m           'w' or 'w:'  open for writing without compression\u001b[0m\n",
      "\u001b[0;34m           'w:gz'       open for writing with gzip compression\u001b[0m\n",
      "\u001b[0;34m           'w:bz2'      open for writing with bzip2 compression\u001b[0m\n",
      "\u001b[0;34m           'w:xz'       open for writing with lzma compression\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m           'x' or 'x:'  create a tarfile exclusively without compression, raise\u001b[0m\n",
      "\u001b[0;34m                        an exception if the file is already created\u001b[0m\n",
      "\u001b[0;34m           'x:gz'       create a gzip compressed tarfile, raise an exception\u001b[0m\n",
      "\u001b[0;34m                        if the file is already created\u001b[0m\n",
      "\u001b[0;34m           'x:bz2'      create a bzip2 compressed tarfile, raise an exception\u001b[0m\n",
      "\u001b[0;34m                        if the file is already created\u001b[0m\n",
      "\u001b[0;34m           'x:xz'       create an lzma compressed tarfile, raise an exception\u001b[0m\n",
      "\u001b[0;34m                        if the file is already created\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m           'r|*'        open a stream of tar blocks with transparent compression\u001b[0m\n",
      "\u001b[0;34m           'r|'         open an uncompressed stream of tar blocks for reading\u001b[0m\n",
      "\u001b[0;34m           'r|gz'       open a gzip compressed stream of tar blocks\u001b[0m\n",
      "\u001b[0;34m           'r|bz2'      open a bzip2 compressed stream of tar blocks\u001b[0m\n",
      "\u001b[0;34m           'r|xz'       open an lzma compressed stream of tar blocks\u001b[0m\n",
      "\u001b[0;34m           'w|'         open an uncompressed stream for writing\u001b[0m\n",
      "\u001b[0;34m           'w|gz'       open a gzip compressed stream for writing\u001b[0m\n",
      "\u001b[0;34m           'w|bz2'      open a bzip2 compressed stream for writing\u001b[0m\n",
      "\u001b[0;34m           'w|xz'       open an lzma compressed stream for writing\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nothing to open\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r:*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Find out which *open() is appropriate for opening the file.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mdef\u001b[0m \u001b[0mnot_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN_METH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomptype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'taropen'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mcomptype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN_METH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_compressed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN_METH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomptype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0msaved_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file could not be opened successfully\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfilemode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomptype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"tar\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Select the *open() function according to\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# given compression.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mcomptype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN_METH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPEN_METH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomptype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfilemode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomptype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"tar\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode must be 'r' or 'w'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaropen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"undiscernible mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/fastaudio/lib/python3.7/tarfile.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "tarfile.open??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mAudioConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msample_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_fft\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwin_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhop_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mf_min\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mf_max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8000.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_mels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwindow_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mhann_window\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f353d839ca0\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpower\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalized\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpad_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0monesided\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'True'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mto_db\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'typing.Any'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'False'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/fastaudio/lib/python3.7/types.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "AudioConfig.Voice??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewClass(object): pass\n",
    "mydict = NewClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, k = 10, 'i', 3.0\n",
    "d = dict(k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'i'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31291/868543454.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'i'"
     ]
    }
   ],
   "source": [
    "d.__setattr__(b,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_ih': ['',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "  'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "  \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"p = Path('data/pitch_accent')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "  'import fastai\\nfastai.__version__',\n",
       "  'AudioConfig.Voice',\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "  'my_dict = object()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "  'd.__setattr__(b=b)',\n",
       "  'd.__setattr__(b,b)',\n",
       "  \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "  \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "  'locals()',\n",
       "  \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       " '_oh': {8:                                         path pattern  kana  morae  drop  \\\n",
       "  0       accentAudio/ある.yomi000142BB_0596.mp3      頭高    アル      2     1   \n",
       "  1       accentAudio/思う.yomi0006C617_043A.mp3      中高   オモウ      3     2   \n",
       "  2       accentAudio/など.yomi000240B7_0028.mp3      頭高    ナド      2     1   \n",
       "  3        accentAudio/私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0   \n",
       "  4       accentAudio/見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1   \n",
       "  ...                                      ...     ...   ...    ...   ...   \n",
       "  163962      OjadMedia/立て-377_10_1_female.mp3      頭高    たて      2     1   \n",
       "  163963       OjadMedia/立てる-377_11_1_male.mp3      中高   たてる      3     2   \n",
       "  163964     OjadMedia/立てる-377_11_1_female.mp3      中高   たてる      3     2   \n",
       "  163965       OjadMedia/立とう-377_12_1_male.mp3      中高   たとう      3     2   \n",
       "  163966     OjadMedia/立とう-377_12_1_female.mp3      中高   たとう      3     2   \n",
       "  \n",
       "                 type  \n",
       "  0               nhk  \n",
       "  1               nhk  \n",
       "  2               nhk  \n",
       "  3               nhk  \n",
       "  4               nhk  \n",
       "  ...             ...  \n",
       "  163962  ojad female  \n",
       "  163963    ojad male  \n",
       "  163964  ojad female  \n",
       "  163965    ojad male  \n",
       "  163966  ojad female  \n",
       "  \n",
       "  [163967 rows x 6 columns],\n",
       "  10:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  12:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  13:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  16:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  18:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  19:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  20:                                                      path pattern      kana  \\\n",
       "  0         ある-66_1_1_male.mp3dict1ある.yomi000142BB_0596.mp3    頭高頭高      あるアル   \n",
       "  1       ある-66_1_1_female.mp3dict1思う.yomi0006C617_043A.mp3    頭高中高     あるオモウ   \n",
       "  2       あります-66_2_1_male.mp3dict1など.yomi000240B7_0028.mp3    中高頭高    ありますナド   \n",
       "  3      あります-66_2_1_female.mp3dict1私.yomi00092F63_0072.mp3    中高平板  ありますワタくシ   \n",
       "  4        あって-66_3_1_male.mp3dict1見る.yomi000A41BD_001E.mp3    頭高頭高     あってミル   \n",
       "  ...                                                   ...     ...       ...   \n",
       "  84477                                                 NaN     NaN       NaN   \n",
       "  84478                                                 NaN     NaN       NaN   \n",
       "  84479                                                 NaN     NaN       NaN   \n",
       "  84480                                                 NaN     NaN       NaN   \n",
       "  84481                                                 NaN     NaN       NaN   \n",
       "  \n",
       "         morae  drop               type  \n",
       "  0        4.0   2.0    dict2 maledict1  \n",
       "  1        5.0   3.0  dict2 femaledict1  \n",
       "  2        6.0   4.0    dict2 maledict1  \n",
       "  3        8.0   3.0  dict2 femaledict1  \n",
       "  4        5.0   2.0    dict2 maledict1  \n",
       "  ...      ...   ...                ...  \n",
       "  84477    NaN   NaN                NaN  \n",
       "  84478    NaN   NaN                NaN  \n",
       "  84479    NaN   NaN                NaN  \n",
       "  84480    NaN   NaN                NaN  \n",
       "  84481    NaN   NaN                NaN  \n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  23:                                 path pattern  kana  morae  drop          type\n",
       "  0      dict1ある.yomi000142BB_0596.mp3      頭高    アル      2     1         dict1\n",
       "  1      dict1思う.yomi0006C617_043A.mp3      中高   オモウ      3     2         dict1\n",
       "  2      dict1など.yomi000240B7_0028.mp3      頭高    ナド      2     1         dict1\n",
       "  3       dict1私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0         dict1\n",
       "  4      dict1見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1         dict1\n",
       "  ...                              ...     ...   ...    ...   ...           ...\n",
       "  84477         立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478          立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479        立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480          立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481        立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [163966 rows x 6 columns],\n",
       "  24: '2.3.1',\n",
       "  25: types.Voice,\n",
       "  37: {'k': 3.0},\n",
       "  43: {'__name__': '__main__',\n",
       "   '__doc__': 'Automatically created module for IPython interactive environment',\n",
       "   '__package__': None,\n",
       "   '__loader__': None,\n",
       "   '__spec__': None,\n",
       "   '__builtin__': <module 'builtins' (built-in)>,\n",
       "   '__builtins__': <module 'builtins' (built-in)>,\n",
       "   '_ih': ['',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "    'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "    \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"p = Path('data/pitch_accent')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "    'import fastai\\nfastai.__version__',\n",
       "    'AudioConfig.Voice',\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "    'my_dict = object()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "    'd.__setattr__(b=b)',\n",
       "    'd.__setattr__(b,b)',\n",
       "    \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "    \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "    'locals()',\n",
       "    \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       "   '_oh': {...},\n",
       "   '_dh': ['/home/mizoru/ML/japanese-ml'],\n",
       "   'In': ['',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "    'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "    \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"p = Path('data/pitch_accent')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "    'import fastai\\nfastai.__version__',\n",
       "    'AudioConfig.Voice',\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "    'my_dict = object()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "    'd.__setattr__(b=b)',\n",
       "    'd.__setattr__(b,b)',\n",
       "    \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "    \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "    'locals()',\n",
       "    \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       "   'Out': {...},\n",
       "   'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f354f4bc590>>,\n",
       "   'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       "   'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       "   '_': {...},\n",
       "   '__': {'k': 3.0},\n",
       "   '___': types.Voice,\n",
       "   'os': <module 'os' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/os.py'>,\n",
       "   'sys': <module 'sys' (built-in)>,\n",
       "   '__vsc_ipynb_file__': '/home/mizoru/ML/japanese-ml/get_data.ipynb',\n",
       "   '_i': 'locals()',\n",
       "   '_ii': \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "   '_iii': \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "   '_i1': \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "   '_i2': 'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "   'models': <module 'fastai.vision.models' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/fastai/vision/models/__init__.py'>,\n",
       "   'multiprocessing': <module 'multiprocessing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/__init__.py'>,\n",
       "   'platform': <module 'platform' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/platform.py'>,\n",
       "   'np': <module 'numpy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/numpy/__init__.py'>,\n",
       "   'io': <module 'io' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/io.py'>,\n",
       "   'operator': <module 'operator' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/operator.py'>,\n",
       "   're': <module 're' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/re.py'>,\n",
       "   'mimetypes': <module 'mimetypes' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/mimetypes.py'>,\n",
       "   'csv': <module 'csv' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/csv.py'>,\n",
       "   'itertools': <module 'itertools' (built-in)>,\n",
       "   'json': <module 'json' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/json/__init__.py'>,\n",
       "   'shutil': <module 'shutil' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/shutil.py'>,\n",
       "   'glob': <module 'glob' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/glob.py'>,\n",
       "   'pickle': <module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>,\n",
       "   'tarfile': <module 'tarfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tarfile.py'>,\n",
       "   'collections': <module 'collections' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/collections/__init__.py'>,\n",
       "   'hashlib': <module 'hashlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/hashlib.py'>,\n",
       "   'types': <module 'types' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/types.py'>,\n",
       "   'inspect': <module 'inspect' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/inspect.py'>,\n",
       "   'functools': <module 'functools' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/functools.py'>,\n",
       "   'random': <module 'random' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/random.py'>,\n",
       "   'time': <module 'time' (built-in)>,\n",
       "   'math': <module 'math' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so'>,\n",
       "   'bz2': <module 'bz2' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/bz2.py'>,\n",
       "   'typing': <module 'typing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/typing.py'>,\n",
       "   'numbers': <module 'numbers' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/numbers.py'>,\n",
       "   'string': <module 'string' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/string.py'>,\n",
       "   'threading': <module 'threading' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/threading.py'>,\n",
       "   'urllib': <module 'urllib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/urllib/__init__.py'>,\n",
       "   'tempfile': <module 'tempfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tempfile.py'>,\n",
       "   'concurrent': <module 'concurrent' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/concurrent/__init__.py'>,\n",
       "   'matplotlib': <module 'matplotlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/__init__.py'>,\n",
       "   'warnings': <module 'warnings' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/warnings.py'>,\n",
       "   'zipfile': <module 'zipfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/zipfile.py'>,\n",
       "   'as_completed': <function concurrent.futures._base.as_completed(fs, timeout=None)>,\n",
       "   'partial': functools.partial,\n",
       "   'reduce': <function _functools.reduce>,\n",
       "   'starmap': itertools.starmap,\n",
       "   'dropwhile': itertools.dropwhile,\n",
       "   'takewhile': itertools.takewhile,\n",
       "   'zip_longest': itertools.zip_longest,\n",
       "   'copy': <function copy.copy(x)>,\n",
       "   'deepcopy': <function copy.deepcopy(x, memo=None, _nil=[])>,\n",
       "   'Lock': <bound method BaseContext.Lock of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       "   'Process': multiprocessing.context.Process,\n",
       "   'Queue': <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       "   'queues': <module 'multiprocessing.queues' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/queues.py'>,\n",
       "   'datetime': datetime.datetime,\n",
       "   'redirect_stdout': contextlib.redirect_stdout,\n",
       "   'contextmanager': <function contextlib.contextmanager(func)>,\n",
       "   'Iterable': typing.Iterable,\n",
       "   'Iterator': typing.Iterator,\n",
       "   'Generator': typing.Generator,\n",
       "   'Sequence': typing.Sequence,\n",
       "   'Union': typing.Union,\n",
       "   'Optional': typing.Optional,\n",
       "   'SimpleNamespace': types.SimpleNamespace,\n",
       "   'Path': pathlib.Path,\n",
       "   'OrderedDict': collections.OrderedDict,\n",
       "   'defaultdict': collections.defaultdict,\n",
       "   'Counter': collections.Counter,\n",
       "   'namedtuple': <function collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)>,\n",
       "   'Enum': <enum 'Enum'>,\n",
       "   'IntEnum': <enum 'IntEnum'>,\n",
       "   'TextWrapper': textwrap.TextWrapper,\n",
       "   'itemgetter': operator.itemgetter,\n",
       "   'attrgetter': operator.attrgetter,\n",
       "   'methodcaller': operator.methodcaller,\n",
       "   'urlopen': <function fastcore.net.urlopen(url, data=None, headers=None, **kwargs)>,\n",
       "   'requests': <module 'requests' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/requests/__init__.py'>,\n",
       "   'yaml': <module 'yaml' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/yaml/__init__.py'>,\n",
       "   'plt': <module 'matplotlib.pyplot' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/pyplot.py'>,\n",
       "   'pd': <module 'pandas' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/pandas/__init__.py'>,\n",
       "   'scipy': <module 'scipy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/__init__.py'>,\n",
       "   'is_categorical_dtype': <function pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype) -> 'bool'>,\n",
       "   'is_numeric_dtype': <function pandas.core.dtypes.common.is_numeric_dtype(arr_or_dtype) -> 'bool'>,\n",
       "   'array': <function numpy.array>,\n",
       "   'ndarray': numpy.ndarray,\n",
       "   'ndimage': <module 'scipy.ndimage' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/ndimage/__init__.py'>,\n",
       "   'set_trace': <function IPython.core.debugger.set_trace(frame=None)>,\n",
       "   'enum': <module 'enum' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/enum.py'>,\n",
       "   'warn': <function _warnings.warn(message, category=None, stacklevel=1, source=None)>,\n",
       "   'WrapperDescriptorType': wrapper_descriptor,\n",
       "   'MethodWrapperType': method-wrapper,\n",
       "   'MethodDescriptorType': method_descriptor,\n",
       "   'BuiltinFunctionType': builtin_function_or_method,\n",
       "   'BuiltinMethodType': builtin_function_or_method,\n",
       "   'MethodType': method,\n",
       "   'FunctionType': function,\n",
       "   'NoneType': NoneType,\n",
       "   'string_classes': (str, bytes),\n",
       "   'is_iter': <function fastai.imports.is_iter(o)>,\n",
       "   'is_coll': <function fastai.imports.is_coll(o)>,\n",
       "   'all_equal': <function fastai.imports.all_equal(a, b)>,\n",
       "   'noop': <function fastai.imports.noop(x=None, *args, **kwargs)>,\n",
       "   'noops': <function fastai.imports.noops(self, x=None, *args, **kwargs)>,\n",
       "   'any_is_instance': <function fastcore.imports.any_is_instance(t, *args)>,\n",
       "   'isinstance_str': <function fastcore.imports.isinstance_str(x, cls_name)>,\n",
       "   'array_equal': <function fastcore.imports.array_equal(a, b)>,\n",
       "   'df_equal': <function fastcore.imports.df_equal(a, b)>,\n",
       "   'equals': <function fastai.imports.equals(a, b)>,\n",
       "   'ipython_shell': <function fastcore.imports.ipython_shell()>,\n",
       "   'in_ipython': <function fastcore.imports.in_ipython()>,\n",
       "   'in_colab': <function fastcore.imports.in_colab()>,\n",
       "   'in_jupyter': <function fastcore.imports.in_jupyter()>,\n",
       "   'in_notebook': <function fastcore.imports.in_notebook()>,\n",
       "   'IN_IPYTHON': True,\n",
       "   'IN_JUPYTER': True,\n",
       "   'IN_COLAB': False,\n",
       "   'IN_NOTEBOOK': True,\n",
       "   'remove_prefix': <function fastcore.imports.remove_prefix(text, prefix)>,\n",
       "   'remove_suffix': <function fastcore.imports.remove_suffix(text, suffix)>,\n",
       "   'working_directory': <function fastcore.foundation.working_directory(path)>,\n",
       "   'add_docs': <function fastcore.foundation.add_docs(cls, cls_doc=None, **docs)>,\n",
       "   'docs': <function fastcore.foundation.docs(cls)>,\n",
       "   'coll_repr': <function fastcore.foundation.coll_repr(c, max_n=10)>,\n",
       "   'is_bool': <function fastcore.foundation.is_bool(x)>,\n",
       "   'mask2idxs': <function fastcore.foundation.mask2idxs(mask)>,\n",
       "   'cycle': <function fastcore.basics.cycle(o)>,\n",
       "   'zip_cycle': <function fastcore.basics.zip_cycle(x, *args)>,\n",
       "   'is_indexer': <function fastcore.foundation.is_indexer(idx)>,\n",
       "   'CollBase': fastcore.foundation.CollBase,\n",
       "   'L': fastcore.foundation.L,\n",
       "   'save_config_file': <function fastcore.foundation.save_config_file(file, d, **kwargs)>,\n",
       "   'read_config_file': <function fastcore.foundation.read_config_file(file, **kwargs)>,\n",
       "   'Config': fastai.data.external.Config,\n",
       "   'lenient_issubclass': <function fastcore.dispatch.lenient_issubclass(cls, types)>,\n",
       "   'sorted_topologically': <function fastcore.dispatch.sorted_topologically(iterable, *, cmp=<built-in function lt>, reverse=False)>,\n",
       "   'TypeDispatch': fastcore.dispatch.TypeDispatch,\n",
       "   'DispatchReg': fastcore.dispatch.DispatchReg,\n",
       "   'typedispatch': <fastcore.dispatch.DispatchReg at 0x7f34c6df11d0>,\n",
       "   'cast': (object,object) -> cast,\n",
       "   'retain_meta': <function fastcore.dispatch.retain_meta(x, res, as_copy=False)>,\n",
       "   'default_set_meta': <function fastcore.dispatch.default_set_meta(self, x, as_copy=False)>,\n",
       "   'retain_type': <function fastcore.dispatch.retain_type(new, old=None, typ=None, as_copy=False)>,\n",
       "   'retain_types': <function fastcore.dispatch.retain_types(new, old=None, typs=None)>,\n",
       "   'explode_types': <function fastcore.dispatch.explode_types(o)>,\n",
       "   'test_fail': <function fastcore.test.test_fail(f, msg='', contains='', args=None, kwargs=None)>,\n",
       "   'test': <function fastcore.test.test(a, b, cmp, cname=None)>,\n",
       "   'nequals': <function fastcore.test.nequals(a, b)>,\n",
       "   'test_eq': <function fastcore.test.test_eq(a, b)>,\n",
       "   'test_eq_type': <function fastcore.test.test_eq_type(a, b)>,\n",
       "   'test_ne': <function fastcore.test.test_ne(a, b)>,\n",
       "   'is_close': <function fastcore.test.is_close(a, b, eps=1e-05)>,\n",
       "   'test_close': <function fastcore.test.test_close(a, b, eps=1e-05)>,\n",
       "   'test_is': <function fastcore.test.test_is(a, b)>,\n",
       "   'test_shuffled': <function fastcore.test.test_shuffled(a, b)>,\n",
       "   'test_stdout': <function fastcore.test.test_stdout(f, exp, regex=False)>,\n",
       "   'test_warns': <function fastcore.test.test_warns(f, show=False)>,\n",
       "   'TEST_IMAGE': 'images/puppy.jpg',\n",
       "   'TEST_IMAGE_BW': 'images/mnist3.png',\n",
       "   'test_fig_exists': <function fastcore.test.test_fig_exists(ax)>,\n",
       "   'ExceptionExpected': fastcore.test.ExceptionExpected,\n",
       "   'exception': <fastcore.test.ExceptionExpected at 0x7f34c0dcc550>,\n",
       "   'defaults': namespace(cpus=4,\n",
       "             use_cuda=None,\n",
       "             activation=torch.nn.modules.activation.ReLU,\n",
       "             callbacks=[fastai.callback.core.TrainEvalCallback,\n",
       "                        fastai.learner.Recorder,\n",
       "                        fastai.callback.progress.ProgressCallback],\n",
       "             lr=0.001),\n",
       "   'ifnone': <function fastcore.basics.ifnone(a, b)>,\n",
       "   'maybe_attr': <function fastcore.basics.maybe_attr(o, attr)>,\n",
       "   'basic_repr': <function fastcore.basics.basic_repr(flds=None)>,\n",
       "   'is_array': <function fastcore.basics.is_array(x)>,\n",
       "   'listify': <function fastcore.basics.listify(o=None, *rest, use_list=False, match=None)>,\n",
       "   'tuplify': <function fastcore.basics.tuplify(o, use_list=False, match=None)>,\n",
       "   'true': <function fastcore.basics.true(*args, **kwargs)>,\n",
       "   'NullType': fastcore.basics.NullType,\n",
       "   'null': <fastcore.basics.NullType at 0x7f34c0e2dbd0>,\n",
       "   'tonull': <function fastcore.basics.tonull(x)>,\n",
       "   'get_class': <function fastcore.basics.get_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       "   'mk_class': <function fastcore.basics.mk_class(nm, *fld_names, sup=None, doc=None, funcs=None, mod=None, **flds)>,\n",
       "   'wrap_class': <function fastcore.basics.wrap_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       "   'ignore_exceptions': fastcore.basics.ignore_exceptions,\n",
       "   'exec_local': <function fastcore.basics.exec_local(code, var_name)>,\n",
       "   'risinstance': <function fastcore.basics.risinstance(types, obj=None)>,\n",
       "   'Inf': fastcore.basics.Inf,\n",
       "   'in_': <function fastcore.basics.in_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'lt': <function fastcore.basics.lt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'gt': <function fastcore.basics.gt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'le': <function fastcore.basics.le(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'ge': <function fastcore.basics.ge(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'eq': <function fastcore.basics.eq(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'ne': <function fastcore.basics.ne(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'add': <function fastcore.basics.add(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'sub': <function fastcore.basics.sub(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'mul': <function fastcore.basics.mul(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'truediv': <function fastcore.basics.truediv(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'is_': <function fastcore.basics.is_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'is_not': <function fastcore.basics.is_not(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'stop': <function fastcore.basics.stop(e=<class 'StopIteration'>)>,\n",
       "   'gen': <function fastcore.basics.gen(func, seq, cond=<function true at 0x7f34c0e30e60>)>,\n",
       "   'chunked': <function fastcore.basics.chunked(it, chunk_sz=None, drop_last=False, n_chunks=None)>,\n",
       "   'otherwise': <function fastcore.basics.otherwise(x, tst, y)>,\n",
       "   'custom_dir': <function fastcore.basics.custom_dir(c, add)>,\n",
       "   'AttrDict': fastcore.basics.AttrDict,\n",
       "   'type_hints': <function fastcore.basics.type_hints(f)>,\n",
       "   'annotations': <function fastcore.basics.annotations(o)>,\n",
       "   'anno_ret': <function fastcore.basics.anno_ret(func)>,\n",
       "   'argnames': <function fastcore.basics.argnames(f, frame=False)>,\n",
       "   'with_cast': <function fastcore.basics.with_cast(f)>,\n",
       "   'store_attr': <function fastcore.basics.store_attr(names=None, self=None, but='', cast=False, store_args=None, **attrs)>,\n",
       "   'attrdict': <function fastcore.basics.attrdict(o, *ks, default=None)>,\n",
       "   'properties': <function fastcore.basics.properties(cls, *ps)>,\n",
       "   'camel2words': <function fastcore.basics.camel2words(s, space=' ')>,\n",
       "   'camel2snake': <function fastcore.basics.camel2snake(name)>,\n",
       "   'snake2camel': <function fastcore.basics.snake2camel(s)>,\n",
       "   'class2attr': <function fastcore.basics.class2attr(self, cls_name)>,\n",
       "   'getattrs': <function fastcore.basics.getattrs(o, *attrs, default=None)>,\n",
       "   'hasattrs': <function fastcore.basics.hasattrs(o, attrs)>,\n",
       "   'setattrs': <function fastcore.basics.setattrs(dest, flds, src)>,\n",
       "   'try_attrs': <function fastcore.basics.try_attrs(obj, *attrs)>,\n",
       "   'GetAttrBase': fastcore.basics.GetAttrBase,\n",
       "   'GetAttr': fastcore.basics.GetAttr,\n",
       "   'delegate_attr': <function fastcore.basics.delegate_attr(self, k, to)>,\n",
       "   'ShowPrint': fastcore.basics.ShowPrint,\n",
       "   'Int': fastcore.basics.Int,\n",
       "   'Str': fastcore.basics.Str,\n",
       "   'Float': fastcore.basics.Float,\n",
       "   'concat': <function fastai.torch_core.concat(*ls)>,\n",
       "   'strcat': <function fastcore.basics.strcat(its, sep: str = '') -> str>,\n",
       "   'detuplify': <function fastcore.basics.detuplify(x)>,\n",
       "   'replicate': <function fastcore.basics.replicate(item, match)>,\n",
       "   'setify': <function fastcore.basics.setify(o)>,\n",
       "   'merge': <function fastcore.basics.merge(*ds)>,\n",
       "   'range_of': <function fastcore.basics.range_of(a, b=None, step=None)>,\n",
       "   'groupby': <function fastcore.basics.groupby(x, key, val=<function noop at 0x7f34c0dfed40>)>,\n",
       "   'last_index': <function fastcore.basics.last_index(x, o)>,\n",
       "   'filter_dict': <function fastcore.basics.filter_dict(d, func)>,\n",
       "   'filter_keys': <function fastcore.basics.filter_keys(d, func)>,\n",
       "   'filter_values': <function fastcore.basics.filter_values(d, func)>,\n",
       "   'sorted_ex': <function fastcore.basics.sorted_ex(iterable, key=None, reverse=False)>,\n",
       "   'not_': <function fastcore.basics.not_(f)>,\n",
       "   'argwhere': <function fastcore.basics.argwhere(iterable, f, negate=False, **kwargs)>,\n",
       "   'filter_ex': <function fastcore.basics.filter_ex(iterable, f=<function noop at 0x7f34c0dfed40>, negate=False, gen=False, **kwargs)>,\n",
       "   'renumerate': <function fastcore.basics.renumerate(iterable, start=0)>,\n",
       "   'first': <function fastcore.basics.first(x, f=None, negate=False, **kwargs)>,\n",
       "   'nested_attr': <function fastcore.basics.nested_attr(o, attr, default=None)>,\n",
       "   'nested_idx': <function fastcore.basics.nested_idx(coll, *idxs)>,\n",
       "   'val2idx': <function fastcore.basics.val2idx(x)>,\n",
       "   'uniqueify': <function fastcore.basics.uniqueify(x, sort=False, bidir=False, start=None)>,\n",
       "   'num_methods': ['__add__',\n",
       "    '__sub__',\n",
       "    '__mul__',\n",
       "    '__matmul__',\n",
       "    '__truediv__',\n",
       "    '__floordiv__',\n",
       "    '__mod__',\n",
       "    '__divmod__',\n",
       "    '__pow__',\n",
       "    '__lshift__',\n",
       "    '__rshift__',\n",
       "    '__and__',\n",
       "    '__xor__',\n",
       "    '__or__',\n",
       "    '__neg__',\n",
       "    '__pos__',\n",
       "    '__abs__'],\n",
       "   'rnum_methods': ['__radd__',\n",
       "    '__rsub__',\n",
       "    '__rmul__',\n",
       "    '__rmatmul__',\n",
       "    '__rtruediv__',\n",
       "    '__rfloordiv__',\n",
       "    '__rmod__',\n",
       "    '__rdivmod__',\n",
       "    '__rpow__',\n",
       "    '__rlshift__',\n",
       "    '__rrshift__',\n",
       "    '__rand__',\n",
       "    '__rxor__',\n",
       "    '__ror__'],\n",
       "   'inum_methods': ['__iadd__',\n",
       "    '__isub__',\n",
       "    '__imul__',\n",
       "    '__imatmul__',\n",
       "    '__itruediv__',\n",
       "    '__ifloordiv__',\n",
       "    '__imod__',\n",
       "    '__ipow__',\n",
       "    '__ilshift__',\n",
       "    '__irshift__',\n",
       "    '__iand__',\n",
       "    '__ixor__',\n",
       "    '__ior__'],\n",
       "   'fastuple': fastcore.basics.fastuple,\n",
       "   'arg0': <fastcore.basics._Arg at 0x7f34c0dbc410>,\n",
       "   'arg1': <fastcore.basics._Arg at 0x7f34c0dbc450>,\n",
       "   'arg2': <fastcore.basics._Arg at 0x7f34c0dbc490>,\n",
       "   'arg3': <fastcore.basics._Arg at 0x7f34c0dbc4d0>,\n",
       "   'arg4': <fastcore.basics._Arg at 0x7f34c0dbc510>,\n",
       "   'bind': fastcore.basics.bind,\n",
       "   'mapt': <function fastcore.basics.mapt(func, *iterables)>,\n",
       "   'map_ex': <function fastcore.basics.map_ex(iterable, f, *args, gen=False, **kwargs)>,\n",
       "   'compose': <function fastcore.basics.compose(*funcs, order=None)>,\n",
       "   'maps': <function fastcore.basics.maps(*args, retain=<function noop at 0x7f34c0dfed40>)>,\n",
       "   'partialler': <function fastcore.basics.partialler(f, *args, order=None, **kwargs)>,\n",
       "   'instantiate': <function fastcore.basics.instantiate(t)>,\n",
       "   'using_attr': <function fastcore.basics.using_attr(f, attr)>,\n",
       "   'Self': <fastcore.basics._SelfCls at 0x7f34c0dbc5d0>,\n",
       "   'copy_func': <function fastcore.basics.copy_func(f)>,\n",
       "   'patch_to': <function fastcore.basics.patch_to(cls, as_prop=False, cls_method=False)>,\n",
       "   'patch': <function fastcore.basics.patch(f=None, *, as_prop=False, cls_method=False)>,\n",
       "   'patch_property': <function fastcore.basics.patch_property(f)>,\n",
       "   'ImportEnum': <enum 'ImportEnum'>,\n",
       "   'StrEnum': <enum 'StrEnum'>,\n",
       "   'str_enum': <function fastcore.basics.str_enum(name, *vals)>,\n",
       "   'Stateful': fastcore.basics.Stateful,\n",
       "   'PrettyString': fastcore.basics.PrettyString,\n",
       "   'even_mults': <function fastcore.basics.even_mults(start, stop, n)>,\n",
       "   'num_cpus': <function fastcore.basics.num_cpus()>,\n",
       "   'add_props': <function fastcore.basics.add_props(f, g=None, n=2)>,\n",
       "   'typed': <function fastcore.basics.typed(f)>,\n",
       "   'dict2obj': <function fastcore.xtras.dict2obj(d)>,\n",
       "   'obj2dict': <function fastcore.xtras.obj2dict(d)>,\n",
       "   'repr_dict': <function fastcore.xtras.repr_dict(d)>,\n",
       "   'is_listy': <function fastcore.xtras.is_listy(x)>,\n",
       "   'shufflish': <function fastcore.xtras.shufflish(x, pct=0.04)>,\n",
       "   'mapped': <function fastcore.xtras.mapped(f, it)>,\n",
       "   'IterLen': fastcore.xtras.IterLen,\n",
       "   'ReindexCollection': fastcore.xtras.ReindexCollection,\n",
       "   'maybe_open': <function fastcore.xtras.maybe_open(f, mode='r', **kwargs)>,\n",
       "   'image_size': <function fastcore.xtras.image_size(fn)>,\n",
       "   'bunzip': <function fastcore.xtras.bunzip(fn)>,\n",
       "   'join_path_file': <function fastcore.xtras.join_path_file(file, path, ext='')>,\n",
       "   'loads': <function fastcore.xtras.loads(s, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)>,\n",
       "   'loads_multi': <function fastcore.xtras.loads_multi(s: str)>,\n",
       "   'untar_dir': <function fastcore.xtras.untar_dir(file, dest)>,\n",
       "   'repo_details': <function fastcore.xtras.repo_details(url)>,\n",
       "   'run': <function fastcore.xtras.run(cmd, *rest, same_in_win=False, ignore_ex=False, as_bytes=False, stderr=False)>,\n",
       "   'open_file': <function fastcore.xtras.open_file(fn, mode='r', **kwargs)>,\n",
       "   'save_pickle': <function fastcore.xtras.save_pickle(fn, o)>,\n",
       "   'load_pickle': <function fastcore.xtras.load_pickle(fn)>,\n",
       "   'truncstr': <function fastcore.xtras.truncstr(s: str, maxlen: int, suf: str = '…', space='') -> str>,\n",
       "   'spark_chars': '▁▂▃▅▆▇',\n",
       "   'sparkline': <function fastcore.xtras.sparkline(data, mn=None, mx=None, empty_zero=False)>,\n",
       "   'autostart': <function fastcore.xtras.autostart(g)>,\n",
       "   'EventTimer': fastcore.xtras.EventTimer,\n",
       "   'stringfmt_names': <function fastcore.xtras.stringfmt_names(s: str) -> list>,\n",
       "   'PartialFormatter': fastcore.xtras.PartialFormatter,\n",
       "   'partial_format': <function fastcore.xtras.partial_format(s: str, **kwargs)>,\n",
       "   'utc2local': <function fastcore.xtras.utc2local(dt: datetime.datetime) -> datetime.datetime>,\n",
       "   'local2utc': <function fastcore.xtras.local2utc(dt: datetime.datetime) -> datetime.datetime>,\n",
       "   'trace': <function fastcore.xtras.trace(f)>,\n",
       "   'round_multiple': <function fastcore.xtras.round_multiple(x, mult, round_down=False)>,\n",
       "   'modified_env': <function fastcore.xtras.modified_env(*delete, **replace)>,\n",
       "   'ContextManagers': fastcore.xtras.ContextManagers,\n",
       "   'str2bool': <function fastcore.xtras.str2bool(s)>,\n",
       "   'sort_by_run': <function fastcore.xtras.sort_by_run(fs)>,\n",
       "   'threaded': <function fastcore.parallel.threaded(f)>,\n",
       "   'startthread': <function fastcore.parallel.startthread(f)>,\n",
       "   'set_num_threads': <function fastcore.parallel.set_num_threads(nt)>,\n",
       "   'parallelable': <function fastcore.parallel.parallelable(param_name, num_workers, f=None)>,\n",
       "   'ThreadPoolExecutor': fastcore.parallel.ThreadPoolExecutor,\n",
       "   'ProcessPoolExecutor': fastcore.parallel.ProcessPoolExecutor,\n",
       "   'parallel': <function fastcore.parallel.parallel(f, items, *args, n_workers=4, total=None, progress=None, pause=0, threadpool=False, timeout=None, chunksize=1, **kwargs)>,\n",
       "   'add_one': <function fastcore.parallel.add_one(x, a=1)>,\n",
       "   'run_procs': <function fastcore.parallel.run_procs(f, f_done, args)>,\n",
       "   'parallel_gen': <function fastcore.parallel.parallel_gen(cls, items, n_workers=4, **kwargs)>,\n",
       "   'url_default_headers': {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
       "    'Accept-Language': 'en-US,en;q=0.9',\n",
       "    'Cache-Control': 'max-age=0',\n",
       "    'Sec-Fetch-Dest': 'document',\n",
       "    'Sec-Fetch-Mode': 'navigate',\n",
       "    'Sec-Fetch-Site': 'none',\n",
       "    'Sec-Fetch-User': '?1',\n",
       "    'Upgrade-Insecure-Requests': '1',\n",
       "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'},\n",
       "   'urlquote': <function fastcore.net.urlquote(url)>,\n",
       "   'urlwrap': <function fastcore.net.urlwrap(url, data=None, headers=None)>,\n",
       "   'ExceptionsHTTP': {400: fastcore.basics.HTTP400BadRequestError,\n",
       "    401: fastcore.basics.HTTP401UnauthorizedError,\n",
       "    402: fastcore.basics.HTTP402PaymentRequiredError,\n",
       "    403: fastcore.basics.HTTP403ForbiddenError,\n",
       "    404: fastcore.basics.HTTP404NotFoundError,\n",
       "    405: fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "    406: fastcore.basics.HTTP406NotAcceptableError,\n",
       "    407: fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "    408: fastcore.basics.HTTP408RequestTimeoutError,\n",
       "    409: fastcore.basics.HTTP409ConflictError,\n",
       "    410: fastcore.basics.HTTP410GoneError,\n",
       "    411: fastcore.basics.HTTP411LengthRequiredError,\n",
       "    412: fastcore.basics.HTTP412PreconditionFailedError,\n",
       "    413: fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "    414: fastcore.basics.HTTP414URITooLongError,\n",
       "    415: fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "    416: fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "    417: fastcore.basics.HTTP417ExpectationFailedError,\n",
       "    418: fastcore.basics.HTTP418AmAteapotError,\n",
       "    421: fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "    422: fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "    423: fastcore.basics.HTTP423LockedError,\n",
       "    424: fastcore.basics.HTTP424FailedDependencyError,\n",
       "    425: fastcore.basics.HTTP425TooEarlyError,\n",
       "    426: fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "    428: fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "    429: fastcore.basics.HTTP429TooManyRequestsError,\n",
       "    431: fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "    451: fastcore.basics.HTTP451LegalReasonsError},\n",
       "   'HTTP4xxClientError': fastcore.net.HTTP4xxClientError,\n",
       "   'HTTP5xxServerError': fastcore.net.HTTP5xxServerError,\n",
       "   'HTTP400BadRequestError': fastcore.basics.HTTP400BadRequestError,\n",
       "   'HTTP401UnauthorizedError': fastcore.basics.HTTP401UnauthorizedError,\n",
       "   'HTTP402PaymentRequiredError': fastcore.basics.HTTP402PaymentRequiredError,\n",
       "   'HTTP403ForbiddenError': fastcore.basics.HTTP403ForbiddenError,\n",
       "   'HTTP404NotFoundError': fastcore.basics.HTTP404NotFoundError,\n",
       "   'HTTP405MethodNotAllowedError': fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "   'HTTP406NotAcceptableError': fastcore.basics.HTTP406NotAcceptableError,\n",
       "   'HTTP407ProxyAuthRequiredError': fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "   'HTTP408RequestTimeoutError': fastcore.basics.HTTP408RequestTimeoutError,\n",
       "   'HTTP409ConflictError': fastcore.basics.HTTP409ConflictError,\n",
       "   'HTTP410GoneError': fastcore.basics.HTTP410GoneError,\n",
       "   'HTTP411LengthRequiredError': fastcore.basics.HTTP411LengthRequiredError,\n",
       "   'HTTP412PreconditionFailedError': fastcore.basics.HTTP412PreconditionFailedError,\n",
       "   'HTTP413PayloadTooLargeError': fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "   'HTTP414URITooLongError': fastcore.basics.HTTP414URITooLongError,\n",
       "   'HTTP415UnsupportedMediaTypeError': fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "   'HTTP416RangeNotSatisfiableError': fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "   'HTTP417ExpectationFailedError': fastcore.basics.HTTP417ExpectationFailedError,\n",
       "   'HTTP418AmAteapotError': fastcore.basics.HTTP418AmAteapotError,\n",
       "   'HTTP421MisdirectedRequestError': fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "   'HTTP422UnprocessableEntityError': fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "   'HTTP423LockedError': fastcore.basics.HTTP423LockedError,\n",
       "   'HTTP424FailedDependencyError': fastcore.basics.HTTP424FailedDependencyError,\n",
       "   'HTTP425TooEarlyError': fastcore.basics.HTTP425TooEarlyError,\n",
       "   'HTTP426UpgradeRequiredError': fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "   'HTTP428PreconditionRequiredError': fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "   'HTTP429TooManyRequestsError': fastcore.basics.HTTP429TooManyRequestsError,\n",
       "   'HTTP431HeaderFieldsTooLargeError': fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "   'HTTP451LegalReasonsError': fastcore.basics.HTTP451LegalReasonsError,\n",
       "   'urlread': <function fastcore.net.urlread(url, data=None, headers=None, decode=True, return_json=False, return_headers=False, **kwargs)>,\n",
       "   'urljson': <function fastcore.net.urljson(url, data=None)>,\n",
       "   'urlcheck': <function fastcore.net.urlcheck(url, timeout=10)>,\n",
       "   'urlclean': <function fastcore.net.urlclean(url)>,\n",
       "   'urlsave': <function fastcore.net.urlsave(url, dest=None)>,\n",
       "   'urlvalid': <function fastcore.net.urlvalid(x)>,\n",
       "   'urlrequest': <function fastcore.net.urlrequest(url, verb, headers=None, route=None, query=None, data=None, json_data=True)>,\n",
       "   'urlsend': <function fastcore.net.urlsend(url, verb, headers=None, route=None, query=None, data=None, json_data=True, return_json=True, return_headers=False, debug=None)>,\n",
       "   'do_request': <function fastcore.net.do_request(url, post=False, headers=None, **data)>,\n",
       "   'start_server': <function fastcore.net.start_server(port, host=None, dgram=False, reuse_addr=True, n_queue=None)>,\n",
       "   'start_client': <function fastcore.net.start_client(port, host=None, dgram=False)>,\n",
       "   'Transform': fastcore.transform.Transform,\n",
       "   'InplaceTransform': fastcore.transform.InplaceTransform,\n",
       "   'DisplayedTransform': fastcore.transform.DisplayedTransform,\n",
       "   'ItemTransform': fastcore.transform.ItemTransform,\n",
       "   'get_func': <function fastcore.transform.get_func(t, name, *args, **kwargs)>,\n",
       "   'Func': fastcore.transform.Func,\n",
       "   'Sig': <fastcore.transform._Sig at 0x7f34c0d37590>,\n",
       "   'compose_tfms': <function fastcore.transform.compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs)>,\n",
       "   'mk_transform': <function fastcore.transform.mk_transform(f)>,\n",
       "   'gather_attrs': <function fastcore.transform.gather_attrs(o, k, nm)>,\n",
       "   'gather_attr_names': <function fastcore.transform.gather_attr_names(o, nm)>,\n",
       "   'Pipeline': fastcore.transform.Pipeline,\n",
       "   'test_sig': <function fastcore.meta.test_sig(f, b)>,\n",
       "   'FixSigMeta': fastcore.meta.FixSigMeta,\n",
       "   'PrePostInitMeta': fastcore.meta.PrePostInitMeta,\n",
       "   'AutoInit': fastcore.meta.AutoInit,\n",
       "   'NewChkMeta': fastcore.meta.NewChkMeta,\n",
       "   'BypassNewMeta': fastcore.meta.BypassNewMeta,\n",
       "   'empty2none': <function fastcore.meta.empty2none(p)>,\n",
       "   'anno_dict': <function fastcore.meta.anno_dict(f)>,\n",
       "   'use_kwargs_dict': <function fastcore.meta.use_kwargs_dict(keep=False, **kwargs)>,\n",
       "   'use_kwargs': <function fastcore.meta.use_kwargs(names, keep=False)>,\n",
       "   'delegates': <function fastcore.meta.delegates(to=None, keep=False, but=None)>,\n",
       "   'method': <function fastcore.meta.method(f)>,\n",
       "   'funcs_kwargs': <function fastcore.meta.funcs_kwargs(as_method=False)>,\n",
       "   'store_true': <function fastcore.script.store_true()>,\n",
       "   'store_false': <function fastcore.script.store_false()>,\n",
       "   'bool_arg': <function fastcore.script.bool_arg(v)>,\n",
       "   'clean_type_str': <function fastcore.script.clean_type_str(x: str)>,\n",
       "   'Param': fastcore.script.Param,\n",
       "   'anno_parser': <function fastcore.script.anno_parser(func, prog=None, from_name=False)>,\n",
       "   'args_from_prog': <function fastcore.script.args_from_prog(func, prog)>,\n",
       "   'SCRIPT_INFO': namespace(func=None),\n",
       "   'call_parse': <function fastcore.script.call_parse(func)>,\n",
       "   'progress_bar': fastprogress.fastprogress.NBProgressBar,\n",
       "   'master_bar': fastprogress.fastprogress.NBMasterBar,\n",
       "   'LambdaType': function,\n",
       "   'one_is_instance': <function fastai.imports.one_is_instance(a, b, t)>,\n",
       "   'pv': <function fastai.imports.pv(text, verbose)>,\n",
       "   'torch': <module 'torch' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/__init__.py'>,\n",
       "   'as_tensor': <function _VariableFunctionsClass.as_tensor>,\n",
       "   'Tensor': torch.Tensor,\n",
       "   'ByteTensor': torch.ByteTensor,\n",
       "   'LongTensor': torch.LongTensor,\n",
       "   'FloatTensor': torch.FloatTensor,\n",
       "   'HalfTensor': torch.HalfTensor,\n",
       "   'DoubleTensor': torch.DoubleTensor,\n",
       "   'nn': <module 'torch.nn' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/__init__.py'>,\n",
       "   'F': <module 'torch.nn.functional' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/functional.py'>,\n",
       "   'SequentialSampler': torch.utils.data.sampler.SequentialSampler,\n",
       "   'RandomSampler': torch.utils.data.sampler.RandomSampler,\n",
       "   'Sampler': torch.utils.data.sampler.Sampler,\n",
       "   'BatchSampler': torch.utils.data.sampler.BatchSampler,\n",
       "   'IterableDataset': torch.utils.data.dataset.IterableDataset,\n",
       "   'get_worker_info': <function torch.utils.data._utils.worker.get_worker_info()>,\n",
       "   'default_collate': <function torch.utils.data._utils.collate.default_collate(batch)>,\n",
       "   'default_convert': <function torch.utils.data._utils.collate.default_convert(data)>,\n",
       "   'subplots': <function fastai.torch_core.subplots(nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **kwargs)>,\n",
       "   'show_image': <function fastai.torch_core.show_image(im, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       "   'show_titled_image': <function fastai.torch_core.show_titled_image(o, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       "   'show_images': <function fastai.torch_core.show_images(ims, nrows=1, ncols=None, titles=None, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       "   'ArrayBase': fastai.torch_core.ArrayBase,\n",
       "   'ArrayImageBase': fastai.torch_core.ArrayImageBase,\n",
       "   'ArrayImage': fastai.torch_core.ArrayImage,\n",
       "   'ArrayImageBW': fastai.torch_core.ArrayImageBW,\n",
       "   'ArrayMask': fastai.torch_core.ArrayMask,\n",
       "   'tensor': <function fastai.torch_core.tensor(x, *rest, dtype=None, device=None, requires_grad=False, pin_memory=False)>,\n",
       "   'set_seed': <function fastai.torch_core.set_seed(s, reproducible=False)>,\n",
       "   'get_random_states': <function fastai.torch_core.get_random_states()>,\n",
       "   'set_random_states': <function fastai.torch_core.set_random_states(random_state, numpy_state, torch_state, torch_cuda_state, torch_deterministic, torch_benchmark)>,\n",
       "   'no_random': <function fastai.torch_core.no_random(seed=42, reproducible=True)>,\n",
       "   'unsqueeze': <function fastai.torch_core.unsqueeze(x, dim=-1, n=1)>,\n",
       "   'unsqueeze_': <function fastai.torch_core.unsqueeze_(x, dim=-1, n=1)>,\n",
       "   'apply': <function fastai.torch_core.apply(func, x, *args, **kwargs)>,\n",
       "   'maybe_gather': <function fastai.torch_core.maybe_gather(x, axis=0)>,\n",
       "   'to_detach': <function fastai.torch_core.to_detach(b, cpu=True, gather=True)>,\n",
       "   'to_half': <function fastai.torch_core.to_half(b)>,\n",
       "   'to_float': <function fastai.torch_core.to_float(b)>,\n",
       "   'default_device': <function fastai.torch_core.default_device(use_cuda=-1)>,\n",
       "   'to_device': <function fastai.torch_core.to_device(b, device=None, non_blocking=False)>,\n",
       "   'to_cpu': <function fastai.torch_core.to_cpu(b)>,\n",
       "   'to_np': <function fastai.torch_core.to_np(x)>,\n",
       "   'to_concat': <function fastai.torch_core.to_concat(xs, dim=0)>,\n",
       "   'TensorBase': fastai.torch_core.TensorBase,\n",
       "   'TensorImageBase': fastai.torch_core.TensorImageBase,\n",
       "   'TensorImage': fastai.torch_core.TensorImage,\n",
       "   'TensorImageBW': fastai.torch_core.TensorImageBW,\n",
       "   'TensorMask': fastai.torch_core.TensorMask,\n",
       "   'TensorFlowField': fastai.torch_core.TensorFlowField,\n",
       "   'TensorCategory': fastai.torch_core.TensorCategory,\n",
       "   'TensorMultiCategory': fastai.torch_core.TensorMultiCategory,\n",
       "   'TitledTensorScalar': fastai.torch_core.TitledTensorScalar,\n",
       "   'Chunks': fastai.torch_core.Chunks,\n",
       "   'show_title': <function fastai.torch_core.show_title(o, ax=None, ctx=None, label=None, color='black', **kwargs)>,\n",
       "   'ShowTitle': fastai.torch_core.ShowTitle,\n",
       "   'TitledInt': fastai.torch_core.TitledInt,\n",
       "   'TitledFloat': fastai.torch_core.TitledFloat,\n",
       "   'TitledStr': fastai.torch_core.TitledStr,\n",
       "   'TitledTuple': fastai.torch_core.TitledTuple,\n",
       "   'get_empty_df': <function fastai.torch_core.get_empty_df(n)>,\n",
       "   'display_df': <function fastai.torch_core.display_df(df)>,\n",
       "   'get_first': <function fastai.torch_core.get_first(c)>,\n",
       "   'one_param': <function fastai.torch_core.one_param(m)>,\n",
       "   'item_find': <function fastai.torch_core.item_find(x, idx=0)>,\n",
       "   'find_device': <function fastai.torch_core.find_device(b)>,\n",
       "   'find_bs': <function fastai.torch_core.find_bs(b)>,\n",
       "   'np_func': <function fastai.torch_core.np_func(f)>,\n",
       "   'Module': fastai.torch_core.Module,\n",
       "   'get_model': <function fastai.torch_core.get_model(model)>,\n",
       "   'one_hot': <function fastai.torch_core.one_hot(x, c)>,\n",
       "   'one_hot_decode': <function fastai.torch_core.one_hot_decode(x, vocab=None)>,\n",
       "   'params': <function fastai.torch_core.params(m)>,\n",
       "   'trainable_params': <function fastai.torch_core.trainable_params(m)>,\n",
       "   'norm_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm3d,\n",
       "    torch.nn.modules.instancenorm.InstanceNorm1d,\n",
       "    torch.nn.modules.instancenorm.InstanceNorm2d,\n",
       "    torch.nn.modules.instancenorm.InstanceNorm3d,\n",
       "    torch.nn.modules.normalization.LayerNorm),\n",
       "   'norm_bias_params': <function fastai.torch_core.norm_bias_params(m, with_bias=True)>,\n",
       "   'batch_to_samples': <function fastai.torch_core.batch_to_samples(b, max_n=10)>,\n",
       "   'logit': <function fastai.torch_core.logit(x)>,\n",
       "   'num_distrib': <function fastai.torch_core.num_distrib()>,\n",
       "   'rank_distrib': <function fastai.torch_core.rank_distrib()>,\n",
       "   'distrib_barrier': <function fastai.torch_core.distrib_barrier()>,\n",
       "   'base_doc': <function fastai.torch_core.base_doc(elt)>,\n",
       "   'doc': <function fastai.torch_core.doc(elt)>,\n",
       "   'nested_reorder': <function fastai.torch_core.nested_reorder(t, idxs)>,\n",
       "   'make_cross_image': <function fastai.torch_core.make_cross_image(bw=True)>,\n",
       "   'show_image_batch': <function fastai.torch_core.show_image_batch(b, show=<function show_titled_image at 0x7f34c0cf3170>, items=9, cols=3, figsize=None, **kwargs)>,\n",
       "   'requires_grad': <function fastai.torch_core.requires_grad(m)>,\n",
       "   'init_default': <function fastai.layers.init_default(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "   'cond_init': <function fastai.torch_core.cond_init(m, func)>,\n",
       "   'apply_leaf': <function fastai.torch_core.apply_leaf(m, f)>,\n",
       "   'apply_init': <function fastai.torch_core.apply_init(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "   'script_use_ctx': <function fastai.torch_core.script_use_ctx(f)>,\n",
       "   'script_save_ctx': <function fastai.torch_core.script_save_ctx(static, *argidx)>,\n",
       "   'script_fwd': <function fastai.torch_core.script_fwd(*argidx)>,\n",
       "   'script_bwd': <function fastai.torch_core.script_bwd(f)>,\n",
       "   'grad_module': <function fastai.torch_core.grad_module(cls)>,\n",
       "   'flatten_check': <function fastai.torch_core.flatten_check(inp, targ)>,\n",
       "   'module': <function fastai.layers.module(*flds, **defaults)>,\n",
       "   'Identity': fastai.layers.Identity,\n",
       "   'Lambda': fastai.layers.Lambda,\n",
       "   'PartialLambda': fastai.layers.PartialLambda,\n",
       "   'Flatten': fastai.layers.Flatten,\n",
       "   'View': fastai.layers.View,\n",
       "   'ResizeBatch': fastai.layers.ResizeBatch,\n",
       "   'Debugger': fastai.layers.Debugger,\n",
       "   'sigmoid_range': <function fastai.layers.sigmoid_range(x, low, high)>,\n",
       "   'SigmoidRange': fastai.layers.SigmoidRange,\n",
       "   'AdaptiveConcatPool1d': fastai.layers.AdaptiveConcatPool1d,\n",
       "   'AdaptiveConcatPool2d': fastai.layers.AdaptiveConcatPool2d,\n",
       "   'PoolType': fastai.layers.PoolType,\n",
       "   'adaptive_pool': <function fastai.layers.adaptive_pool(pool_type)>,\n",
       "   'PoolFlatten': fastai.layers.PoolFlatten,\n",
       "   'NormType': <enum 'NormType'>,\n",
       "   'BatchNorm': <function fastai.layers.BatchNorm(nf, ndim=2, norm_type=<NormType.Batch: 1>, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)>,\n",
       "   'InstanceNorm': <function fastai.layers.InstanceNorm(nf, ndim=2, norm_type=<NormType.Instance: 5>, affine=True, eps: float = 1e-05, momentum: float = 0.1, track_running_stats: bool = False)>,\n",
       "   'BatchNorm1dFlat': fastai.layers.BatchNorm1dFlat,\n",
       "   'LinBnDrop': fastai.layers.LinBnDrop,\n",
       "   'sigmoid': <function fastai.layers.sigmoid(input, eps=1e-07)>,\n",
       "   'sigmoid_': <function fastai.layers.sigmoid_(input, eps=1e-07)>,\n",
       "   'vleaky_relu': <function fastai.layers.vleaky_relu(input, inplace=True)>,\n",
       "   'init_linear': <function fastai.layers.init_linear(m, act_func=None, init='auto', bias_std=0.01)>,\n",
       "   'ConvLayer': fastai.layers.ConvLayer,\n",
       "   'AdaptiveAvgPool': <function fastai.layers.AdaptiveAvgPool(sz=1, ndim=2)>,\n",
       "   'MaxPool': <function fastai.layers.MaxPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       "   'AvgPool': <function fastai.layers.AvgPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       "   'trunc_normal_': <function fastai.layers.trunc_normal_(x, mean=0.0, std=1.0)>,\n",
       "   'Embedding': fastai.layers.Embedding,\n",
       "   'SelfAttention': fastai.layers.SelfAttention,\n",
       "   'PooledSelfAttention2d': fastai.layers.PooledSelfAttention2d,\n",
       "   'SimpleSelfAttention': fastai.layers.SimpleSelfAttention,\n",
       "   'icnr_init': <function fastai.layers.icnr_init(x, scale=2, init=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "   'PixelShuffle_ICNR': fastai.layers.PixelShuffle_ICNR,\n",
       "   'sequential': <function fastai.layers.sequential(*args)>,\n",
       "   'SequentialEx': fastai.layers.SequentialEx,\n",
       "   'MergeLayer': fastai.layers.MergeLayer,\n",
       "   'Cat': fastai.layers.Cat,\n",
       "   'SimpleCNN': fastai.layers.SimpleCNN,\n",
       "   'ProdLayer': fastai.layers.ProdLayer,\n",
       "   'inplace_relu': functools.partial(<class 'torch.nn.modules.activation.ReLU'>, inplace=True),\n",
       "   'SEModule': <function fastai.layers.SEModule(ch, reduction, act_cls=<class 'torch.nn.modules.activation.ReLU'>)>,\n",
       "   'ResBlock': fastai.layers.ResBlock,\n",
       "   'SEBlock': <function fastai.layers.SEBlock(expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)>,\n",
       "   'SEResNeXtBlock': <function fastai.layers.SEResNeXtBlock(expansion, ni, nf, groups=32, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       "   'SeparableBlock': <function fastai.layers.SeparableBlock(expansion, ni, nf, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       "   'TimeDistributed': fastai.layers.TimeDistributed,\n",
       "   'swish': <function fastai.layers.swish(x, inplace=False)>,\n",
       "   'Swish': fastai.layers.Swish,\n",
       "   'MishJitAutoFn': fastai.layers.MishJitAutoFn,\n",
       "   'mish': <function fastai.layers.mish(x)>,\n",
       "   'Mish': fastai.layers.Mish,\n",
       "   'ParameterModule': fastai.layers.ParameterModule,\n",
       "   'children_and_parameters': <function fastai.layers.children_and_parameters(m)>,\n",
       "   'has_children': <function fastai.layers.has_children(m)>,\n",
       "   'flatten_model': <function fastai.layers.flatten_model(m)>,\n",
       "   'NoneReduce': fastai.layers.NoneReduce,\n",
       "   'in_channels': <function fastai.layers.in_channels(m)>,\n",
       "   'BaseLoss': fastai.losses.BaseLoss,\n",
       "   'CrossEntropyLossFlat': fastai.losses.CrossEntropyLossFlat,\n",
       "   'FocalLossFlat': fastai.losses.FocalLossFlat,\n",
       "   'BCEWithLogitsLossFlat': fastai.losses.BCEWithLogitsLossFlat,\n",
       "   'BCELossFlat': <function fastai.losses.BCELossFlat(*args, axis=-1, floatify=True, weight=None, reduction='mean')>,\n",
       "   'MSELossFlat': <function fastai.losses.MSELossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       "   'L1LossFlat': <function fastai.losses.L1LossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       "   'LabelSmoothingCrossEntropy': fastai.losses.LabelSmoothingCrossEntropy,\n",
       "   'LabelSmoothingCrossEntropyFlat': fastai.losses.LabelSmoothingCrossEntropyFlat,\n",
       "   'show_batch': (TensorImage,TensorImage) -> show_batch\n",
       "   (TensorImage,object) -> show_batch\n",
       "   (AudioTensor,object) -> show_batch\n",
       "   (AudioSpectrogram,object) -> show_batch\n",
       "   (object,object) -> show_batch,\n",
       "   'show_results': (TensorImage,TensorCategory) -> show_results\n",
       "   (TensorImage,TensorMask) -> show_results\n",
       "   (TensorImage,TensorBBox) -> show_results\n",
       "   (TensorImage,TensorPoint) -> show_results\n",
       "   (TensorImage,TensorImage) -> show_results\n",
       "   (TensorImage,object) -> show_results\n",
       "   (object,object) -> show_results,\n",
       "   'TfmdDL': fastai.data.core.TfmdDL,\n",
       "   'DataLoaders': fastai.data.core.DataLoaders,\n",
       "   'FilteredBase': fastai.data.core.FilteredBase,\n",
       "   'TfmdLists': fastai.data.core.TfmdLists,\n",
       "   'decode_at': <function fastai.data.core.decode_at(o, idx)>,\n",
       "   'show_at': <function fastai.data.core.show_at(o, idx, **kwargs)>,\n",
       "   'Datasets': fastai.data.core.Datasets,\n",
       "   'test_set': <function fastai.data.core.test_set(dsets, test_items, rm_tfms=None, with_labels=False)>,\n",
       "   'fa_collate': <function fastai.data.load.fa_collate(t)>,\n",
       "   'fa_convert': <function fastai.data.load.fa_convert(t)>,\n",
       "   'SkipItemException': fastai.data.load.SkipItemException,\n",
       "   'DataLoader': fastai.data.load.DataLoader,\n",
       "   'URLs': fastai.data.external.URLs,\n",
       "   'download_url': <function fastai.data.external.download_url(url, dest, overwrite=False, pbar=None, show_progress=True, chunk_size=1048576, timeout=4, retries=5)>,\n",
       "   'download_data': <function fastai.data.external.download_data(url, fname=None, c_key='archive', force_download=False, timeout=4)>,\n",
       "   'file_extract': <function fastai.data.external.file_extract(fname, dest=None)>,\n",
       "   'newest_folder': <function fastai.data.external.newest_folder(path)>,\n",
       "   'rename_extracted': <function fastai.data.external.rename_extracted(dest)>,\n",
       "   'untar_data': <function fastai.data.external.untar_data(url, fname=None, dest=None, c_key='data', force_download=False, extract_func=<function file_extract at 0x7f34bf3bec20>, timeout=4)>,\n",
       "   'get_files': <function fastai.data.transforms.get_files(path, extensions=None, recurse=True, folders=None, followlinks=True)>,\n",
       "   'FileGetter': <function fastai.data.transforms.FileGetter(suf='', extensions=None, recurse=True, folders=None)>,\n",
       "   'image_extensions': {'.art',\n",
       "    '.bmp',\n",
       "    '.cdr',\n",
       "    '.cdt',\n",
       "    '.cpt',\n",
       "    '.cr2',\n",
       "    '.crw',\n",
       "    '.djv',\n",
       "    '.djvu',\n",
       "    '.erf',\n",
       "    '.gif',\n",
       "    '.ico',\n",
       "    '.ief',\n",
       "    '.jng',\n",
       "    '.jp2',\n",
       "    '.jpe',\n",
       "    '.jpeg',\n",
       "    '.jpf',\n",
       "    '.jpg',\n",
       "    '.jpg2',\n",
       "    '.jpm',\n",
       "    '.jpx',\n",
       "    '.nef',\n",
       "    '.orf',\n",
       "    '.pat',\n",
       "    '.pbm',\n",
       "    '.pcx',\n",
       "    '.pgm',\n",
       "    '.png',\n",
       "    '.pnm',\n",
       "    '.ppm',\n",
       "    '.psd',\n",
       "    '.ras',\n",
       "    '.rgb',\n",
       "    '.svg',\n",
       "    '.svgz',\n",
       "    '.tif',\n",
       "    '.tiff',\n",
       "    '.wbmp',\n",
       "    '.xbm',\n",
       "    '.xpm',\n",
       "    '.xwd'},\n",
       "   'get_image_files': <function fastai.data.transforms.get_image_files(path, recurse=True, folders=None)>,\n",
       "   'ImageGetter': <function fastai.data.transforms.ImageGetter(suf='', recurse=True, folders=None)>,\n",
       "   'get_text_files': <function fastai.data.transforms.get_text_files(path, recurse=True, folders=None)>,\n",
       "   'ItemGetter': fastai.data.transforms.ItemGetter,\n",
       "   'AttrGetter': fastai.data.transforms.AttrGetter,\n",
       "   'RandomSplitter': <function fastai.data.transforms.RandomSplitter(valid_pct=0.2, seed=None)>,\n",
       "   'TrainTestSplitter': <function fastai.data.transforms.TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, train_size=None, shuffle=True)>,\n",
       "   'IndexSplitter': <function fastai.data.transforms.IndexSplitter(valid_idx)>,\n",
       "   'GrandparentSplitter': <function fastai.data.transforms.GrandparentSplitter(train_name='train', valid_name='valid')>,\n",
       "   'FuncSplitter': <function fastai.data.transforms.FuncSplitter(func)>,\n",
       "   'MaskSplitter': <function fastai.data.transforms.MaskSplitter(mask)>,\n",
       "   'FileSplitter': <function fastai.data.transforms.FileSplitter(fname)>,\n",
       "   'ColSplitter': <function fastai.data.transforms.ColSplitter(col='is_valid')>,\n",
       "   'RandomSubsetSplitter': <function fastai.data.transforms.RandomSubsetSplitter(train_sz, valid_sz, seed=None)>,\n",
       "   'parent_label': <function fastai.data.transforms.parent_label(o)>,\n",
       "   'RegexLabeller': fastai.data.transforms.RegexLabeller,\n",
       "   'ColReader': fastai.data.transforms.ColReader,\n",
       "   'CategoryMap': fastai.data.transforms.CategoryMap,\n",
       "   'Categorize': fastai.data.transforms.Categorize,\n",
       "   'Category': fastai.data.transforms.Category,\n",
       "   'MultiCategorize': fastai.data.transforms.MultiCategorize,\n",
       "   'MultiCategory': fastai.data.transforms.MultiCategory,\n",
       "   'OneHotEncode': fastai.data.transforms.OneHotEncode,\n",
       "   'EncodedMultiCategorize': fastai.data.transforms.EncodedMultiCategorize,\n",
       "   'RegressionSetup': fastai.data.transforms.RegressionSetup,\n",
       "   'get_c': <function fastai.data.transforms.get_c(dls)>,\n",
       "   'ToTensor': fastai.data.transforms.ToTensor,\n",
       "   'IntToFloatTensor': fastai.data.transforms.IntToFloatTensor,\n",
       "   'broadcast_vec': <function fastai.data.transforms.broadcast_vec(dim, ndim, *t, cuda=True)>,\n",
       "   'Normalize': fastai.data.transforms.Normalize,\n",
       "   'TransformBlock': fastai.data.block.TransformBlock,\n",
       "   'CategoryBlock': <function fastai.data.block.CategoryBlock(vocab=None, sort=True, add_na=False)>,\n",
       "   'MultiCategoryBlock': <function fastai.data.block.MultiCategoryBlock(encoded=False, vocab=None, add_na=False)>,\n",
       "   'RegressionBlock': <function fastai.data.block.RegressionBlock(n_out=None)>,\n",
       "   'DataBlock': fastai.data.block.DataBlock,\n",
       "   'Optimizer': fastai.optimizer.Optimizer,\n",
       "   'sgd_step': <function fastai.optimizer.sgd_step(p, lr, **kwargs)>,\n",
       "   'weight_decay': <function fastai.optimizer.weight_decay(p, lr, wd, do_wd=True, **kwargs)>,\n",
       "   'l2_reg': <function fastai.optimizer.l2_reg(p, lr, wd, do_wd=True, **kwargs)>,\n",
       "   'average_grad': <function fastai.optimizer.average_grad(p, mom, dampening=False, grad_avg=None, **kwargs)>,\n",
       "   'average_sqr_grad': <function fastai.optimizer.average_sqr_grad(p, sqr_mom, dampening=True, sqr_avg=None, **kwargs)>,\n",
       "   'momentum_step': <function fastai.optimizer.momentum_step(p, lr, grad_avg, **kwargs)>,\n",
       "   'SGD': <function fastai.optimizer.SGD(params, lr, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       "   'rms_prop_step': <function fastai.optimizer.rms_prop_step(p, lr, sqr_avg, eps, grad_avg=None, **kwargs)>,\n",
       "   'RMSProp': <function fastai.optimizer.RMSProp(params, lr, sqr_mom=0.99, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       "   'step_stat': <function fastai.optimizer.step_stat(p, step=0, **kwargs)>,\n",
       "   'debias': <function fastai.optimizer.debias(mom, damp, step)>,\n",
       "   'adam_step': <function fastai.optimizer.adam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       "   'Adam': <function fastai.optimizer.Adam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.01, decouple_wd=True)>,\n",
       "   'radam_step': <function fastai.optimizer.radam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, beta, **kwargs)>,\n",
       "   'RAdam': <function fastai.optimizer.RAdam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, beta=0.0, decouple_wd=True)>,\n",
       "   'qhadam_step': <function fastai.optimizer.qhadam_step(p, lr, mom, sqr_mom, sqr_avg, nu_1, nu_2, step, grad_avg, eps, **kwargs)>,\n",
       "   'QHAdam': <function fastai.optimizer.QHAdam(params, lr, mom=0.999, sqr_mom=0.999, nu_1=0.7, nu_2=1.0, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       "   'larc_layer_lr': <function fastai.optimizer.larc_layer_lr(p, lr, trust_coeff, wd, eps, clip=True, **kwargs)>,\n",
       "   'larc_step': <function fastai.optimizer.larc_step(p, local_lr, grad_avg=None, **kwargs)>,\n",
       "   'Larc': <function fastai.optimizer.Larc(params, lr, mom=0.9, clip=True, trust_coeff=0.02, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       "   'lamb_step': <function fastai.optimizer.lamb_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       "   'Lamb': <function fastai.optimizer.Lamb(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, decouple_wd=True)>,\n",
       "   'Lookahead': fastai.optimizer.Lookahead,\n",
       "   'ranger': <function fastai.optimizer.ranger(p, lr, mom=0.95, wd=0.01, eps=1e-06, sqr_mom=0.99, beta=0.0, decouple_wd=True)>,\n",
       "   'detuplify_pg': <function fastai.optimizer.detuplify_pg(d)>,\n",
       "   'set_item_pg': <function fastai.optimizer.set_item_pg(pg, k, v)>,\n",
       "   'pytorch_hp_map': {'momentum': 'mom',\n",
       "    'weight_decay': 'wd',\n",
       "    'alpha': 'sqr_mom',\n",
       "    'betas__0': 'mom',\n",
       "    'betas__1': 'sqr_mom'},\n",
       "   'OptimWrapper': fastai.optimizer.OptimWrapper,\n",
       "   'CancelStepException': fastcore.basics.CancelStepException,\n",
       "   'CancelFitException': fastcore.basics.CancelFitException,\n",
       "   'CancelEpochException': fastcore.basics.CancelEpochException,\n",
       "   'CancelTrainException': fastcore.basics.CancelTrainException,\n",
       "   'CancelValidException': fastcore.basics.CancelValidException,\n",
       "   'CancelBatchException': fastcore.basics.CancelBatchException,\n",
       "   'event': fastcore.basics.event,\n",
       "   'Callback': fastai.callback.core.Callback,\n",
       "   'TrainEvalCallback': fastai.callback.core.TrainEvalCallback,\n",
       "   'GatherPredsCallback': fastai.callback.core.GatherPredsCallback,\n",
       "   'FetchPredsCallback': fastai.callback.core.FetchPredsCallback,\n",
       "   'replacing_yield': <function fastai.learner.replacing_yield(o, attr, val)>,\n",
       "   'mk_metric': <function fastai.learner.mk_metric(m)>,\n",
       "   'save_model': <function fastai.learner.save_model(file, model, opt, with_opt=True, pickle_protocol=2)>,\n",
       "   'load_model': <function fastai.learner.load_model(file, model, opt, with_opt=True, device=None, strict=True)>,\n",
       "   'Learner': fastai.learner.Learner,\n",
       "   'before_batch_cb': <function fastai.learner.before_batch_cb(f)>,\n",
       "   'load_learner': <function fastai.learner.load_learner(fname, cpu=True, pickle_module=<module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>)>,\n",
       "   'to_detach_from_dl': <function fastai.learner.to_detach_from_dl(learn: (<class 'fastai.learner.Learner'>, <class 'NoneType'>), b: object, cpu: bool = True, gather: bool = True)>,\n",
       "   'Metric': fastai.learner.Metric,\n",
       "   'AvgMetric': fastai.learner.AvgMetric,\n",
       "   'AvgLoss': fastai.learner.AvgLoss,\n",
       "   'AvgSmoothLoss': fastai.learner.AvgSmoothLoss,\n",
       "   'ValueMetric': fastai.learner.ValueMetric,\n",
       "   'Recorder': fastai.learner.Recorder,\n",
       "   'AccumMetric': fastai.metrics.AccumMetric,\n",
       "   'skm_to_fastai': <function fastai.metrics.skm_to_fastai(func, is_class=True, thresh=None, axis=-1, activation=None, **kwargs)>,\n",
       "   'optim_metric': <function fastai.metrics.optim_metric(f, argname, bounds, tol=0.01, do_neg=True, get_x=False)>,\n",
       "   'accuracy': <function fastai.metrics.accuracy(inp, targ, axis=-1)>,\n",
       "   'error_rate': <function fastai.metrics.error_rate(inp, targ, axis=-1)>,\n",
       "   'top_k_accuracy': <function fastai.metrics.top_k_accuracy(inp, targ, k=5, axis=-1)>,\n",
       "   'APScoreBinary': <function fastai.metrics.APScoreBinary(axis=-1, average='macro', pos_label=1, sample_weight=None)>,\n",
       "   'BalancedAccuracy': <function fastai.metrics.BalancedAccuracy(axis=-1, sample_weight=None, adjusted=False)>,\n",
       "   'BrierScore': <function fastai.metrics.BrierScore(axis=-1, sample_weight=None, pos_label=None)>,\n",
       "   'CohenKappa': <function fastai.metrics.CohenKappa(axis=-1, labels=None, weights=None, sample_weight=None)>,\n",
       "   'F1Score': <function fastai.metrics.F1Score(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'FBeta': <function fastai.metrics.FBeta(beta, axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'HammingLoss': <function fastai.metrics.HammingLoss(axis=-1, sample_weight=None)>,\n",
       "   'Jaccard': <function fastai.metrics.Jaccard(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'Precision': <function fastai.metrics.Precision(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'Recall': <function fastai.metrics.Recall(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'RocAuc': <function fastai.metrics.RocAuc(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='ovr')>,\n",
       "   'RocAucBinary': <function fastai.metrics.RocAucBinary(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='raise')>,\n",
       "   'MatthewsCorrCoef': <function fastai.metrics.MatthewsCorrCoef(sample_weight=None, **kwargs)>,\n",
       "   'Perplexity': fastai.metrics.Perplexity,\n",
       "   'perplexity': <fastai.metrics.Perplexity at 0x7f34b7101810>,\n",
       "   'accuracy_multi': <function fastai.metrics.accuracy_multi(inp, targ, thresh=0.5, sigmoid=True)>,\n",
       "   'APScoreMulti': <function fastai.metrics.APScoreMulti(sigmoid=True, average='macro', pos_label=1, sample_weight=None)>,\n",
       "   'BrierScoreMulti': <function fastai.metrics.BrierScoreMulti(thresh=0.5, sigmoid=True, sample_weight=None, pos_label=None)>,\n",
       "   'F1ScoreMulti': <function fastai.metrics.F1ScoreMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'FBetaMulti': <function fastai.metrics.FBetaMulti(beta, thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'HammingLossMulti': <function fastai.metrics.HammingLossMulti(thresh=0.5, sigmoid=True, labels=None, sample_weight=None)>,\n",
       "   'JaccardMulti': <function fastai.metrics.JaccardMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'MatthewsCorrCoefMulti': <function fastai.metrics.MatthewsCorrCoefMulti(thresh=0.5, sigmoid=True, sample_weight=None)>,\n",
       "   'PrecisionMulti': <function fastai.metrics.PrecisionMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'RecallMulti': <function fastai.metrics.RecallMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'RocAucMulti': <function fastai.metrics.RocAucMulti(sigmoid=True, average='macro', sample_weight=None, max_fpr=None)>,\n",
       "   'mse': <function fastai.metrics.mse(inp, targ)>,\n",
       "   'rmse': <fastai.metrics.AccumMetric at 0x7f34b7101850>,\n",
       "   'mae': <function fastai.metrics.mae(inp, targ)>,\n",
       "   'msle': <function fastai.metrics.msle(inp, targ)>,\n",
       "   'exp_rmspe': <fastai.metrics.AccumMetric at 0x7f34b71018d0>,\n",
       "   'ExplainedVariance': <function fastai.metrics.ExplainedVariance(sample_weight=None)>,\n",
       "   'R2Score': <function fastai.metrics.R2Score(sample_weight=None)>,\n",
       "   'PearsonCorrCoef': <function fastai.metrics.PearsonCorrCoef(dim_argmax=None, activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       "   'SpearmanCorrCoef': <function fastai.metrics.SpearmanCorrCoef(dim_argmax=None, axis=0, nan_policy='propagate', activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       "   'foreground_acc': <function fastai.metrics.foreground_acc(inp, targ, bkg_idx=0, axis=1)>,\n",
       "   'Dice': fastai.metrics.Dice,\n",
       "   'DiceMulti': fastai.metrics.DiceMulti,\n",
       "   'JaccardCoeff': fastai.metrics.JaccardCoeff,\n",
       "   'CorpusBLEUMetric': fastai.metrics.CorpusBLEUMetric,\n",
       "   'LossMetric': fastai.metrics.LossMetric,\n",
       "   'LossMetrics': <function fastai.metrics.LossMetrics(attrs, nms=None)>,\n",
       "   'plot_top_losses': (TensorImage,TensorMultiCategory) -> plot_top_losses\n",
       "   (TensorImage,TensorCategory) -> plot_top_losses\n",
       "   (TensorImage,TensorMask) -> plot_top_losses\n",
       "   (object,object) -> plot_top_losses,\n",
       "   'Interpretation': fastai.interpret.Interpretation,\n",
       "   'ClassificationInterpretation': fastai.interpret.ClassificationInterpretation,\n",
       "   'SegmentationInterpretation': fastai.interpret.SegmentationInterpretation,\n",
       "   'CollectDataCallback': fastai.callback.data.CollectDataCallback,\n",
       "   'WeightedDL': fastai.callback.data.WeightedDL,\n",
       "   'PartialDL': fastai.callback.data.PartialDL,\n",
       "   'MixedPrecision': fastai.callback.fp16.MixedPrecision,\n",
       "   'FP16TestCallback': fastai.callback.fp16.FP16TestCallback,\n",
       "   'get_master': <function fastai.callback.fp16.get_master(opt, flat_master=False)>,\n",
       "   'to_master_grads': <function fastai.callback.fp16.to_master_grads(model_pgs, master_pgs, flat_master=False)>,\n",
       "   'to_model_params': <function fastai.callback.fp16.to_model_params(model_pgs, master_pgs, flat_master=False) -> None>,\n",
       "   'test_overflow': <function fastai.callback.fp16.test_overflow(x)>,\n",
       "   'grad_overflow': <function fastai.callback.fp16.grad_overflow(pgs)>,\n",
       "   'copy_clone': <function fastai.callback.fp16.copy_clone(d)>,\n",
       "   'ModelToHalf': fastai.callback.fp16.ModelToHalf,\n",
       "   'NonNativeMixedPrecision': fastai.callback.fp16.NonNativeMixedPrecision,\n",
       "   'Hook': fastai.callback.hook.Hook,\n",
       "   'hook_output': <function fastai.callback.hook.hook_output(module, detach=True, cpu=False, grad=False)>,\n",
       "   'Hooks': fastai.callback.hook.Hooks,\n",
       "   'hook_outputs': <function fastai.callback.hook.hook_outputs(modules, detach=True, cpu=False, grad=False)>,\n",
       "   'dummy_eval': <function fastai.callback.hook.dummy_eval(m, size=(64, 64))>,\n",
       "   'model_sizes': <function fastai.callback.hook.model_sizes(m, size=(64, 64))>,\n",
       "   'num_features_model': <function fastai.callback.hook.num_features_model(m)>,\n",
       "   'has_params': <function fastai.callback.hook.has_params(m)>,\n",
       "   'HookCallback': fastai.callback.hook.HookCallback,\n",
       "   'total_params': <function fastai.callback.hook.total_params(m)>,\n",
       "   'layer_info': <function fastai.callback.hook.layer_info(learn, *xb)>,\n",
       "   'module_summary': <function fastai.callback.hook.module_summary(learn, *xb)>,\n",
       "   'ActivationStats': fastai.callback.hook.ActivationStats,\n",
       "   'reduce_loss': <function fastai.callback.mixup.reduce_loss(loss, reduction='mean')>,\n",
       "   'MixHandler': fastai.callback.mixup.MixHandler,\n",
       "   'MixUp': fastai.callback.mixup.MixUp,\n",
       "   'CutMix': fastai.callback.mixup.CutMix,\n",
       "   'ProgressCallback': fastai.callback.progress.ProgressCallback,\n",
       "   'ShowGraphCallback': fastai.callback.progress.ShowGraphCallback,\n",
       "   'CSVLogger': fastai.callback.progress.CSVLogger,\n",
       "   'annealer': <function fastai.callback.schedule.annealer(f)>,\n",
       "   'sched_lin': <function fastai.callback.schedule.sched_lin(start, end, pos)>,\n",
       "   'sched_cos': <function fastai.callback.schedule.sched_cos(start, end, pos)>,\n",
       "   'sched_no': <function fastai.callback.schedule.sched_no(start, end, pos)>,\n",
       "   'sched_exp': <function fastai.callback.schedule.sched_exp(start, end, pos)>,\n",
       "   'SchedLin': <function fastai.callback.schedule.SchedLin(start, end)>,\n",
       "   'SchedCos': <function fastai.callback.schedule.SchedCos(start, end)>,\n",
       "   'SchedNo': <function fastai.callback.schedule.SchedNo(start, end)>,\n",
       "   'SchedExp': <function fastai.callback.schedule.SchedExp(start, end)>,\n",
       "   'SchedPoly': <function fastai.callback.schedule.SchedPoly(start, end, power)>,\n",
       "   'combine_scheds': <function fastai.callback.schedule.combine_scheds(pcts, scheds)>,\n",
       "   'combined_cos': <function fastai.callback.schedule.combined_cos(pct, start, middle, end)>,\n",
       "   'ParamScheduler': fastai.callback.schedule.ParamScheduler,\n",
       "   'LRFinder': fastai.callback.schedule.LRFinder,\n",
       "   'SuggestedLRs': fastai.callback.schedule.SuggestedLRs,\n",
       "   'TerminateOnNaNCallback': fastai.callback.tracker.TerminateOnNaNCallback,\n",
       "   'TrackerCallback': fastai.callback.tracker.TrackerCallback,\n",
       "   'EarlyStoppingCallback': fastai.callback.tracker.EarlyStoppingCallback,\n",
       "   'SaveModelCallback': fastai.callback.tracker.SaveModelCallback,\n",
       "   'ReduceLROnPlateau': fastai.callback.tracker.ReduceLROnPlateau,\n",
       "   'ModelResetter': fastai.callback.rnn.ModelResetter,\n",
       "   'RNNCallback': fastai.callback.rnn.RNNCallback,\n",
       "   'RNNRegularizer': fastai.callback.rnn.RNNRegularizer,\n",
       "   'rnn_cbs': <function fastai.callback.rnn.rnn_cbs(alpha=0.0, beta=0.0)>,\n",
       "   'ShortEpochCallback': fastai.callback.training.ShortEpochCallback,\n",
       "   'GradientAccumulation': fastai.callback.training.GradientAccumulation,\n",
       "   'GradientClip': fastai.callback.training.GradientClip,\n",
       "   'set_bn_eval': <function fastai.callback.training.set_bn_eval(m: torch.nn.modules.module.Module, use_eval=True) -> None>,\n",
       "   'BnFreeze': fastai.callback.training.BnFreeze,\n",
       "   'bn_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm3d),\n",
       "   'MCDropoutCallback': fastai.callback.preds.MCDropoutCallback,\n",
       "   'RandTransform': fastai.vision.augment.RandTransform,\n",
       "   'TensorTypes': (fastai.torch_core.TensorImage,\n",
       "    fastai.torch_core.TensorMask,\n",
       "    fastai.vision.core.TensorPoint,\n",
       "    fastai.vision.core.TensorBBox),\n",
       "   'FlipItem': fastai.vision.augment.FlipItem,\n",
       "   'DihedralItem': fastai.vision.augment.DihedralItem,\n",
       "   'PadMode': fastcore.basics.PadMode,\n",
       "   'CropPad': fastai.vision.augment.CropPad,\n",
       "   'RandomCrop': fastai.vision.augment.RandomCrop,\n",
       "   'OldRandomCrop': fastai.vision.augment.OldRandomCrop,\n",
       "   'ResizeMethod': fastcore.basics.ResizeMethod,\n",
       "   'Resize': fastai.vision.augment.Resize,\n",
       "   'RandomResizedCrop': fastai.vision.augment.RandomResizedCrop,\n",
       "   'RatioResize': fastai.vision.augment.RatioResize,\n",
       "   'affine_grid': <function fastai.vision.augment.affine_grid(theta, size, align_corners=None)>,\n",
       "   'AffineCoordTfm': fastai.vision.augment.AffineCoordTfm,\n",
       "   'RandomResizedCropGPU': fastai.vision.augment.RandomResizedCropGPU,\n",
       "   'mask_tensor': <function fastai.vision.augment.mask_tensor(x, p=0.5, neutral=0.0, batch=False)>,\n",
       "   'affine_mat': <function fastai.vision.augment.affine_mat(*ms)>,\n",
       "   'flip_mat': <function fastai.vision.augment.flip_mat(x, p=0.5, draw=None, batch=False)>,\n",
       "   'Flip': fastai.vision.augment.Flip,\n",
       "   'DeterministicDraw': fastai.vision.augment.DeterministicDraw,\n",
       "   'DeterministicFlip': fastai.vision.augment.DeterministicFlip,\n",
       "   'dihedral_mat': <function fastai.vision.augment.dihedral_mat(x, p=0.5, draw=None, batch=False)>,\n",
       "   'Dihedral': fastai.vision.augment.Dihedral,\n",
       "   'DeterministicDihedral': fastai.vision.augment.DeterministicDihedral,\n",
       "   'rotate_mat': <function fastai.vision.augment.rotate_mat(x, max_deg=10, p=0.5, draw=None, batch=False)>,\n",
       "   'Rotate': fastai.vision.augment.Rotate,\n",
       "   'zoom_mat': <function fastai.vision.augment.zoom_mat(x, min_zoom=1.0, max_zoom=1.1, p=0.5, draw=None, draw_x=None, draw_y=None, batch=False)>,\n",
       "   'Zoom': fastai.vision.augment.Zoom,\n",
       "   'find_coeffs': <function fastai.vision.augment.find_coeffs(p1, p2)>,\n",
       "   'apply_perspective': <function fastai.vision.augment.apply_perspective(coords, coeffs)>,\n",
       "   'Warp': fastai.vision.augment.Warp,\n",
       "   'SpaceTfm': fastai.vision.augment.SpaceTfm,\n",
       "   'LightingTfm': fastai.vision.augment.LightingTfm,\n",
       "   'Brightness': fastai.vision.augment.Brightness,\n",
       "   'Contrast': fastai.vision.augment.Contrast,\n",
       "   'grayscale': <function fastai.vision.augment.grayscale(x)>,\n",
       "   'Saturation': fastai.vision.augment.Saturation,\n",
       "   'rgb2hsv': <function fastai.vision.augment.rgb2hsv(img)>,\n",
       "   'hsv2rgb': <function fastai.vision.augment.hsv2rgb(img)>,\n",
       "   'HSVTfm': fastai.vision.augment.HSVTfm,\n",
       "   'Hue': fastai.vision.augment.Hue,\n",
       "   'cutout_gaussian': <function fastai.vision.augment.cutout_gaussian(x, areas)>,\n",
       "   'norm_apply_denorm': <function fastai.vision.augment.norm_apply_denorm(x, f, nrm)>,\n",
       "   'RandomErasing': fastai.vision.augment.RandomErasing,\n",
       "   'setup_aug_tfms': <function fastai.vision.augment.setup_aug_tfms(tfms)>,\n",
       "   'aug_transforms': <function fastai.vision.augment.aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=None, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0)>,\n",
       "   'Image': <module 'PIL.Image' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/PIL/Image.py'>,\n",
       "   'imagenet_stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
       "   'cifar_stats': ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261]),\n",
       "   'mnist_stats': ([0.131], [0.308]),\n",
       "   'n_px': None,\n",
       "   'shape': None,\n",
       "   'aspect': None,\n",
       "   'to_image': <function fastai.vision.core.to_image(x)>,\n",
       "   'load_image': <function fastai.vision.core.load_image(fn, mode=None)>,\n",
       "   'image2tensor': <function fastai.vision.core.image2tensor(img)>,\n",
       "   'PILBase': fastai.vision.core.PILBase,\n",
       "   'PILImage': fastai.vision.core.PILImage,\n",
       "   'PILImageBW': fastai.vision.core.PILImageBW,\n",
       "   'PILMask': fastai.vision.core.PILMask,\n",
       "   'OpenMask': PILBase.create:\n",
       "   encodes: (Path,object) -> create\n",
       "   (str,object) -> create\n",
       "   (Tensor,object) -> create\n",
       "   (ndarray,object) -> create\n",
       "   (bytes,object) -> createdecodes: ,\n",
       "   'AddMaskCodes': fastai.vision.core.AddMaskCodes,\n",
       "   'TensorPoint': fastai.vision.core.TensorPoint,\n",
       "   'TensorPointCreate': TensorPoint.create:\n",
       "   encodes: (object,object) -> createdecodes: ,\n",
       "   'get_annotations': <function fastai.vision.core.get_annotations(fname, prefix=None)>,\n",
       "   'TensorBBox': fastai.vision.core.TensorBBox,\n",
       "   'LabeledBBox': fastai.vision.core.LabeledBBox,\n",
       "   'encodes': <function fastai.vision.core.encodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       "   'PointScaler': fastai.vision.core.PointScaler,\n",
       "   'BBoxLabeler': fastai.vision.core.BBoxLabeler,\n",
       "   'decodes': <function fastai.vision.core.decodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       "   'get_grid': <function fastai.vision.data.get_grid(n, nrows=None, ncols=None, add_vert=0, figsize=None, double=False, title=None, return_fig=False, flatten=True, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       "   'clip_remove_empty': <function fastai.vision.data.clip_remove_empty(bbox, label)>,\n",
       "   'bb_pad': <function fastai.vision.data.bb_pad(samples, pad_idx=0)>,\n",
       "   'ImageBlock': <function fastai.vision.data.ImageBlock(cls=<class 'fastai.vision.core.PILImage'>)>,\n",
       "   'MaskBlock': <function fastai.vision.data.MaskBlock(codes=None)>,\n",
       "   'PointBlock': <fastai.data.block.TransformBlock at 0x7f34b7020410>,\n",
       "   'BBoxBlock': <fastai.data.block.TransformBlock at 0x7f34b7093850>,\n",
       "   'BBoxLblBlock': <function fastai.vision.data.BBoxLblBlock(vocab=None, add_na=True)>,\n",
       "   'ImageDataLoaders': fastai.vision.data.ImageDataLoaders,\n",
       "   'SegmentationDataLoaders': fastai.vision.data.SegmentationDataLoaders,\n",
       "   'init_cnn': <function fastai.vision.models.xresnet.init_cnn(m)>,\n",
       "   'XResNet': fastai.vision.models.xresnet.XResNet,\n",
       "   'xresnet18': <function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>,\n",
       "   'xresnet34': <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>,\n",
       "   'xresnet50': <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>,\n",
       "   'xresnet101': <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>,\n",
       "   'xresnet152': <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>,\n",
       "   'xresnet18_deep': <function fastai.vision.models.xresnet.xresnet18_deep(pretrained=False, **kwargs)>,\n",
       "   'xresnet34_deep': <function fastai.vision.models.xresnet.xresnet34_deep(pretrained=False, **kwargs)>,\n",
       "   'xresnet50_deep': <function fastai.vision.models.xresnet.xresnet50_deep(pretrained=False, **kwargs)>,\n",
       "   'xresnet18_deeper': <function fastai.vision.models.xresnet.xresnet18_deeper(pretrained=False, **kwargs)>,\n",
       "   'xresnet34_deeper': <function fastai.vision.models.xresnet.xresnet34_deeper(pretrained=False, **kwargs)>,\n",
       "   'xresnet50_deeper': <function fastai.vision.models.xresnet.xresnet50_deeper(pretrained=False, **kwargs)>,\n",
       "   'se_kwargs1': {'groups': 1, 'reduction': 16},\n",
       "   'se_kwargs2': {'groups': 32, 'reduction': 16},\n",
       "   'se_kwargs3': {'groups': 32, 'reduction': 0},\n",
       "   'g0': [2, 2, 2, 2],\n",
       "   'g1': [3, 4, 6, 3],\n",
       "   'g2': [3, 4, 23, 3],\n",
       "   'g3': [3, 8, 36, 3],\n",
       "   'xse_resnet18': <function fastai.vision.models.xresnet.xse_resnet18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext18': <function fastai.vision.models.xresnet.xse_resnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext18': <function fastai.vision.models.xresnet.xresnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet34': <function fastai.vision.models.xresnet.xse_resnet34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext34': <function fastai.vision.models.xresnet.xse_resnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext34': <function fastai.vision.models.xresnet.xresnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet50': <function fastai.vision.models.xresnet.xse_resnet50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext50': <function fastai.vision.models.xresnet.xse_resnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext50': <function fastai.vision.models.xresnet.xresnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet101': <function fastai.vision.models.xresnet.xse_resnet101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext101': <function fastai.vision.models.xresnet.xse_resnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext101': <function fastai.vision.models.xresnet.xresnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet152': <function fastai.vision.models.xresnet.xse_resnet152(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xsenet154': <function fastai.vision.models.xresnet.xsenet154(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext18_deep': <function fastai.vision.models.xresnet.xse_resnext18_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext34_deep': <function fastai.vision.models.xresnet.xse_resnext34_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext50_deep': <function fastai.vision.models.xresnet.xse_resnext50_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext18_deeper': <function fastai.vision.models.xresnet.xse_resnext18_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext34_deeper': <function fastai.vision.models.xresnet.xse_resnext34_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext50_deeper': <function fastai.vision.models.xresnet.xse_resnext50_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'UnetBlock': fastai.vision.models.unet.UnetBlock,\n",
       "   'ResizeToOrig': fastai.vision.models.unet.ResizeToOrig,\n",
       "   'DynamicUnet': fastai.vision.models.unet.DynamicUnet,\n",
       "   'ResNet': torchvision.models.resnet.ResNet,\n",
       "   'resnet18': <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet34': <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet50': <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet101': <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet152': <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'SqueezeNet': torchvision.models.squeezenet.SqueezeNet,\n",
       "   'squeezenet1_0': <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       "   'squeezenet1_1': <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       "   'densenet121': <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'densenet169': <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'densenet201': <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'densenet161': <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'vgg11_bn': <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'vgg13_bn': <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'vgg16_bn': <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'vgg19_bn': <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'alexnet': <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>,\n",
       "   'has_pool_type': <function fastai.vision.learner.has_pool_type(m)>,\n",
       "   'create_body': <function fastai.vision.learner.create_body(arch, n_in=3, pretrained=True, cut=None)>,\n",
       "   'create_head': <function fastai.vision.learner.create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "   'default_split': <function fastai.vision.learner.default_split(m)>,\n",
       "   'model_meta': {<function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._alexnet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])}},\n",
       "   'create_cnn_model': <function fastai.vision.learner.create_cnn_model(arch, n_out, pretrained=True, cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "   'cnn_learner': <function fastai.vision.learner.cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "   'create_unet_model': <function fastai.vision.learner.create_unet_model(arch, n_out, img_size, pretrained=True, cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       "   'unet_learner': <function fastai.vision.learner.unet_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       "   'download_images': <function fastai.vision.utils.download_images(dest, url_file=None, urls=None, max_pics=1000, n_workers=8, timeout=4, preserve_filename=False)>,\n",
       "   'resize_to': <function fastai.vision.utils.resize_to(img, targ_sz, use_min=False)>,\n",
       "   'verify_image': <function fastai.vision.utils.verify_image(fn)>,\n",
       "   'verify_images': <function fastai.vision.utils.verify_images(fns)>,\n",
       "   'resize_image': <function fastai.vision.utils.resize_image(file, dest, max_size=None, n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=False, **kwargs)>,\n",
       "   'resize_images': <function fastai.vision.utils.resize_images(path, max_workers=4, max_size=None, recurse=False, dest=Path('.'), n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=None, **kwargs)>,\n",
       "   'transforms': <module 'torchaudio.transforms' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/transforms.py'>,\n",
       "   'make_dataclass': <function dataclasses.make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)>,\n",
       "   'signature': <function inspect.signature(obj, *, follow_wrapped=True)>,\n",
       "   'save_audio': <function torchaudio.backend.sox_io_backend.save(filepath: str, src: torch.Tensor, sample_rate: int, channels_first: bool = True, compression: Union[float, NoneType] = None, format: Union[str, NoneType] = None, encoding: Union[str, NoneType] = None, bits_per_sample: Union[int, NoneType] = None)>,\n",
       "   'Resample': fastaudio.augment.preprocess.Resample,\n",
       "   'DownmixMono': fastaudio.augment.signal.DownmixMono,\n",
       "   'ResizeSignal': fastaudio.augment.signal.ResizeSignal,\n",
       "   'AudioTensor': fastaudio.core.signal.AudioTensor,\n",
       "   'get_audio_files': <function fastaudio.core.signal.get_audio_files(path, recurse=True, folders=None)>,\n",
       "   'audio_item_tfms': <function fastaudio.core.config.audio_item_tfms(sample_rate=16000, force_mono=True, crop_signal_to=None)>,\n",
       "   'PreprocessAudio': fastaudio.core.config.PreprocessAudio,\n",
       "   'preprocess_audio_folder': <function fastaudio.core.config.preprocess_audio_folder(path, folders=None, output_dir=None, sample_rate=16000, force_mono=True, crop_signal_to=None, **kwargs)>,\n",
       "   'AudioBlock': fastaudio.core.config.AudioBlock,\n",
       "   'config_from_func': <function fastaudio.core.config.config_from_func(func, name, **kwargs)>,\n",
       "   'AudioConfig': fastaudio.core.config.AudioConfig,\n",
       "   'torchaudio': <module 'torchaudio' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/__init__.py'>,\n",
       "   'Audio': IPython.lib.display.Audio,\n",
       "   'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
       "   'waveplot': <function librosa.display.waveplot(y, sr=22050, max_points=50000.0, x_axis='time', offset=0.0, max_sr=1000, ax=None, **kwargs)>,\n",
       "   'path': <module 'posixpath' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/posixpath.py'>,\n",
       "   'audio_extensions': ('.m3u',\n",
       "    '.ram',\n",
       "    '.au',\n",
       "    '.snd',\n",
       "    '.mp3',\n",
       "    '.mp2',\n",
       "    '.aif',\n",
       "    '.aifc',\n",
       "    '.aiff',\n",
       "    '.ra',\n",
       "    '.wav',\n",
       "    '.amr',\n",
       "    '.awb',\n",
       "    '.axa',\n",
       "    '.csd',\n",
       "    '.orc',\n",
       "    '.sco',\n",
       "    '.flac',\n",
       "    '.mid',\n",
       "    '.midi',\n",
       "    '.kar',\n",
       "    '.mpga',\n",
       "    '.mpega',\n",
       "    '.m4a',\n",
       "    '.oga',\n",
       "    '.ogg',\n",
       "    '.opus',\n",
       "    '.spx',\n",
       "    '.sid',\n",
       "    '.gsm',\n",
       "    '.wma',\n",
       "    '.wax',\n",
       "    '.rm',\n",
       "    '.pls',\n",
       "    '.sd2'),\n",
       "   'AudioGetter': <function fastaudio.core.signal.AudioGetter(suf='', recurse=True, folders=None)>,\n",
       "   'tar_extract_at_filename': <function fastaudio.core.signal.tar_extract_at_filename(fname, dest)>,\n",
       "   'show_audio_signal': <function fastaudio.core.signal.show_audio_signal(ai, ctx, ax=None, title='', **kwargs)>,\n",
       "   'OpenAudio': fastaudio.core.signal.OpenAudio,\n",
       "   ...}},\n",
       " '_dh': ['/home/mizoru/ML/japanese-ml'],\n",
       " 'In': ['',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "  'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "  \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"p = Path('data/pitch_accent')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "  'import fastai\\nfastai.__version__',\n",
       "  'AudioConfig.Voice',\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "  'my_dict = object()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "  'd.__setattr__(b=b)',\n",
       "  'd.__setattr__(b,b)',\n",
       "  \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "  \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "  'locals()',\n",
       "  \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       " 'Out': {8:                                         path pattern  kana  morae  drop  \\\n",
       "  0       accentAudio/ある.yomi000142BB_0596.mp3      頭高    アル      2     1   \n",
       "  1       accentAudio/思う.yomi0006C617_043A.mp3      中高   オモウ      3     2   \n",
       "  2       accentAudio/など.yomi000240B7_0028.mp3      頭高    ナド      2     1   \n",
       "  3        accentAudio/私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0   \n",
       "  4       accentAudio/見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1   \n",
       "  ...                                      ...     ...   ...    ...   ...   \n",
       "  163962      OjadMedia/立て-377_10_1_female.mp3      頭高    たて      2     1   \n",
       "  163963       OjadMedia/立てる-377_11_1_male.mp3      中高   たてる      3     2   \n",
       "  163964     OjadMedia/立てる-377_11_1_female.mp3      中高   たてる      3     2   \n",
       "  163965       OjadMedia/立とう-377_12_1_male.mp3      中高   たとう      3     2   \n",
       "  163966     OjadMedia/立とう-377_12_1_female.mp3      中高   たとう      3     2   \n",
       "  \n",
       "                 type  \n",
       "  0               nhk  \n",
       "  1               nhk  \n",
       "  2               nhk  \n",
       "  3               nhk  \n",
       "  4               nhk  \n",
       "  ...             ...  \n",
       "  163962  ojad female  \n",
       "  163963    ojad male  \n",
       "  163964  ojad female  \n",
       "  163965    ojad male  \n",
       "  163966  ojad female  \n",
       "  \n",
       "  [163967 rows x 6 columns],\n",
       "  10:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  12:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  13:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  16:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  18:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  19:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  20:                                                      path pattern      kana  \\\n",
       "  0         ある-66_1_1_male.mp3dict1ある.yomi000142BB_0596.mp3    頭高頭高      あるアル   \n",
       "  1       ある-66_1_1_female.mp3dict1思う.yomi0006C617_043A.mp3    頭高中高     あるオモウ   \n",
       "  2       あります-66_2_1_male.mp3dict1など.yomi000240B7_0028.mp3    中高頭高    ありますナド   \n",
       "  3      あります-66_2_1_female.mp3dict1私.yomi00092F63_0072.mp3    中高平板  ありますワタくシ   \n",
       "  4        あって-66_3_1_male.mp3dict1見る.yomi000A41BD_001E.mp3    頭高頭高     あってミル   \n",
       "  ...                                                   ...     ...       ...   \n",
       "  84477                                                 NaN     NaN       NaN   \n",
       "  84478                                                 NaN     NaN       NaN   \n",
       "  84479                                                 NaN     NaN       NaN   \n",
       "  84480                                                 NaN     NaN       NaN   \n",
       "  84481                                                 NaN     NaN       NaN   \n",
       "  \n",
       "         morae  drop               type  \n",
       "  0        4.0   2.0    dict2 maledict1  \n",
       "  1        5.0   3.0  dict2 femaledict1  \n",
       "  2        6.0   4.0    dict2 maledict1  \n",
       "  3        8.0   3.0  dict2 femaledict1  \n",
       "  4        5.0   2.0    dict2 maledict1  \n",
       "  ...      ...   ...                ...  \n",
       "  84477    NaN   NaN                NaN  \n",
       "  84478    NaN   NaN                NaN  \n",
       "  84479    NaN   NaN                NaN  \n",
       "  84480    NaN   NaN                NaN  \n",
       "  84481    NaN   NaN                NaN  \n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  23:                                 path pattern  kana  morae  drop          type\n",
       "  0      dict1ある.yomi000142BB_0596.mp3      頭高    アル      2     1         dict1\n",
       "  1      dict1思う.yomi0006C617_043A.mp3      中高   オモウ      3     2         dict1\n",
       "  2      dict1など.yomi000240B7_0028.mp3      頭高    ナド      2     1         dict1\n",
       "  3       dict1私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0         dict1\n",
       "  4      dict1見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1         dict1\n",
       "  ...                              ...     ...   ...    ...   ...           ...\n",
       "  84477         立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478          立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479        立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480          立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481        立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [163966 rows x 6 columns],\n",
       "  24: '2.3.1',\n",
       "  25: types.Voice,\n",
       "  37: {'k': 3.0},\n",
       "  43: {'__name__': '__main__',\n",
       "   '__doc__': 'Automatically created module for IPython interactive environment',\n",
       "   '__package__': None,\n",
       "   '__loader__': None,\n",
       "   '__spec__': None,\n",
       "   '__builtin__': <module 'builtins' (built-in)>,\n",
       "   '__builtins__': <module 'builtins' (built-in)>,\n",
       "   '_ih': ['',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "    'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "    \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"p = Path('data/pitch_accent')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "    'import fastai\\nfastai.__version__',\n",
       "    'AudioConfig.Voice',\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "    'my_dict = object()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "    'd.__setattr__(b=b)',\n",
       "    'd.__setattr__(b,b)',\n",
       "    \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "    \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "    'locals()',\n",
       "    \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       "   '_oh': {...},\n",
       "   '_dh': ['/home/mizoru/ML/japanese-ml'],\n",
       "   'In': ['',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "    \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "    'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "    \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "    \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"p = Path('data/pitch_accent')\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "    \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "    'import fastai\\nfastai.__version__',\n",
       "    'AudioConfig.Voice',\n",
       "    \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "    'my_dict = object()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "    \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "    'd.__setattr__(b=b)',\n",
       "    'd.__setattr__(b,b)',\n",
       "    \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "    \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "    'locals()',\n",
       "    \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       "   'Out': {...},\n",
       "   'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f354f4bc590>>,\n",
       "   'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       "   'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       "   '_': {...},\n",
       "   '__': {'k': 3.0},\n",
       "   '___': types.Voice,\n",
       "   'os': <module 'os' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/os.py'>,\n",
       "   'sys': <module 'sys' (built-in)>,\n",
       "   '__vsc_ipynb_file__': '/home/mizoru/ML/japanese-ml/get_data.ipynb',\n",
       "   '_i': 'locals()',\n",
       "   '_ii': \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "   '_iii': \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "   '_i1': \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "   '_i2': 'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "   'models': <module 'fastai.vision.models' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/fastai/vision/models/__init__.py'>,\n",
       "   'multiprocessing': <module 'multiprocessing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/__init__.py'>,\n",
       "   'platform': <module 'platform' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/platform.py'>,\n",
       "   'np': <module 'numpy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/numpy/__init__.py'>,\n",
       "   'io': <module 'io' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/io.py'>,\n",
       "   'operator': <module 'operator' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/operator.py'>,\n",
       "   're': <module 're' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/re.py'>,\n",
       "   'mimetypes': <module 'mimetypes' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/mimetypes.py'>,\n",
       "   'csv': <module 'csv' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/csv.py'>,\n",
       "   'itertools': <module 'itertools' (built-in)>,\n",
       "   'json': <module 'json' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/json/__init__.py'>,\n",
       "   'shutil': <module 'shutil' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/shutil.py'>,\n",
       "   'glob': <module 'glob' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/glob.py'>,\n",
       "   'pickle': <module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>,\n",
       "   'tarfile': <module 'tarfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tarfile.py'>,\n",
       "   'collections': <module 'collections' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/collections/__init__.py'>,\n",
       "   'hashlib': <module 'hashlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/hashlib.py'>,\n",
       "   'types': <module 'types' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/types.py'>,\n",
       "   'inspect': <module 'inspect' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/inspect.py'>,\n",
       "   'functools': <module 'functools' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/functools.py'>,\n",
       "   'random': <module 'random' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/random.py'>,\n",
       "   'time': <module 'time' (built-in)>,\n",
       "   'math': <module 'math' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so'>,\n",
       "   'bz2': <module 'bz2' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/bz2.py'>,\n",
       "   'typing': <module 'typing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/typing.py'>,\n",
       "   'numbers': <module 'numbers' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/numbers.py'>,\n",
       "   'string': <module 'string' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/string.py'>,\n",
       "   'threading': <module 'threading' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/threading.py'>,\n",
       "   'urllib': <module 'urllib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/urllib/__init__.py'>,\n",
       "   'tempfile': <module 'tempfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tempfile.py'>,\n",
       "   'concurrent': <module 'concurrent' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/concurrent/__init__.py'>,\n",
       "   'matplotlib': <module 'matplotlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/__init__.py'>,\n",
       "   'warnings': <module 'warnings' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/warnings.py'>,\n",
       "   'zipfile': <module 'zipfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/zipfile.py'>,\n",
       "   'as_completed': <function concurrent.futures._base.as_completed(fs, timeout=None)>,\n",
       "   'partial': functools.partial,\n",
       "   'reduce': <function _functools.reduce>,\n",
       "   'starmap': itertools.starmap,\n",
       "   'dropwhile': itertools.dropwhile,\n",
       "   'takewhile': itertools.takewhile,\n",
       "   'zip_longest': itertools.zip_longest,\n",
       "   'copy': <function copy.copy(x)>,\n",
       "   'deepcopy': <function copy.deepcopy(x, memo=None, _nil=[])>,\n",
       "   'Lock': <bound method BaseContext.Lock of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       "   'Process': multiprocessing.context.Process,\n",
       "   'Queue': <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       "   'queues': <module 'multiprocessing.queues' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/queues.py'>,\n",
       "   'datetime': datetime.datetime,\n",
       "   'redirect_stdout': contextlib.redirect_stdout,\n",
       "   'contextmanager': <function contextlib.contextmanager(func)>,\n",
       "   'Iterable': typing.Iterable,\n",
       "   'Iterator': typing.Iterator,\n",
       "   'Generator': typing.Generator,\n",
       "   'Sequence': typing.Sequence,\n",
       "   'Union': typing.Union,\n",
       "   'Optional': typing.Optional,\n",
       "   'SimpleNamespace': types.SimpleNamespace,\n",
       "   'Path': pathlib.Path,\n",
       "   'OrderedDict': collections.OrderedDict,\n",
       "   'defaultdict': collections.defaultdict,\n",
       "   'Counter': collections.Counter,\n",
       "   'namedtuple': <function collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)>,\n",
       "   'Enum': <enum 'Enum'>,\n",
       "   'IntEnum': <enum 'IntEnum'>,\n",
       "   'TextWrapper': textwrap.TextWrapper,\n",
       "   'itemgetter': operator.itemgetter,\n",
       "   'attrgetter': operator.attrgetter,\n",
       "   'methodcaller': operator.methodcaller,\n",
       "   'urlopen': <function fastcore.net.urlopen(url, data=None, headers=None, **kwargs)>,\n",
       "   'requests': <module 'requests' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/requests/__init__.py'>,\n",
       "   'yaml': <module 'yaml' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/yaml/__init__.py'>,\n",
       "   'plt': <module 'matplotlib.pyplot' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/pyplot.py'>,\n",
       "   'pd': <module 'pandas' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/pandas/__init__.py'>,\n",
       "   'scipy': <module 'scipy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/__init__.py'>,\n",
       "   'is_categorical_dtype': <function pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype) -> 'bool'>,\n",
       "   'is_numeric_dtype': <function pandas.core.dtypes.common.is_numeric_dtype(arr_or_dtype) -> 'bool'>,\n",
       "   'array': <function numpy.array>,\n",
       "   'ndarray': numpy.ndarray,\n",
       "   'ndimage': <module 'scipy.ndimage' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/ndimage/__init__.py'>,\n",
       "   'set_trace': <function IPython.core.debugger.set_trace(frame=None)>,\n",
       "   'enum': <module 'enum' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/enum.py'>,\n",
       "   'warn': <function _warnings.warn(message, category=None, stacklevel=1, source=None)>,\n",
       "   'WrapperDescriptorType': wrapper_descriptor,\n",
       "   'MethodWrapperType': method-wrapper,\n",
       "   'MethodDescriptorType': method_descriptor,\n",
       "   'BuiltinFunctionType': builtin_function_or_method,\n",
       "   'BuiltinMethodType': builtin_function_or_method,\n",
       "   'MethodType': method,\n",
       "   'FunctionType': function,\n",
       "   'NoneType': NoneType,\n",
       "   'string_classes': (str, bytes),\n",
       "   'is_iter': <function fastai.imports.is_iter(o)>,\n",
       "   'is_coll': <function fastai.imports.is_coll(o)>,\n",
       "   'all_equal': <function fastai.imports.all_equal(a, b)>,\n",
       "   'noop': <function fastai.imports.noop(x=None, *args, **kwargs)>,\n",
       "   'noops': <function fastai.imports.noops(self, x=None, *args, **kwargs)>,\n",
       "   'any_is_instance': <function fastcore.imports.any_is_instance(t, *args)>,\n",
       "   'isinstance_str': <function fastcore.imports.isinstance_str(x, cls_name)>,\n",
       "   'array_equal': <function fastcore.imports.array_equal(a, b)>,\n",
       "   'df_equal': <function fastcore.imports.df_equal(a, b)>,\n",
       "   'equals': <function fastai.imports.equals(a, b)>,\n",
       "   'ipython_shell': <function fastcore.imports.ipython_shell()>,\n",
       "   'in_ipython': <function fastcore.imports.in_ipython()>,\n",
       "   'in_colab': <function fastcore.imports.in_colab()>,\n",
       "   'in_jupyter': <function fastcore.imports.in_jupyter()>,\n",
       "   'in_notebook': <function fastcore.imports.in_notebook()>,\n",
       "   'IN_IPYTHON': True,\n",
       "   'IN_JUPYTER': True,\n",
       "   'IN_COLAB': False,\n",
       "   'IN_NOTEBOOK': True,\n",
       "   'remove_prefix': <function fastcore.imports.remove_prefix(text, prefix)>,\n",
       "   'remove_suffix': <function fastcore.imports.remove_suffix(text, suffix)>,\n",
       "   'working_directory': <function fastcore.foundation.working_directory(path)>,\n",
       "   'add_docs': <function fastcore.foundation.add_docs(cls, cls_doc=None, **docs)>,\n",
       "   'docs': <function fastcore.foundation.docs(cls)>,\n",
       "   'coll_repr': <function fastcore.foundation.coll_repr(c, max_n=10)>,\n",
       "   'is_bool': <function fastcore.foundation.is_bool(x)>,\n",
       "   'mask2idxs': <function fastcore.foundation.mask2idxs(mask)>,\n",
       "   'cycle': <function fastcore.basics.cycle(o)>,\n",
       "   'zip_cycle': <function fastcore.basics.zip_cycle(x, *args)>,\n",
       "   'is_indexer': <function fastcore.foundation.is_indexer(idx)>,\n",
       "   'CollBase': fastcore.foundation.CollBase,\n",
       "   'L': fastcore.foundation.L,\n",
       "   'save_config_file': <function fastcore.foundation.save_config_file(file, d, **kwargs)>,\n",
       "   'read_config_file': <function fastcore.foundation.read_config_file(file, **kwargs)>,\n",
       "   'Config': fastai.data.external.Config,\n",
       "   'lenient_issubclass': <function fastcore.dispatch.lenient_issubclass(cls, types)>,\n",
       "   'sorted_topologically': <function fastcore.dispatch.sorted_topologically(iterable, *, cmp=<built-in function lt>, reverse=False)>,\n",
       "   'TypeDispatch': fastcore.dispatch.TypeDispatch,\n",
       "   'DispatchReg': fastcore.dispatch.DispatchReg,\n",
       "   'typedispatch': <fastcore.dispatch.DispatchReg at 0x7f34c6df11d0>,\n",
       "   'cast': (object,object) -> cast,\n",
       "   'retain_meta': <function fastcore.dispatch.retain_meta(x, res, as_copy=False)>,\n",
       "   'default_set_meta': <function fastcore.dispatch.default_set_meta(self, x, as_copy=False)>,\n",
       "   'retain_type': <function fastcore.dispatch.retain_type(new, old=None, typ=None, as_copy=False)>,\n",
       "   'retain_types': <function fastcore.dispatch.retain_types(new, old=None, typs=None)>,\n",
       "   'explode_types': <function fastcore.dispatch.explode_types(o)>,\n",
       "   'test_fail': <function fastcore.test.test_fail(f, msg='', contains='', args=None, kwargs=None)>,\n",
       "   'test': <function fastcore.test.test(a, b, cmp, cname=None)>,\n",
       "   'nequals': <function fastcore.test.nequals(a, b)>,\n",
       "   'test_eq': <function fastcore.test.test_eq(a, b)>,\n",
       "   'test_eq_type': <function fastcore.test.test_eq_type(a, b)>,\n",
       "   'test_ne': <function fastcore.test.test_ne(a, b)>,\n",
       "   'is_close': <function fastcore.test.is_close(a, b, eps=1e-05)>,\n",
       "   'test_close': <function fastcore.test.test_close(a, b, eps=1e-05)>,\n",
       "   'test_is': <function fastcore.test.test_is(a, b)>,\n",
       "   'test_shuffled': <function fastcore.test.test_shuffled(a, b)>,\n",
       "   'test_stdout': <function fastcore.test.test_stdout(f, exp, regex=False)>,\n",
       "   'test_warns': <function fastcore.test.test_warns(f, show=False)>,\n",
       "   'TEST_IMAGE': 'images/puppy.jpg',\n",
       "   'TEST_IMAGE_BW': 'images/mnist3.png',\n",
       "   'test_fig_exists': <function fastcore.test.test_fig_exists(ax)>,\n",
       "   'ExceptionExpected': fastcore.test.ExceptionExpected,\n",
       "   'exception': <fastcore.test.ExceptionExpected at 0x7f34c0dcc550>,\n",
       "   'defaults': namespace(cpus=4,\n",
       "             use_cuda=None,\n",
       "             activation=torch.nn.modules.activation.ReLU,\n",
       "             callbacks=[fastai.callback.core.TrainEvalCallback,\n",
       "                        fastai.learner.Recorder,\n",
       "                        fastai.callback.progress.ProgressCallback],\n",
       "             lr=0.001),\n",
       "   'ifnone': <function fastcore.basics.ifnone(a, b)>,\n",
       "   'maybe_attr': <function fastcore.basics.maybe_attr(o, attr)>,\n",
       "   'basic_repr': <function fastcore.basics.basic_repr(flds=None)>,\n",
       "   'is_array': <function fastcore.basics.is_array(x)>,\n",
       "   'listify': <function fastcore.basics.listify(o=None, *rest, use_list=False, match=None)>,\n",
       "   'tuplify': <function fastcore.basics.tuplify(o, use_list=False, match=None)>,\n",
       "   'true': <function fastcore.basics.true(*args, **kwargs)>,\n",
       "   'NullType': fastcore.basics.NullType,\n",
       "   'null': <fastcore.basics.NullType at 0x7f34c0e2dbd0>,\n",
       "   'tonull': <function fastcore.basics.tonull(x)>,\n",
       "   'get_class': <function fastcore.basics.get_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       "   'mk_class': <function fastcore.basics.mk_class(nm, *fld_names, sup=None, doc=None, funcs=None, mod=None, **flds)>,\n",
       "   'wrap_class': <function fastcore.basics.wrap_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       "   'ignore_exceptions': fastcore.basics.ignore_exceptions,\n",
       "   'exec_local': <function fastcore.basics.exec_local(code, var_name)>,\n",
       "   'risinstance': <function fastcore.basics.risinstance(types, obj=None)>,\n",
       "   'Inf': fastcore.basics.Inf,\n",
       "   'in_': <function fastcore.basics.in_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'lt': <function fastcore.basics.lt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'gt': <function fastcore.basics.gt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'le': <function fastcore.basics.le(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'ge': <function fastcore.basics.ge(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'eq': <function fastcore.basics.eq(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'ne': <function fastcore.basics.ne(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'add': <function fastcore.basics.add(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'sub': <function fastcore.basics.sub(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'mul': <function fastcore.basics.mul(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'truediv': <function fastcore.basics.truediv(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'is_': <function fastcore.basics.is_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'is_not': <function fastcore.basics.is_not(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "   'stop': <function fastcore.basics.stop(e=<class 'StopIteration'>)>,\n",
       "   'gen': <function fastcore.basics.gen(func, seq, cond=<function true at 0x7f34c0e30e60>)>,\n",
       "   'chunked': <function fastcore.basics.chunked(it, chunk_sz=None, drop_last=False, n_chunks=None)>,\n",
       "   'otherwise': <function fastcore.basics.otherwise(x, tst, y)>,\n",
       "   'custom_dir': <function fastcore.basics.custom_dir(c, add)>,\n",
       "   'AttrDict': fastcore.basics.AttrDict,\n",
       "   'type_hints': <function fastcore.basics.type_hints(f)>,\n",
       "   'annotations': <function fastcore.basics.annotations(o)>,\n",
       "   'anno_ret': <function fastcore.basics.anno_ret(func)>,\n",
       "   'argnames': <function fastcore.basics.argnames(f, frame=False)>,\n",
       "   'with_cast': <function fastcore.basics.with_cast(f)>,\n",
       "   'store_attr': <function fastcore.basics.store_attr(names=None, self=None, but='', cast=False, store_args=None, **attrs)>,\n",
       "   'attrdict': <function fastcore.basics.attrdict(o, *ks, default=None)>,\n",
       "   'properties': <function fastcore.basics.properties(cls, *ps)>,\n",
       "   'camel2words': <function fastcore.basics.camel2words(s, space=' ')>,\n",
       "   'camel2snake': <function fastcore.basics.camel2snake(name)>,\n",
       "   'snake2camel': <function fastcore.basics.snake2camel(s)>,\n",
       "   'class2attr': <function fastcore.basics.class2attr(self, cls_name)>,\n",
       "   'getattrs': <function fastcore.basics.getattrs(o, *attrs, default=None)>,\n",
       "   'hasattrs': <function fastcore.basics.hasattrs(o, attrs)>,\n",
       "   'setattrs': <function fastcore.basics.setattrs(dest, flds, src)>,\n",
       "   'try_attrs': <function fastcore.basics.try_attrs(obj, *attrs)>,\n",
       "   'GetAttrBase': fastcore.basics.GetAttrBase,\n",
       "   'GetAttr': fastcore.basics.GetAttr,\n",
       "   'delegate_attr': <function fastcore.basics.delegate_attr(self, k, to)>,\n",
       "   'ShowPrint': fastcore.basics.ShowPrint,\n",
       "   'Int': fastcore.basics.Int,\n",
       "   'Str': fastcore.basics.Str,\n",
       "   'Float': fastcore.basics.Float,\n",
       "   'concat': <function fastai.torch_core.concat(*ls)>,\n",
       "   'strcat': <function fastcore.basics.strcat(its, sep: str = '') -> str>,\n",
       "   'detuplify': <function fastcore.basics.detuplify(x)>,\n",
       "   'replicate': <function fastcore.basics.replicate(item, match)>,\n",
       "   'setify': <function fastcore.basics.setify(o)>,\n",
       "   'merge': <function fastcore.basics.merge(*ds)>,\n",
       "   'range_of': <function fastcore.basics.range_of(a, b=None, step=None)>,\n",
       "   'groupby': <function fastcore.basics.groupby(x, key, val=<function noop at 0x7f34c0dfed40>)>,\n",
       "   'last_index': <function fastcore.basics.last_index(x, o)>,\n",
       "   'filter_dict': <function fastcore.basics.filter_dict(d, func)>,\n",
       "   'filter_keys': <function fastcore.basics.filter_keys(d, func)>,\n",
       "   'filter_values': <function fastcore.basics.filter_values(d, func)>,\n",
       "   'sorted_ex': <function fastcore.basics.sorted_ex(iterable, key=None, reverse=False)>,\n",
       "   'not_': <function fastcore.basics.not_(f)>,\n",
       "   'argwhere': <function fastcore.basics.argwhere(iterable, f, negate=False, **kwargs)>,\n",
       "   'filter_ex': <function fastcore.basics.filter_ex(iterable, f=<function noop at 0x7f34c0dfed40>, negate=False, gen=False, **kwargs)>,\n",
       "   'renumerate': <function fastcore.basics.renumerate(iterable, start=0)>,\n",
       "   'first': <function fastcore.basics.first(x, f=None, negate=False, **kwargs)>,\n",
       "   'nested_attr': <function fastcore.basics.nested_attr(o, attr, default=None)>,\n",
       "   'nested_idx': <function fastcore.basics.nested_idx(coll, *idxs)>,\n",
       "   'val2idx': <function fastcore.basics.val2idx(x)>,\n",
       "   'uniqueify': <function fastcore.basics.uniqueify(x, sort=False, bidir=False, start=None)>,\n",
       "   'num_methods': ['__add__',\n",
       "    '__sub__',\n",
       "    '__mul__',\n",
       "    '__matmul__',\n",
       "    '__truediv__',\n",
       "    '__floordiv__',\n",
       "    '__mod__',\n",
       "    '__divmod__',\n",
       "    '__pow__',\n",
       "    '__lshift__',\n",
       "    '__rshift__',\n",
       "    '__and__',\n",
       "    '__xor__',\n",
       "    '__or__',\n",
       "    '__neg__',\n",
       "    '__pos__',\n",
       "    '__abs__'],\n",
       "   'rnum_methods': ['__radd__',\n",
       "    '__rsub__',\n",
       "    '__rmul__',\n",
       "    '__rmatmul__',\n",
       "    '__rtruediv__',\n",
       "    '__rfloordiv__',\n",
       "    '__rmod__',\n",
       "    '__rdivmod__',\n",
       "    '__rpow__',\n",
       "    '__rlshift__',\n",
       "    '__rrshift__',\n",
       "    '__rand__',\n",
       "    '__rxor__',\n",
       "    '__ror__'],\n",
       "   'inum_methods': ['__iadd__',\n",
       "    '__isub__',\n",
       "    '__imul__',\n",
       "    '__imatmul__',\n",
       "    '__itruediv__',\n",
       "    '__ifloordiv__',\n",
       "    '__imod__',\n",
       "    '__ipow__',\n",
       "    '__ilshift__',\n",
       "    '__irshift__',\n",
       "    '__iand__',\n",
       "    '__ixor__',\n",
       "    '__ior__'],\n",
       "   'fastuple': fastcore.basics.fastuple,\n",
       "   'arg0': <fastcore.basics._Arg at 0x7f34c0dbc410>,\n",
       "   'arg1': <fastcore.basics._Arg at 0x7f34c0dbc450>,\n",
       "   'arg2': <fastcore.basics._Arg at 0x7f34c0dbc490>,\n",
       "   'arg3': <fastcore.basics._Arg at 0x7f34c0dbc4d0>,\n",
       "   'arg4': <fastcore.basics._Arg at 0x7f34c0dbc510>,\n",
       "   'bind': fastcore.basics.bind,\n",
       "   'mapt': <function fastcore.basics.mapt(func, *iterables)>,\n",
       "   'map_ex': <function fastcore.basics.map_ex(iterable, f, *args, gen=False, **kwargs)>,\n",
       "   'compose': <function fastcore.basics.compose(*funcs, order=None)>,\n",
       "   'maps': <function fastcore.basics.maps(*args, retain=<function noop at 0x7f34c0dfed40>)>,\n",
       "   'partialler': <function fastcore.basics.partialler(f, *args, order=None, **kwargs)>,\n",
       "   'instantiate': <function fastcore.basics.instantiate(t)>,\n",
       "   'using_attr': <function fastcore.basics.using_attr(f, attr)>,\n",
       "   'Self': <fastcore.basics._SelfCls at 0x7f34c0dbc5d0>,\n",
       "   'copy_func': <function fastcore.basics.copy_func(f)>,\n",
       "   'patch_to': <function fastcore.basics.patch_to(cls, as_prop=False, cls_method=False)>,\n",
       "   'patch': <function fastcore.basics.patch(f=None, *, as_prop=False, cls_method=False)>,\n",
       "   'patch_property': <function fastcore.basics.patch_property(f)>,\n",
       "   'ImportEnum': <enum 'ImportEnum'>,\n",
       "   'StrEnum': <enum 'StrEnum'>,\n",
       "   'str_enum': <function fastcore.basics.str_enum(name, *vals)>,\n",
       "   'Stateful': fastcore.basics.Stateful,\n",
       "   'PrettyString': fastcore.basics.PrettyString,\n",
       "   'even_mults': <function fastcore.basics.even_mults(start, stop, n)>,\n",
       "   'num_cpus': <function fastcore.basics.num_cpus()>,\n",
       "   'add_props': <function fastcore.basics.add_props(f, g=None, n=2)>,\n",
       "   'typed': <function fastcore.basics.typed(f)>,\n",
       "   'dict2obj': <function fastcore.xtras.dict2obj(d)>,\n",
       "   'obj2dict': <function fastcore.xtras.obj2dict(d)>,\n",
       "   'repr_dict': <function fastcore.xtras.repr_dict(d)>,\n",
       "   'is_listy': <function fastcore.xtras.is_listy(x)>,\n",
       "   'shufflish': <function fastcore.xtras.shufflish(x, pct=0.04)>,\n",
       "   'mapped': <function fastcore.xtras.mapped(f, it)>,\n",
       "   'IterLen': fastcore.xtras.IterLen,\n",
       "   'ReindexCollection': fastcore.xtras.ReindexCollection,\n",
       "   'maybe_open': <function fastcore.xtras.maybe_open(f, mode='r', **kwargs)>,\n",
       "   'image_size': <function fastcore.xtras.image_size(fn)>,\n",
       "   'bunzip': <function fastcore.xtras.bunzip(fn)>,\n",
       "   'join_path_file': <function fastcore.xtras.join_path_file(file, path, ext='')>,\n",
       "   'loads': <function fastcore.xtras.loads(s, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)>,\n",
       "   'loads_multi': <function fastcore.xtras.loads_multi(s: str)>,\n",
       "   'untar_dir': <function fastcore.xtras.untar_dir(file, dest)>,\n",
       "   'repo_details': <function fastcore.xtras.repo_details(url)>,\n",
       "   'run': <function fastcore.xtras.run(cmd, *rest, same_in_win=False, ignore_ex=False, as_bytes=False, stderr=False)>,\n",
       "   'open_file': <function fastcore.xtras.open_file(fn, mode='r', **kwargs)>,\n",
       "   'save_pickle': <function fastcore.xtras.save_pickle(fn, o)>,\n",
       "   'load_pickle': <function fastcore.xtras.load_pickle(fn)>,\n",
       "   'truncstr': <function fastcore.xtras.truncstr(s: str, maxlen: int, suf: str = '…', space='') -> str>,\n",
       "   'spark_chars': '▁▂▃▅▆▇',\n",
       "   'sparkline': <function fastcore.xtras.sparkline(data, mn=None, mx=None, empty_zero=False)>,\n",
       "   'autostart': <function fastcore.xtras.autostart(g)>,\n",
       "   'EventTimer': fastcore.xtras.EventTimer,\n",
       "   'stringfmt_names': <function fastcore.xtras.stringfmt_names(s: str) -> list>,\n",
       "   'PartialFormatter': fastcore.xtras.PartialFormatter,\n",
       "   'partial_format': <function fastcore.xtras.partial_format(s: str, **kwargs)>,\n",
       "   'utc2local': <function fastcore.xtras.utc2local(dt: datetime.datetime) -> datetime.datetime>,\n",
       "   'local2utc': <function fastcore.xtras.local2utc(dt: datetime.datetime) -> datetime.datetime>,\n",
       "   'trace': <function fastcore.xtras.trace(f)>,\n",
       "   'round_multiple': <function fastcore.xtras.round_multiple(x, mult, round_down=False)>,\n",
       "   'modified_env': <function fastcore.xtras.modified_env(*delete, **replace)>,\n",
       "   'ContextManagers': fastcore.xtras.ContextManagers,\n",
       "   'str2bool': <function fastcore.xtras.str2bool(s)>,\n",
       "   'sort_by_run': <function fastcore.xtras.sort_by_run(fs)>,\n",
       "   'threaded': <function fastcore.parallel.threaded(f)>,\n",
       "   'startthread': <function fastcore.parallel.startthread(f)>,\n",
       "   'set_num_threads': <function fastcore.parallel.set_num_threads(nt)>,\n",
       "   'parallelable': <function fastcore.parallel.parallelable(param_name, num_workers, f=None)>,\n",
       "   'ThreadPoolExecutor': fastcore.parallel.ThreadPoolExecutor,\n",
       "   'ProcessPoolExecutor': fastcore.parallel.ProcessPoolExecutor,\n",
       "   'parallel': <function fastcore.parallel.parallel(f, items, *args, n_workers=4, total=None, progress=None, pause=0, threadpool=False, timeout=None, chunksize=1, **kwargs)>,\n",
       "   'add_one': <function fastcore.parallel.add_one(x, a=1)>,\n",
       "   'run_procs': <function fastcore.parallel.run_procs(f, f_done, args)>,\n",
       "   'parallel_gen': <function fastcore.parallel.parallel_gen(cls, items, n_workers=4, **kwargs)>,\n",
       "   'url_default_headers': {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
       "    'Accept-Language': 'en-US,en;q=0.9',\n",
       "    'Cache-Control': 'max-age=0',\n",
       "    'Sec-Fetch-Dest': 'document',\n",
       "    'Sec-Fetch-Mode': 'navigate',\n",
       "    'Sec-Fetch-Site': 'none',\n",
       "    'Sec-Fetch-User': '?1',\n",
       "    'Upgrade-Insecure-Requests': '1',\n",
       "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'},\n",
       "   'urlquote': <function fastcore.net.urlquote(url)>,\n",
       "   'urlwrap': <function fastcore.net.urlwrap(url, data=None, headers=None)>,\n",
       "   'ExceptionsHTTP': {400: fastcore.basics.HTTP400BadRequestError,\n",
       "    401: fastcore.basics.HTTP401UnauthorizedError,\n",
       "    402: fastcore.basics.HTTP402PaymentRequiredError,\n",
       "    403: fastcore.basics.HTTP403ForbiddenError,\n",
       "    404: fastcore.basics.HTTP404NotFoundError,\n",
       "    405: fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "    406: fastcore.basics.HTTP406NotAcceptableError,\n",
       "    407: fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "    408: fastcore.basics.HTTP408RequestTimeoutError,\n",
       "    409: fastcore.basics.HTTP409ConflictError,\n",
       "    410: fastcore.basics.HTTP410GoneError,\n",
       "    411: fastcore.basics.HTTP411LengthRequiredError,\n",
       "    412: fastcore.basics.HTTP412PreconditionFailedError,\n",
       "    413: fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "    414: fastcore.basics.HTTP414URITooLongError,\n",
       "    415: fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "    416: fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "    417: fastcore.basics.HTTP417ExpectationFailedError,\n",
       "    418: fastcore.basics.HTTP418AmAteapotError,\n",
       "    421: fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "    422: fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "    423: fastcore.basics.HTTP423LockedError,\n",
       "    424: fastcore.basics.HTTP424FailedDependencyError,\n",
       "    425: fastcore.basics.HTTP425TooEarlyError,\n",
       "    426: fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "    428: fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "    429: fastcore.basics.HTTP429TooManyRequestsError,\n",
       "    431: fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "    451: fastcore.basics.HTTP451LegalReasonsError},\n",
       "   'HTTP4xxClientError': fastcore.net.HTTP4xxClientError,\n",
       "   'HTTP5xxServerError': fastcore.net.HTTP5xxServerError,\n",
       "   'HTTP400BadRequestError': fastcore.basics.HTTP400BadRequestError,\n",
       "   'HTTP401UnauthorizedError': fastcore.basics.HTTP401UnauthorizedError,\n",
       "   'HTTP402PaymentRequiredError': fastcore.basics.HTTP402PaymentRequiredError,\n",
       "   'HTTP403ForbiddenError': fastcore.basics.HTTP403ForbiddenError,\n",
       "   'HTTP404NotFoundError': fastcore.basics.HTTP404NotFoundError,\n",
       "   'HTTP405MethodNotAllowedError': fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "   'HTTP406NotAcceptableError': fastcore.basics.HTTP406NotAcceptableError,\n",
       "   'HTTP407ProxyAuthRequiredError': fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "   'HTTP408RequestTimeoutError': fastcore.basics.HTTP408RequestTimeoutError,\n",
       "   'HTTP409ConflictError': fastcore.basics.HTTP409ConflictError,\n",
       "   'HTTP410GoneError': fastcore.basics.HTTP410GoneError,\n",
       "   'HTTP411LengthRequiredError': fastcore.basics.HTTP411LengthRequiredError,\n",
       "   'HTTP412PreconditionFailedError': fastcore.basics.HTTP412PreconditionFailedError,\n",
       "   'HTTP413PayloadTooLargeError': fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "   'HTTP414URITooLongError': fastcore.basics.HTTP414URITooLongError,\n",
       "   'HTTP415UnsupportedMediaTypeError': fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "   'HTTP416RangeNotSatisfiableError': fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "   'HTTP417ExpectationFailedError': fastcore.basics.HTTP417ExpectationFailedError,\n",
       "   'HTTP418AmAteapotError': fastcore.basics.HTTP418AmAteapotError,\n",
       "   'HTTP421MisdirectedRequestError': fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "   'HTTP422UnprocessableEntityError': fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "   'HTTP423LockedError': fastcore.basics.HTTP423LockedError,\n",
       "   'HTTP424FailedDependencyError': fastcore.basics.HTTP424FailedDependencyError,\n",
       "   'HTTP425TooEarlyError': fastcore.basics.HTTP425TooEarlyError,\n",
       "   'HTTP426UpgradeRequiredError': fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "   'HTTP428PreconditionRequiredError': fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "   'HTTP429TooManyRequestsError': fastcore.basics.HTTP429TooManyRequestsError,\n",
       "   'HTTP431HeaderFieldsTooLargeError': fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "   'HTTP451LegalReasonsError': fastcore.basics.HTTP451LegalReasonsError,\n",
       "   'urlread': <function fastcore.net.urlread(url, data=None, headers=None, decode=True, return_json=False, return_headers=False, **kwargs)>,\n",
       "   'urljson': <function fastcore.net.urljson(url, data=None)>,\n",
       "   'urlcheck': <function fastcore.net.urlcheck(url, timeout=10)>,\n",
       "   'urlclean': <function fastcore.net.urlclean(url)>,\n",
       "   'urlsave': <function fastcore.net.urlsave(url, dest=None)>,\n",
       "   'urlvalid': <function fastcore.net.urlvalid(x)>,\n",
       "   'urlrequest': <function fastcore.net.urlrequest(url, verb, headers=None, route=None, query=None, data=None, json_data=True)>,\n",
       "   'urlsend': <function fastcore.net.urlsend(url, verb, headers=None, route=None, query=None, data=None, json_data=True, return_json=True, return_headers=False, debug=None)>,\n",
       "   'do_request': <function fastcore.net.do_request(url, post=False, headers=None, **data)>,\n",
       "   'start_server': <function fastcore.net.start_server(port, host=None, dgram=False, reuse_addr=True, n_queue=None)>,\n",
       "   'start_client': <function fastcore.net.start_client(port, host=None, dgram=False)>,\n",
       "   'Transform': fastcore.transform.Transform,\n",
       "   'InplaceTransform': fastcore.transform.InplaceTransform,\n",
       "   'DisplayedTransform': fastcore.transform.DisplayedTransform,\n",
       "   'ItemTransform': fastcore.transform.ItemTransform,\n",
       "   'get_func': <function fastcore.transform.get_func(t, name, *args, **kwargs)>,\n",
       "   'Func': fastcore.transform.Func,\n",
       "   'Sig': <fastcore.transform._Sig at 0x7f34c0d37590>,\n",
       "   'compose_tfms': <function fastcore.transform.compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs)>,\n",
       "   'mk_transform': <function fastcore.transform.mk_transform(f)>,\n",
       "   'gather_attrs': <function fastcore.transform.gather_attrs(o, k, nm)>,\n",
       "   'gather_attr_names': <function fastcore.transform.gather_attr_names(o, nm)>,\n",
       "   'Pipeline': fastcore.transform.Pipeline,\n",
       "   'test_sig': <function fastcore.meta.test_sig(f, b)>,\n",
       "   'FixSigMeta': fastcore.meta.FixSigMeta,\n",
       "   'PrePostInitMeta': fastcore.meta.PrePostInitMeta,\n",
       "   'AutoInit': fastcore.meta.AutoInit,\n",
       "   'NewChkMeta': fastcore.meta.NewChkMeta,\n",
       "   'BypassNewMeta': fastcore.meta.BypassNewMeta,\n",
       "   'empty2none': <function fastcore.meta.empty2none(p)>,\n",
       "   'anno_dict': <function fastcore.meta.anno_dict(f)>,\n",
       "   'use_kwargs_dict': <function fastcore.meta.use_kwargs_dict(keep=False, **kwargs)>,\n",
       "   'use_kwargs': <function fastcore.meta.use_kwargs(names, keep=False)>,\n",
       "   'delegates': <function fastcore.meta.delegates(to=None, keep=False, but=None)>,\n",
       "   'method': <function fastcore.meta.method(f)>,\n",
       "   'funcs_kwargs': <function fastcore.meta.funcs_kwargs(as_method=False)>,\n",
       "   'store_true': <function fastcore.script.store_true()>,\n",
       "   'store_false': <function fastcore.script.store_false()>,\n",
       "   'bool_arg': <function fastcore.script.bool_arg(v)>,\n",
       "   'clean_type_str': <function fastcore.script.clean_type_str(x: str)>,\n",
       "   'Param': fastcore.script.Param,\n",
       "   'anno_parser': <function fastcore.script.anno_parser(func, prog=None, from_name=False)>,\n",
       "   'args_from_prog': <function fastcore.script.args_from_prog(func, prog)>,\n",
       "   'SCRIPT_INFO': namespace(func=None),\n",
       "   'call_parse': <function fastcore.script.call_parse(func)>,\n",
       "   'progress_bar': fastprogress.fastprogress.NBProgressBar,\n",
       "   'master_bar': fastprogress.fastprogress.NBMasterBar,\n",
       "   'LambdaType': function,\n",
       "   'one_is_instance': <function fastai.imports.one_is_instance(a, b, t)>,\n",
       "   'pv': <function fastai.imports.pv(text, verbose)>,\n",
       "   'torch': <module 'torch' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/__init__.py'>,\n",
       "   'as_tensor': <function _VariableFunctionsClass.as_tensor>,\n",
       "   'Tensor': torch.Tensor,\n",
       "   'ByteTensor': torch.ByteTensor,\n",
       "   'LongTensor': torch.LongTensor,\n",
       "   'FloatTensor': torch.FloatTensor,\n",
       "   'HalfTensor': torch.HalfTensor,\n",
       "   'DoubleTensor': torch.DoubleTensor,\n",
       "   'nn': <module 'torch.nn' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/__init__.py'>,\n",
       "   'F': <module 'torch.nn.functional' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/functional.py'>,\n",
       "   'SequentialSampler': torch.utils.data.sampler.SequentialSampler,\n",
       "   'RandomSampler': torch.utils.data.sampler.RandomSampler,\n",
       "   'Sampler': torch.utils.data.sampler.Sampler,\n",
       "   'BatchSampler': torch.utils.data.sampler.BatchSampler,\n",
       "   'IterableDataset': torch.utils.data.dataset.IterableDataset,\n",
       "   'get_worker_info': <function torch.utils.data._utils.worker.get_worker_info()>,\n",
       "   'default_collate': <function torch.utils.data._utils.collate.default_collate(batch)>,\n",
       "   'default_convert': <function torch.utils.data._utils.collate.default_convert(data)>,\n",
       "   'subplots': <function fastai.torch_core.subplots(nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **kwargs)>,\n",
       "   'show_image': <function fastai.torch_core.show_image(im, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       "   'show_titled_image': <function fastai.torch_core.show_titled_image(o, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       "   'show_images': <function fastai.torch_core.show_images(ims, nrows=1, ncols=None, titles=None, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       "   'ArrayBase': fastai.torch_core.ArrayBase,\n",
       "   'ArrayImageBase': fastai.torch_core.ArrayImageBase,\n",
       "   'ArrayImage': fastai.torch_core.ArrayImage,\n",
       "   'ArrayImageBW': fastai.torch_core.ArrayImageBW,\n",
       "   'ArrayMask': fastai.torch_core.ArrayMask,\n",
       "   'tensor': <function fastai.torch_core.tensor(x, *rest, dtype=None, device=None, requires_grad=False, pin_memory=False)>,\n",
       "   'set_seed': <function fastai.torch_core.set_seed(s, reproducible=False)>,\n",
       "   'get_random_states': <function fastai.torch_core.get_random_states()>,\n",
       "   'set_random_states': <function fastai.torch_core.set_random_states(random_state, numpy_state, torch_state, torch_cuda_state, torch_deterministic, torch_benchmark)>,\n",
       "   'no_random': <function fastai.torch_core.no_random(seed=42, reproducible=True)>,\n",
       "   'unsqueeze': <function fastai.torch_core.unsqueeze(x, dim=-1, n=1)>,\n",
       "   'unsqueeze_': <function fastai.torch_core.unsqueeze_(x, dim=-1, n=1)>,\n",
       "   'apply': <function fastai.torch_core.apply(func, x, *args, **kwargs)>,\n",
       "   'maybe_gather': <function fastai.torch_core.maybe_gather(x, axis=0)>,\n",
       "   'to_detach': <function fastai.torch_core.to_detach(b, cpu=True, gather=True)>,\n",
       "   'to_half': <function fastai.torch_core.to_half(b)>,\n",
       "   'to_float': <function fastai.torch_core.to_float(b)>,\n",
       "   'default_device': <function fastai.torch_core.default_device(use_cuda=-1)>,\n",
       "   'to_device': <function fastai.torch_core.to_device(b, device=None, non_blocking=False)>,\n",
       "   'to_cpu': <function fastai.torch_core.to_cpu(b)>,\n",
       "   'to_np': <function fastai.torch_core.to_np(x)>,\n",
       "   'to_concat': <function fastai.torch_core.to_concat(xs, dim=0)>,\n",
       "   'TensorBase': fastai.torch_core.TensorBase,\n",
       "   'TensorImageBase': fastai.torch_core.TensorImageBase,\n",
       "   'TensorImage': fastai.torch_core.TensorImage,\n",
       "   'TensorImageBW': fastai.torch_core.TensorImageBW,\n",
       "   'TensorMask': fastai.torch_core.TensorMask,\n",
       "   'TensorFlowField': fastai.torch_core.TensorFlowField,\n",
       "   'TensorCategory': fastai.torch_core.TensorCategory,\n",
       "   'TensorMultiCategory': fastai.torch_core.TensorMultiCategory,\n",
       "   'TitledTensorScalar': fastai.torch_core.TitledTensorScalar,\n",
       "   'Chunks': fastai.torch_core.Chunks,\n",
       "   'show_title': <function fastai.torch_core.show_title(o, ax=None, ctx=None, label=None, color='black', **kwargs)>,\n",
       "   'ShowTitle': fastai.torch_core.ShowTitle,\n",
       "   'TitledInt': fastai.torch_core.TitledInt,\n",
       "   'TitledFloat': fastai.torch_core.TitledFloat,\n",
       "   'TitledStr': fastai.torch_core.TitledStr,\n",
       "   'TitledTuple': fastai.torch_core.TitledTuple,\n",
       "   'get_empty_df': <function fastai.torch_core.get_empty_df(n)>,\n",
       "   'display_df': <function fastai.torch_core.display_df(df)>,\n",
       "   'get_first': <function fastai.torch_core.get_first(c)>,\n",
       "   'one_param': <function fastai.torch_core.one_param(m)>,\n",
       "   'item_find': <function fastai.torch_core.item_find(x, idx=0)>,\n",
       "   'find_device': <function fastai.torch_core.find_device(b)>,\n",
       "   'find_bs': <function fastai.torch_core.find_bs(b)>,\n",
       "   'np_func': <function fastai.torch_core.np_func(f)>,\n",
       "   'Module': fastai.torch_core.Module,\n",
       "   'get_model': <function fastai.torch_core.get_model(model)>,\n",
       "   'one_hot': <function fastai.torch_core.one_hot(x, c)>,\n",
       "   'one_hot_decode': <function fastai.torch_core.one_hot_decode(x, vocab=None)>,\n",
       "   'params': <function fastai.torch_core.params(m)>,\n",
       "   'trainable_params': <function fastai.torch_core.trainable_params(m)>,\n",
       "   'norm_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm3d,\n",
       "    torch.nn.modules.instancenorm.InstanceNorm1d,\n",
       "    torch.nn.modules.instancenorm.InstanceNorm2d,\n",
       "    torch.nn.modules.instancenorm.InstanceNorm3d,\n",
       "    torch.nn.modules.normalization.LayerNorm),\n",
       "   'norm_bias_params': <function fastai.torch_core.norm_bias_params(m, with_bias=True)>,\n",
       "   'batch_to_samples': <function fastai.torch_core.batch_to_samples(b, max_n=10)>,\n",
       "   'logit': <function fastai.torch_core.logit(x)>,\n",
       "   'num_distrib': <function fastai.torch_core.num_distrib()>,\n",
       "   'rank_distrib': <function fastai.torch_core.rank_distrib()>,\n",
       "   'distrib_barrier': <function fastai.torch_core.distrib_barrier()>,\n",
       "   'base_doc': <function fastai.torch_core.base_doc(elt)>,\n",
       "   'doc': <function fastai.torch_core.doc(elt)>,\n",
       "   'nested_reorder': <function fastai.torch_core.nested_reorder(t, idxs)>,\n",
       "   'make_cross_image': <function fastai.torch_core.make_cross_image(bw=True)>,\n",
       "   'show_image_batch': <function fastai.torch_core.show_image_batch(b, show=<function show_titled_image at 0x7f34c0cf3170>, items=9, cols=3, figsize=None, **kwargs)>,\n",
       "   'requires_grad': <function fastai.torch_core.requires_grad(m)>,\n",
       "   'init_default': <function fastai.layers.init_default(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "   'cond_init': <function fastai.torch_core.cond_init(m, func)>,\n",
       "   'apply_leaf': <function fastai.torch_core.apply_leaf(m, f)>,\n",
       "   'apply_init': <function fastai.torch_core.apply_init(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "   'script_use_ctx': <function fastai.torch_core.script_use_ctx(f)>,\n",
       "   'script_save_ctx': <function fastai.torch_core.script_save_ctx(static, *argidx)>,\n",
       "   'script_fwd': <function fastai.torch_core.script_fwd(*argidx)>,\n",
       "   'script_bwd': <function fastai.torch_core.script_bwd(f)>,\n",
       "   'grad_module': <function fastai.torch_core.grad_module(cls)>,\n",
       "   'flatten_check': <function fastai.torch_core.flatten_check(inp, targ)>,\n",
       "   'module': <function fastai.layers.module(*flds, **defaults)>,\n",
       "   'Identity': fastai.layers.Identity,\n",
       "   'Lambda': fastai.layers.Lambda,\n",
       "   'PartialLambda': fastai.layers.PartialLambda,\n",
       "   'Flatten': fastai.layers.Flatten,\n",
       "   'View': fastai.layers.View,\n",
       "   'ResizeBatch': fastai.layers.ResizeBatch,\n",
       "   'Debugger': fastai.layers.Debugger,\n",
       "   'sigmoid_range': <function fastai.layers.sigmoid_range(x, low, high)>,\n",
       "   'SigmoidRange': fastai.layers.SigmoidRange,\n",
       "   'AdaptiveConcatPool1d': fastai.layers.AdaptiveConcatPool1d,\n",
       "   'AdaptiveConcatPool2d': fastai.layers.AdaptiveConcatPool2d,\n",
       "   'PoolType': fastai.layers.PoolType,\n",
       "   'adaptive_pool': <function fastai.layers.adaptive_pool(pool_type)>,\n",
       "   'PoolFlatten': fastai.layers.PoolFlatten,\n",
       "   'NormType': <enum 'NormType'>,\n",
       "   'BatchNorm': <function fastai.layers.BatchNorm(nf, ndim=2, norm_type=<NormType.Batch: 1>, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)>,\n",
       "   'InstanceNorm': <function fastai.layers.InstanceNorm(nf, ndim=2, norm_type=<NormType.Instance: 5>, affine=True, eps: float = 1e-05, momentum: float = 0.1, track_running_stats: bool = False)>,\n",
       "   'BatchNorm1dFlat': fastai.layers.BatchNorm1dFlat,\n",
       "   'LinBnDrop': fastai.layers.LinBnDrop,\n",
       "   'sigmoid': <function fastai.layers.sigmoid(input, eps=1e-07)>,\n",
       "   'sigmoid_': <function fastai.layers.sigmoid_(input, eps=1e-07)>,\n",
       "   'vleaky_relu': <function fastai.layers.vleaky_relu(input, inplace=True)>,\n",
       "   'init_linear': <function fastai.layers.init_linear(m, act_func=None, init='auto', bias_std=0.01)>,\n",
       "   'ConvLayer': fastai.layers.ConvLayer,\n",
       "   'AdaptiveAvgPool': <function fastai.layers.AdaptiveAvgPool(sz=1, ndim=2)>,\n",
       "   'MaxPool': <function fastai.layers.MaxPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       "   'AvgPool': <function fastai.layers.AvgPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       "   'trunc_normal_': <function fastai.layers.trunc_normal_(x, mean=0.0, std=1.0)>,\n",
       "   'Embedding': fastai.layers.Embedding,\n",
       "   'SelfAttention': fastai.layers.SelfAttention,\n",
       "   'PooledSelfAttention2d': fastai.layers.PooledSelfAttention2d,\n",
       "   'SimpleSelfAttention': fastai.layers.SimpleSelfAttention,\n",
       "   'icnr_init': <function fastai.layers.icnr_init(x, scale=2, init=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "   'PixelShuffle_ICNR': fastai.layers.PixelShuffle_ICNR,\n",
       "   'sequential': <function fastai.layers.sequential(*args)>,\n",
       "   'SequentialEx': fastai.layers.SequentialEx,\n",
       "   'MergeLayer': fastai.layers.MergeLayer,\n",
       "   'Cat': fastai.layers.Cat,\n",
       "   'SimpleCNN': fastai.layers.SimpleCNN,\n",
       "   'ProdLayer': fastai.layers.ProdLayer,\n",
       "   'inplace_relu': functools.partial(<class 'torch.nn.modules.activation.ReLU'>, inplace=True),\n",
       "   'SEModule': <function fastai.layers.SEModule(ch, reduction, act_cls=<class 'torch.nn.modules.activation.ReLU'>)>,\n",
       "   'ResBlock': fastai.layers.ResBlock,\n",
       "   'SEBlock': <function fastai.layers.SEBlock(expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)>,\n",
       "   'SEResNeXtBlock': <function fastai.layers.SEResNeXtBlock(expansion, ni, nf, groups=32, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       "   'SeparableBlock': <function fastai.layers.SeparableBlock(expansion, ni, nf, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       "   'TimeDistributed': fastai.layers.TimeDistributed,\n",
       "   'swish': <function fastai.layers.swish(x, inplace=False)>,\n",
       "   'Swish': fastai.layers.Swish,\n",
       "   'MishJitAutoFn': fastai.layers.MishJitAutoFn,\n",
       "   'mish': <function fastai.layers.mish(x)>,\n",
       "   'Mish': fastai.layers.Mish,\n",
       "   'ParameterModule': fastai.layers.ParameterModule,\n",
       "   'children_and_parameters': <function fastai.layers.children_and_parameters(m)>,\n",
       "   'has_children': <function fastai.layers.has_children(m)>,\n",
       "   'flatten_model': <function fastai.layers.flatten_model(m)>,\n",
       "   'NoneReduce': fastai.layers.NoneReduce,\n",
       "   'in_channels': <function fastai.layers.in_channels(m)>,\n",
       "   'BaseLoss': fastai.losses.BaseLoss,\n",
       "   'CrossEntropyLossFlat': fastai.losses.CrossEntropyLossFlat,\n",
       "   'FocalLossFlat': fastai.losses.FocalLossFlat,\n",
       "   'BCEWithLogitsLossFlat': fastai.losses.BCEWithLogitsLossFlat,\n",
       "   'BCELossFlat': <function fastai.losses.BCELossFlat(*args, axis=-1, floatify=True, weight=None, reduction='mean')>,\n",
       "   'MSELossFlat': <function fastai.losses.MSELossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       "   'L1LossFlat': <function fastai.losses.L1LossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       "   'LabelSmoothingCrossEntropy': fastai.losses.LabelSmoothingCrossEntropy,\n",
       "   'LabelSmoothingCrossEntropyFlat': fastai.losses.LabelSmoothingCrossEntropyFlat,\n",
       "   'show_batch': (TensorImage,TensorImage) -> show_batch\n",
       "   (TensorImage,object) -> show_batch\n",
       "   (AudioTensor,object) -> show_batch\n",
       "   (AudioSpectrogram,object) -> show_batch\n",
       "   (object,object) -> show_batch,\n",
       "   'show_results': (TensorImage,TensorCategory) -> show_results\n",
       "   (TensorImage,TensorMask) -> show_results\n",
       "   (TensorImage,TensorBBox) -> show_results\n",
       "   (TensorImage,TensorPoint) -> show_results\n",
       "   (TensorImage,TensorImage) -> show_results\n",
       "   (TensorImage,object) -> show_results\n",
       "   (object,object) -> show_results,\n",
       "   'TfmdDL': fastai.data.core.TfmdDL,\n",
       "   'DataLoaders': fastai.data.core.DataLoaders,\n",
       "   'FilteredBase': fastai.data.core.FilteredBase,\n",
       "   'TfmdLists': fastai.data.core.TfmdLists,\n",
       "   'decode_at': <function fastai.data.core.decode_at(o, idx)>,\n",
       "   'show_at': <function fastai.data.core.show_at(o, idx, **kwargs)>,\n",
       "   'Datasets': fastai.data.core.Datasets,\n",
       "   'test_set': <function fastai.data.core.test_set(dsets, test_items, rm_tfms=None, with_labels=False)>,\n",
       "   'fa_collate': <function fastai.data.load.fa_collate(t)>,\n",
       "   'fa_convert': <function fastai.data.load.fa_convert(t)>,\n",
       "   'SkipItemException': fastai.data.load.SkipItemException,\n",
       "   'DataLoader': fastai.data.load.DataLoader,\n",
       "   'URLs': fastai.data.external.URLs,\n",
       "   'download_url': <function fastai.data.external.download_url(url, dest, overwrite=False, pbar=None, show_progress=True, chunk_size=1048576, timeout=4, retries=5)>,\n",
       "   'download_data': <function fastai.data.external.download_data(url, fname=None, c_key='archive', force_download=False, timeout=4)>,\n",
       "   'file_extract': <function fastai.data.external.file_extract(fname, dest=None)>,\n",
       "   'newest_folder': <function fastai.data.external.newest_folder(path)>,\n",
       "   'rename_extracted': <function fastai.data.external.rename_extracted(dest)>,\n",
       "   'untar_data': <function fastai.data.external.untar_data(url, fname=None, dest=None, c_key='data', force_download=False, extract_func=<function file_extract at 0x7f34bf3bec20>, timeout=4)>,\n",
       "   'get_files': <function fastai.data.transforms.get_files(path, extensions=None, recurse=True, folders=None, followlinks=True)>,\n",
       "   'FileGetter': <function fastai.data.transforms.FileGetter(suf='', extensions=None, recurse=True, folders=None)>,\n",
       "   'image_extensions': {'.art',\n",
       "    '.bmp',\n",
       "    '.cdr',\n",
       "    '.cdt',\n",
       "    '.cpt',\n",
       "    '.cr2',\n",
       "    '.crw',\n",
       "    '.djv',\n",
       "    '.djvu',\n",
       "    '.erf',\n",
       "    '.gif',\n",
       "    '.ico',\n",
       "    '.ief',\n",
       "    '.jng',\n",
       "    '.jp2',\n",
       "    '.jpe',\n",
       "    '.jpeg',\n",
       "    '.jpf',\n",
       "    '.jpg',\n",
       "    '.jpg2',\n",
       "    '.jpm',\n",
       "    '.jpx',\n",
       "    '.nef',\n",
       "    '.orf',\n",
       "    '.pat',\n",
       "    '.pbm',\n",
       "    '.pcx',\n",
       "    '.pgm',\n",
       "    '.png',\n",
       "    '.pnm',\n",
       "    '.ppm',\n",
       "    '.psd',\n",
       "    '.ras',\n",
       "    '.rgb',\n",
       "    '.svg',\n",
       "    '.svgz',\n",
       "    '.tif',\n",
       "    '.tiff',\n",
       "    '.wbmp',\n",
       "    '.xbm',\n",
       "    '.xpm',\n",
       "    '.xwd'},\n",
       "   'get_image_files': <function fastai.data.transforms.get_image_files(path, recurse=True, folders=None)>,\n",
       "   'ImageGetter': <function fastai.data.transforms.ImageGetter(suf='', recurse=True, folders=None)>,\n",
       "   'get_text_files': <function fastai.data.transforms.get_text_files(path, recurse=True, folders=None)>,\n",
       "   'ItemGetter': fastai.data.transforms.ItemGetter,\n",
       "   'AttrGetter': fastai.data.transforms.AttrGetter,\n",
       "   'RandomSplitter': <function fastai.data.transforms.RandomSplitter(valid_pct=0.2, seed=None)>,\n",
       "   'TrainTestSplitter': <function fastai.data.transforms.TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, train_size=None, shuffle=True)>,\n",
       "   'IndexSplitter': <function fastai.data.transforms.IndexSplitter(valid_idx)>,\n",
       "   'GrandparentSplitter': <function fastai.data.transforms.GrandparentSplitter(train_name='train', valid_name='valid')>,\n",
       "   'FuncSplitter': <function fastai.data.transforms.FuncSplitter(func)>,\n",
       "   'MaskSplitter': <function fastai.data.transforms.MaskSplitter(mask)>,\n",
       "   'FileSplitter': <function fastai.data.transforms.FileSplitter(fname)>,\n",
       "   'ColSplitter': <function fastai.data.transforms.ColSplitter(col='is_valid')>,\n",
       "   'RandomSubsetSplitter': <function fastai.data.transforms.RandomSubsetSplitter(train_sz, valid_sz, seed=None)>,\n",
       "   'parent_label': <function fastai.data.transforms.parent_label(o)>,\n",
       "   'RegexLabeller': fastai.data.transforms.RegexLabeller,\n",
       "   'ColReader': fastai.data.transforms.ColReader,\n",
       "   'CategoryMap': fastai.data.transforms.CategoryMap,\n",
       "   'Categorize': fastai.data.transforms.Categorize,\n",
       "   'Category': fastai.data.transforms.Category,\n",
       "   'MultiCategorize': fastai.data.transforms.MultiCategorize,\n",
       "   'MultiCategory': fastai.data.transforms.MultiCategory,\n",
       "   'OneHotEncode': fastai.data.transforms.OneHotEncode,\n",
       "   'EncodedMultiCategorize': fastai.data.transforms.EncodedMultiCategorize,\n",
       "   'RegressionSetup': fastai.data.transforms.RegressionSetup,\n",
       "   'get_c': <function fastai.data.transforms.get_c(dls)>,\n",
       "   'ToTensor': fastai.data.transforms.ToTensor,\n",
       "   'IntToFloatTensor': fastai.data.transforms.IntToFloatTensor,\n",
       "   'broadcast_vec': <function fastai.data.transforms.broadcast_vec(dim, ndim, *t, cuda=True)>,\n",
       "   'Normalize': fastai.data.transforms.Normalize,\n",
       "   'TransformBlock': fastai.data.block.TransformBlock,\n",
       "   'CategoryBlock': <function fastai.data.block.CategoryBlock(vocab=None, sort=True, add_na=False)>,\n",
       "   'MultiCategoryBlock': <function fastai.data.block.MultiCategoryBlock(encoded=False, vocab=None, add_na=False)>,\n",
       "   'RegressionBlock': <function fastai.data.block.RegressionBlock(n_out=None)>,\n",
       "   'DataBlock': fastai.data.block.DataBlock,\n",
       "   'Optimizer': fastai.optimizer.Optimizer,\n",
       "   'sgd_step': <function fastai.optimizer.sgd_step(p, lr, **kwargs)>,\n",
       "   'weight_decay': <function fastai.optimizer.weight_decay(p, lr, wd, do_wd=True, **kwargs)>,\n",
       "   'l2_reg': <function fastai.optimizer.l2_reg(p, lr, wd, do_wd=True, **kwargs)>,\n",
       "   'average_grad': <function fastai.optimizer.average_grad(p, mom, dampening=False, grad_avg=None, **kwargs)>,\n",
       "   'average_sqr_grad': <function fastai.optimizer.average_sqr_grad(p, sqr_mom, dampening=True, sqr_avg=None, **kwargs)>,\n",
       "   'momentum_step': <function fastai.optimizer.momentum_step(p, lr, grad_avg, **kwargs)>,\n",
       "   'SGD': <function fastai.optimizer.SGD(params, lr, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       "   'rms_prop_step': <function fastai.optimizer.rms_prop_step(p, lr, sqr_avg, eps, grad_avg=None, **kwargs)>,\n",
       "   'RMSProp': <function fastai.optimizer.RMSProp(params, lr, sqr_mom=0.99, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       "   'step_stat': <function fastai.optimizer.step_stat(p, step=0, **kwargs)>,\n",
       "   'debias': <function fastai.optimizer.debias(mom, damp, step)>,\n",
       "   'adam_step': <function fastai.optimizer.adam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       "   'Adam': <function fastai.optimizer.Adam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.01, decouple_wd=True)>,\n",
       "   'radam_step': <function fastai.optimizer.radam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, beta, **kwargs)>,\n",
       "   'RAdam': <function fastai.optimizer.RAdam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, beta=0.0, decouple_wd=True)>,\n",
       "   'qhadam_step': <function fastai.optimizer.qhadam_step(p, lr, mom, sqr_mom, sqr_avg, nu_1, nu_2, step, grad_avg, eps, **kwargs)>,\n",
       "   'QHAdam': <function fastai.optimizer.QHAdam(params, lr, mom=0.999, sqr_mom=0.999, nu_1=0.7, nu_2=1.0, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       "   'larc_layer_lr': <function fastai.optimizer.larc_layer_lr(p, lr, trust_coeff, wd, eps, clip=True, **kwargs)>,\n",
       "   'larc_step': <function fastai.optimizer.larc_step(p, local_lr, grad_avg=None, **kwargs)>,\n",
       "   'Larc': <function fastai.optimizer.Larc(params, lr, mom=0.9, clip=True, trust_coeff=0.02, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       "   'lamb_step': <function fastai.optimizer.lamb_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       "   'Lamb': <function fastai.optimizer.Lamb(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, decouple_wd=True)>,\n",
       "   'Lookahead': fastai.optimizer.Lookahead,\n",
       "   'ranger': <function fastai.optimizer.ranger(p, lr, mom=0.95, wd=0.01, eps=1e-06, sqr_mom=0.99, beta=0.0, decouple_wd=True)>,\n",
       "   'detuplify_pg': <function fastai.optimizer.detuplify_pg(d)>,\n",
       "   'set_item_pg': <function fastai.optimizer.set_item_pg(pg, k, v)>,\n",
       "   'pytorch_hp_map': {'momentum': 'mom',\n",
       "    'weight_decay': 'wd',\n",
       "    'alpha': 'sqr_mom',\n",
       "    'betas__0': 'mom',\n",
       "    'betas__1': 'sqr_mom'},\n",
       "   'OptimWrapper': fastai.optimizer.OptimWrapper,\n",
       "   'CancelStepException': fastcore.basics.CancelStepException,\n",
       "   'CancelFitException': fastcore.basics.CancelFitException,\n",
       "   'CancelEpochException': fastcore.basics.CancelEpochException,\n",
       "   'CancelTrainException': fastcore.basics.CancelTrainException,\n",
       "   'CancelValidException': fastcore.basics.CancelValidException,\n",
       "   'CancelBatchException': fastcore.basics.CancelBatchException,\n",
       "   'event': fastcore.basics.event,\n",
       "   'Callback': fastai.callback.core.Callback,\n",
       "   'TrainEvalCallback': fastai.callback.core.TrainEvalCallback,\n",
       "   'GatherPredsCallback': fastai.callback.core.GatherPredsCallback,\n",
       "   'FetchPredsCallback': fastai.callback.core.FetchPredsCallback,\n",
       "   'replacing_yield': <function fastai.learner.replacing_yield(o, attr, val)>,\n",
       "   'mk_metric': <function fastai.learner.mk_metric(m)>,\n",
       "   'save_model': <function fastai.learner.save_model(file, model, opt, with_opt=True, pickle_protocol=2)>,\n",
       "   'load_model': <function fastai.learner.load_model(file, model, opt, with_opt=True, device=None, strict=True)>,\n",
       "   'Learner': fastai.learner.Learner,\n",
       "   'before_batch_cb': <function fastai.learner.before_batch_cb(f)>,\n",
       "   'load_learner': <function fastai.learner.load_learner(fname, cpu=True, pickle_module=<module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>)>,\n",
       "   'to_detach_from_dl': <function fastai.learner.to_detach_from_dl(learn: (<class 'fastai.learner.Learner'>, <class 'NoneType'>), b: object, cpu: bool = True, gather: bool = True)>,\n",
       "   'Metric': fastai.learner.Metric,\n",
       "   'AvgMetric': fastai.learner.AvgMetric,\n",
       "   'AvgLoss': fastai.learner.AvgLoss,\n",
       "   'AvgSmoothLoss': fastai.learner.AvgSmoothLoss,\n",
       "   'ValueMetric': fastai.learner.ValueMetric,\n",
       "   'Recorder': fastai.learner.Recorder,\n",
       "   'AccumMetric': fastai.metrics.AccumMetric,\n",
       "   'skm_to_fastai': <function fastai.metrics.skm_to_fastai(func, is_class=True, thresh=None, axis=-1, activation=None, **kwargs)>,\n",
       "   'optim_metric': <function fastai.metrics.optim_metric(f, argname, bounds, tol=0.01, do_neg=True, get_x=False)>,\n",
       "   'accuracy': <function fastai.metrics.accuracy(inp, targ, axis=-1)>,\n",
       "   'error_rate': <function fastai.metrics.error_rate(inp, targ, axis=-1)>,\n",
       "   'top_k_accuracy': <function fastai.metrics.top_k_accuracy(inp, targ, k=5, axis=-1)>,\n",
       "   'APScoreBinary': <function fastai.metrics.APScoreBinary(axis=-1, average='macro', pos_label=1, sample_weight=None)>,\n",
       "   'BalancedAccuracy': <function fastai.metrics.BalancedAccuracy(axis=-1, sample_weight=None, adjusted=False)>,\n",
       "   'BrierScore': <function fastai.metrics.BrierScore(axis=-1, sample_weight=None, pos_label=None)>,\n",
       "   'CohenKappa': <function fastai.metrics.CohenKappa(axis=-1, labels=None, weights=None, sample_weight=None)>,\n",
       "   'F1Score': <function fastai.metrics.F1Score(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'FBeta': <function fastai.metrics.FBeta(beta, axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'HammingLoss': <function fastai.metrics.HammingLoss(axis=-1, sample_weight=None)>,\n",
       "   'Jaccard': <function fastai.metrics.Jaccard(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'Precision': <function fastai.metrics.Precision(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'Recall': <function fastai.metrics.Recall(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "   'RocAuc': <function fastai.metrics.RocAuc(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='ovr')>,\n",
       "   'RocAucBinary': <function fastai.metrics.RocAucBinary(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='raise')>,\n",
       "   'MatthewsCorrCoef': <function fastai.metrics.MatthewsCorrCoef(sample_weight=None, **kwargs)>,\n",
       "   'Perplexity': fastai.metrics.Perplexity,\n",
       "   'perplexity': <fastai.metrics.Perplexity at 0x7f34b7101810>,\n",
       "   'accuracy_multi': <function fastai.metrics.accuracy_multi(inp, targ, thresh=0.5, sigmoid=True)>,\n",
       "   'APScoreMulti': <function fastai.metrics.APScoreMulti(sigmoid=True, average='macro', pos_label=1, sample_weight=None)>,\n",
       "   'BrierScoreMulti': <function fastai.metrics.BrierScoreMulti(thresh=0.5, sigmoid=True, sample_weight=None, pos_label=None)>,\n",
       "   'F1ScoreMulti': <function fastai.metrics.F1ScoreMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'FBetaMulti': <function fastai.metrics.FBetaMulti(beta, thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'HammingLossMulti': <function fastai.metrics.HammingLossMulti(thresh=0.5, sigmoid=True, labels=None, sample_weight=None)>,\n",
       "   'JaccardMulti': <function fastai.metrics.JaccardMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'MatthewsCorrCoefMulti': <function fastai.metrics.MatthewsCorrCoefMulti(thresh=0.5, sigmoid=True, sample_weight=None)>,\n",
       "   'PrecisionMulti': <function fastai.metrics.PrecisionMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'RecallMulti': <function fastai.metrics.RecallMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "   'RocAucMulti': <function fastai.metrics.RocAucMulti(sigmoid=True, average='macro', sample_weight=None, max_fpr=None)>,\n",
       "   'mse': <function fastai.metrics.mse(inp, targ)>,\n",
       "   'rmse': <fastai.metrics.AccumMetric at 0x7f34b7101850>,\n",
       "   'mae': <function fastai.metrics.mae(inp, targ)>,\n",
       "   'msle': <function fastai.metrics.msle(inp, targ)>,\n",
       "   'exp_rmspe': <fastai.metrics.AccumMetric at 0x7f34b71018d0>,\n",
       "   'ExplainedVariance': <function fastai.metrics.ExplainedVariance(sample_weight=None)>,\n",
       "   'R2Score': <function fastai.metrics.R2Score(sample_weight=None)>,\n",
       "   'PearsonCorrCoef': <function fastai.metrics.PearsonCorrCoef(dim_argmax=None, activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       "   'SpearmanCorrCoef': <function fastai.metrics.SpearmanCorrCoef(dim_argmax=None, axis=0, nan_policy='propagate', activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       "   'foreground_acc': <function fastai.metrics.foreground_acc(inp, targ, bkg_idx=0, axis=1)>,\n",
       "   'Dice': fastai.metrics.Dice,\n",
       "   'DiceMulti': fastai.metrics.DiceMulti,\n",
       "   'JaccardCoeff': fastai.metrics.JaccardCoeff,\n",
       "   'CorpusBLEUMetric': fastai.metrics.CorpusBLEUMetric,\n",
       "   'LossMetric': fastai.metrics.LossMetric,\n",
       "   'LossMetrics': <function fastai.metrics.LossMetrics(attrs, nms=None)>,\n",
       "   'plot_top_losses': (TensorImage,TensorMultiCategory) -> plot_top_losses\n",
       "   (TensorImage,TensorCategory) -> plot_top_losses\n",
       "   (TensorImage,TensorMask) -> plot_top_losses\n",
       "   (object,object) -> plot_top_losses,\n",
       "   'Interpretation': fastai.interpret.Interpretation,\n",
       "   'ClassificationInterpretation': fastai.interpret.ClassificationInterpretation,\n",
       "   'SegmentationInterpretation': fastai.interpret.SegmentationInterpretation,\n",
       "   'CollectDataCallback': fastai.callback.data.CollectDataCallback,\n",
       "   'WeightedDL': fastai.callback.data.WeightedDL,\n",
       "   'PartialDL': fastai.callback.data.PartialDL,\n",
       "   'MixedPrecision': fastai.callback.fp16.MixedPrecision,\n",
       "   'FP16TestCallback': fastai.callback.fp16.FP16TestCallback,\n",
       "   'get_master': <function fastai.callback.fp16.get_master(opt, flat_master=False)>,\n",
       "   'to_master_grads': <function fastai.callback.fp16.to_master_grads(model_pgs, master_pgs, flat_master=False)>,\n",
       "   'to_model_params': <function fastai.callback.fp16.to_model_params(model_pgs, master_pgs, flat_master=False) -> None>,\n",
       "   'test_overflow': <function fastai.callback.fp16.test_overflow(x)>,\n",
       "   'grad_overflow': <function fastai.callback.fp16.grad_overflow(pgs)>,\n",
       "   'copy_clone': <function fastai.callback.fp16.copy_clone(d)>,\n",
       "   'ModelToHalf': fastai.callback.fp16.ModelToHalf,\n",
       "   'NonNativeMixedPrecision': fastai.callback.fp16.NonNativeMixedPrecision,\n",
       "   'Hook': fastai.callback.hook.Hook,\n",
       "   'hook_output': <function fastai.callback.hook.hook_output(module, detach=True, cpu=False, grad=False)>,\n",
       "   'Hooks': fastai.callback.hook.Hooks,\n",
       "   'hook_outputs': <function fastai.callback.hook.hook_outputs(modules, detach=True, cpu=False, grad=False)>,\n",
       "   'dummy_eval': <function fastai.callback.hook.dummy_eval(m, size=(64, 64))>,\n",
       "   'model_sizes': <function fastai.callback.hook.model_sizes(m, size=(64, 64))>,\n",
       "   'num_features_model': <function fastai.callback.hook.num_features_model(m)>,\n",
       "   'has_params': <function fastai.callback.hook.has_params(m)>,\n",
       "   'HookCallback': fastai.callback.hook.HookCallback,\n",
       "   'total_params': <function fastai.callback.hook.total_params(m)>,\n",
       "   'layer_info': <function fastai.callback.hook.layer_info(learn, *xb)>,\n",
       "   'module_summary': <function fastai.callback.hook.module_summary(learn, *xb)>,\n",
       "   'ActivationStats': fastai.callback.hook.ActivationStats,\n",
       "   'reduce_loss': <function fastai.callback.mixup.reduce_loss(loss, reduction='mean')>,\n",
       "   'MixHandler': fastai.callback.mixup.MixHandler,\n",
       "   'MixUp': fastai.callback.mixup.MixUp,\n",
       "   'CutMix': fastai.callback.mixup.CutMix,\n",
       "   'ProgressCallback': fastai.callback.progress.ProgressCallback,\n",
       "   'ShowGraphCallback': fastai.callback.progress.ShowGraphCallback,\n",
       "   'CSVLogger': fastai.callback.progress.CSVLogger,\n",
       "   'annealer': <function fastai.callback.schedule.annealer(f)>,\n",
       "   'sched_lin': <function fastai.callback.schedule.sched_lin(start, end, pos)>,\n",
       "   'sched_cos': <function fastai.callback.schedule.sched_cos(start, end, pos)>,\n",
       "   'sched_no': <function fastai.callback.schedule.sched_no(start, end, pos)>,\n",
       "   'sched_exp': <function fastai.callback.schedule.sched_exp(start, end, pos)>,\n",
       "   'SchedLin': <function fastai.callback.schedule.SchedLin(start, end)>,\n",
       "   'SchedCos': <function fastai.callback.schedule.SchedCos(start, end)>,\n",
       "   'SchedNo': <function fastai.callback.schedule.SchedNo(start, end)>,\n",
       "   'SchedExp': <function fastai.callback.schedule.SchedExp(start, end)>,\n",
       "   'SchedPoly': <function fastai.callback.schedule.SchedPoly(start, end, power)>,\n",
       "   'combine_scheds': <function fastai.callback.schedule.combine_scheds(pcts, scheds)>,\n",
       "   'combined_cos': <function fastai.callback.schedule.combined_cos(pct, start, middle, end)>,\n",
       "   'ParamScheduler': fastai.callback.schedule.ParamScheduler,\n",
       "   'LRFinder': fastai.callback.schedule.LRFinder,\n",
       "   'SuggestedLRs': fastai.callback.schedule.SuggestedLRs,\n",
       "   'TerminateOnNaNCallback': fastai.callback.tracker.TerminateOnNaNCallback,\n",
       "   'TrackerCallback': fastai.callback.tracker.TrackerCallback,\n",
       "   'EarlyStoppingCallback': fastai.callback.tracker.EarlyStoppingCallback,\n",
       "   'SaveModelCallback': fastai.callback.tracker.SaveModelCallback,\n",
       "   'ReduceLROnPlateau': fastai.callback.tracker.ReduceLROnPlateau,\n",
       "   'ModelResetter': fastai.callback.rnn.ModelResetter,\n",
       "   'RNNCallback': fastai.callback.rnn.RNNCallback,\n",
       "   'RNNRegularizer': fastai.callback.rnn.RNNRegularizer,\n",
       "   'rnn_cbs': <function fastai.callback.rnn.rnn_cbs(alpha=0.0, beta=0.0)>,\n",
       "   'ShortEpochCallback': fastai.callback.training.ShortEpochCallback,\n",
       "   'GradientAccumulation': fastai.callback.training.GradientAccumulation,\n",
       "   'GradientClip': fastai.callback.training.GradientClip,\n",
       "   'set_bn_eval': <function fastai.callback.training.set_bn_eval(m: torch.nn.modules.module.Module, use_eval=True) -> None>,\n",
       "   'BnFreeze': fastai.callback.training.BnFreeze,\n",
       "   'bn_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "    torch.nn.modules.batchnorm.BatchNorm3d),\n",
       "   'MCDropoutCallback': fastai.callback.preds.MCDropoutCallback,\n",
       "   'RandTransform': fastai.vision.augment.RandTransform,\n",
       "   'TensorTypes': (fastai.torch_core.TensorImage,\n",
       "    fastai.torch_core.TensorMask,\n",
       "    fastai.vision.core.TensorPoint,\n",
       "    fastai.vision.core.TensorBBox),\n",
       "   'FlipItem': fastai.vision.augment.FlipItem,\n",
       "   'DihedralItem': fastai.vision.augment.DihedralItem,\n",
       "   'PadMode': fastcore.basics.PadMode,\n",
       "   'CropPad': fastai.vision.augment.CropPad,\n",
       "   'RandomCrop': fastai.vision.augment.RandomCrop,\n",
       "   'OldRandomCrop': fastai.vision.augment.OldRandomCrop,\n",
       "   'ResizeMethod': fastcore.basics.ResizeMethod,\n",
       "   'Resize': fastai.vision.augment.Resize,\n",
       "   'RandomResizedCrop': fastai.vision.augment.RandomResizedCrop,\n",
       "   'RatioResize': fastai.vision.augment.RatioResize,\n",
       "   'affine_grid': <function fastai.vision.augment.affine_grid(theta, size, align_corners=None)>,\n",
       "   'AffineCoordTfm': fastai.vision.augment.AffineCoordTfm,\n",
       "   'RandomResizedCropGPU': fastai.vision.augment.RandomResizedCropGPU,\n",
       "   'mask_tensor': <function fastai.vision.augment.mask_tensor(x, p=0.5, neutral=0.0, batch=False)>,\n",
       "   'affine_mat': <function fastai.vision.augment.affine_mat(*ms)>,\n",
       "   'flip_mat': <function fastai.vision.augment.flip_mat(x, p=0.5, draw=None, batch=False)>,\n",
       "   'Flip': fastai.vision.augment.Flip,\n",
       "   'DeterministicDraw': fastai.vision.augment.DeterministicDraw,\n",
       "   'DeterministicFlip': fastai.vision.augment.DeterministicFlip,\n",
       "   'dihedral_mat': <function fastai.vision.augment.dihedral_mat(x, p=0.5, draw=None, batch=False)>,\n",
       "   'Dihedral': fastai.vision.augment.Dihedral,\n",
       "   'DeterministicDihedral': fastai.vision.augment.DeterministicDihedral,\n",
       "   'rotate_mat': <function fastai.vision.augment.rotate_mat(x, max_deg=10, p=0.5, draw=None, batch=False)>,\n",
       "   'Rotate': fastai.vision.augment.Rotate,\n",
       "   'zoom_mat': <function fastai.vision.augment.zoom_mat(x, min_zoom=1.0, max_zoom=1.1, p=0.5, draw=None, draw_x=None, draw_y=None, batch=False)>,\n",
       "   'Zoom': fastai.vision.augment.Zoom,\n",
       "   'find_coeffs': <function fastai.vision.augment.find_coeffs(p1, p2)>,\n",
       "   'apply_perspective': <function fastai.vision.augment.apply_perspective(coords, coeffs)>,\n",
       "   'Warp': fastai.vision.augment.Warp,\n",
       "   'SpaceTfm': fastai.vision.augment.SpaceTfm,\n",
       "   'LightingTfm': fastai.vision.augment.LightingTfm,\n",
       "   'Brightness': fastai.vision.augment.Brightness,\n",
       "   'Contrast': fastai.vision.augment.Contrast,\n",
       "   'grayscale': <function fastai.vision.augment.grayscale(x)>,\n",
       "   'Saturation': fastai.vision.augment.Saturation,\n",
       "   'rgb2hsv': <function fastai.vision.augment.rgb2hsv(img)>,\n",
       "   'hsv2rgb': <function fastai.vision.augment.hsv2rgb(img)>,\n",
       "   'HSVTfm': fastai.vision.augment.HSVTfm,\n",
       "   'Hue': fastai.vision.augment.Hue,\n",
       "   'cutout_gaussian': <function fastai.vision.augment.cutout_gaussian(x, areas)>,\n",
       "   'norm_apply_denorm': <function fastai.vision.augment.norm_apply_denorm(x, f, nrm)>,\n",
       "   'RandomErasing': fastai.vision.augment.RandomErasing,\n",
       "   'setup_aug_tfms': <function fastai.vision.augment.setup_aug_tfms(tfms)>,\n",
       "   'aug_transforms': <function fastai.vision.augment.aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=None, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0)>,\n",
       "   'Image': <module 'PIL.Image' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/PIL/Image.py'>,\n",
       "   'imagenet_stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
       "   'cifar_stats': ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261]),\n",
       "   'mnist_stats': ([0.131], [0.308]),\n",
       "   'n_px': None,\n",
       "   'shape': None,\n",
       "   'aspect': None,\n",
       "   'to_image': <function fastai.vision.core.to_image(x)>,\n",
       "   'load_image': <function fastai.vision.core.load_image(fn, mode=None)>,\n",
       "   'image2tensor': <function fastai.vision.core.image2tensor(img)>,\n",
       "   'PILBase': fastai.vision.core.PILBase,\n",
       "   'PILImage': fastai.vision.core.PILImage,\n",
       "   'PILImageBW': fastai.vision.core.PILImageBW,\n",
       "   'PILMask': fastai.vision.core.PILMask,\n",
       "   'OpenMask': PILBase.create:\n",
       "   encodes: (Path,object) -> create\n",
       "   (str,object) -> create\n",
       "   (Tensor,object) -> create\n",
       "   (ndarray,object) -> create\n",
       "   (bytes,object) -> createdecodes: ,\n",
       "   'AddMaskCodes': fastai.vision.core.AddMaskCodes,\n",
       "   'TensorPoint': fastai.vision.core.TensorPoint,\n",
       "   'TensorPointCreate': TensorPoint.create:\n",
       "   encodes: (object,object) -> createdecodes: ,\n",
       "   'get_annotations': <function fastai.vision.core.get_annotations(fname, prefix=None)>,\n",
       "   'TensorBBox': fastai.vision.core.TensorBBox,\n",
       "   'LabeledBBox': fastai.vision.core.LabeledBBox,\n",
       "   'encodes': <function fastai.vision.core.encodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       "   'PointScaler': fastai.vision.core.PointScaler,\n",
       "   'BBoxLabeler': fastai.vision.core.BBoxLabeler,\n",
       "   'decodes': <function fastai.vision.core.decodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       "   'get_grid': <function fastai.vision.data.get_grid(n, nrows=None, ncols=None, add_vert=0, figsize=None, double=False, title=None, return_fig=False, flatten=True, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       "   'clip_remove_empty': <function fastai.vision.data.clip_remove_empty(bbox, label)>,\n",
       "   'bb_pad': <function fastai.vision.data.bb_pad(samples, pad_idx=0)>,\n",
       "   'ImageBlock': <function fastai.vision.data.ImageBlock(cls=<class 'fastai.vision.core.PILImage'>)>,\n",
       "   'MaskBlock': <function fastai.vision.data.MaskBlock(codes=None)>,\n",
       "   'PointBlock': <fastai.data.block.TransformBlock at 0x7f34b7020410>,\n",
       "   'BBoxBlock': <fastai.data.block.TransformBlock at 0x7f34b7093850>,\n",
       "   'BBoxLblBlock': <function fastai.vision.data.BBoxLblBlock(vocab=None, add_na=True)>,\n",
       "   'ImageDataLoaders': fastai.vision.data.ImageDataLoaders,\n",
       "   'SegmentationDataLoaders': fastai.vision.data.SegmentationDataLoaders,\n",
       "   'init_cnn': <function fastai.vision.models.xresnet.init_cnn(m)>,\n",
       "   'XResNet': fastai.vision.models.xresnet.XResNet,\n",
       "   'xresnet18': <function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>,\n",
       "   'xresnet34': <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>,\n",
       "   'xresnet50': <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>,\n",
       "   'xresnet101': <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>,\n",
       "   'xresnet152': <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>,\n",
       "   'xresnet18_deep': <function fastai.vision.models.xresnet.xresnet18_deep(pretrained=False, **kwargs)>,\n",
       "   'xresnet34_deep': <function fastai.vision.models.xresnet.xresnet34_deep(pretrained=False, **kwargs)>,\n",
       "   'xresnet50_deep': <function fastai.vision.models.xresnet.xresnet50_deep(pretrained=False, **kwargs)>,\n",
       "   'xresnet18_deeper': <function fastai.vision.models.xresnet.xresnet18_deeper(pretrained=False, **kwargs)>,\n",
       "   'xresnet34_deeper': <function fastai.vision.models.xresnet.xresnet34_deeper(pretrained=False, **kwargs)>,\n",
       "   'xresnet50_deeper': <function fastai.vision.models.xresnet.xresnet50_deeper(pretrained=False, **kwargs)>,\n",
       "   'se_kwargs1': {'groups': 1, 'reduction': 16},\n",
       "   'se_kwargs2': {'groups': 32, 'reduction': 16},\n",
       "   'se_kwargs3': {'groups': 32, 'reduction': 0},\n",
       "   'g0': [2, 2, 2, 2],\n",
       "   'g1': [3, 4, 6, 3],\n",
       "   'g2': [3, 4, 23, 3],\n",
       "   'g3': [3, 8, 36, 3],\n",
       "   'xse_resnet18': <function fastai.vision.models.xresnet.xse_resnet18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext18': <function fastai.vision.models.xresnet.xse_resnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext18': <function fastai.vision.models.xresnet.xresnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet34': <function fastai.vision.models.xresnet.xse_resnet34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext34': <function fastai.vision.models.xresnet.xse_resnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext34': <function fastai.vision.models.xresnet.xresnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet50': <function fastai.vision.models.xresnet.xse_resnet50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext50': <function fastai.vision.models.xresnet.xse_resnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext50': <function fastai.vision.models.xresnet.xresnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet101': <function fastai.vision.models.xresnet.xse_resnet101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext101': <function fastai.vision.models.xresnet.xse_resnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xresnext101': <function fastai.vision.models.xresnet.xresnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnet152': <function fastai.vision.models.xresnet.xse_resnet152(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xsenet154': <function fastai.vision.models.xresnet.xsenet154(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext18_deep': <function fastai.vision.models.xresnet.xse_resnext18_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext34_deep': <function fastai.vision.models.xresnet.xse_resnext34_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext50_deep': <function fastai.vision.models.xresnet.xse_resnext50_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext18_deeper': <function fastai.vision.models.xresnet.xse_resnext18_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext34_deeper': <function fastai.vision.models.xresnet.xse_resnext34_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'xse_resnext50_deeper': <function fastai.vision.models.xresnet.xse_resnext50_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "   'UnetBlock': fastai.vision.models.unet.UnetBlock,\n",
       "   'ResizeToOrig': fastai.vision.models.unet.ResizeToOrig,\n",
       "   'DynamicUnet': fastai.vision.models.unet.DynamicUnet,\n",
       "   'ResNet': torchvision.models.resnet.ResNet,\n",
       "   'resnet18': <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet34': <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet50': <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet101': <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'resnet152': <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "   'SqueezeNet': torchvision.models.squeezenet.SqueezeNet,\n",
       "   'squeezenet1_0': <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       "   'squeezenet1_1': <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       "   'densenet121': <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'densenet169': <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'densenet201': <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'densenet161': <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "   'vgg11_bn': <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'vgg13_bn': <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'vgg16_bn': <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'vgg19_bn': <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "   'alexnet': <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>,\n",
       "   'has_pool_type': <function fastai.vision.learner.has_pool_type(m)>,\n",
       "   'create_body': <function fastai.vision.learner.create_body(arch, n_in=3, pretrained=True, cut=None)>,\n",
       "   'create_head': <function fastai.vision.learner.create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "   'default_split': <function fastai.vision.learner.default_split(m)>,\n",
       "   'model_meta': {<function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "     'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "     'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "    <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>: {'cut': -2,\n",
       "     'split': <function fastai.vision.learner._alexnet_split(m: torch.nn.modules.module.Module)>,\n",
       "     'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])}},\n",
       "   'create_cnn_model': <function fastai.vision.learner.create_cnn_model(arch, n_out, pretrained=True, cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "   'cnn_learner': <function fastai.vision.learner.cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "   'create_unet_model': <function fastai.vision.learner.create_unet_model(arch, n_out, img_size, pretrained=True, cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       "   'unet_learner': <function fastai.vision.learner.unet_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       "   'download_images': <function fastai.vision.utils.download_images(dest, url_file=None, urls=None, max_pics=1000, n_workers=8, timeout=4, preserve_filename=False)>,\n",
       "   'resize_to': <function fastai.vision.utils.resize_to(img, targ_sz, use_min=False)>,\n",
       "   'verify_image': <function fastai.vision.utils.verify_image(fn)>,\n",
       "   'verify_images': <function fastai.vision.utils.verify_images(fns)>,\n",
       "   'resize_image': <function fastai.vision.utils.resize_image(file, dest, max_size=None, n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=False, **kwargs)>,\n",
       "   'resize_images': <function fastai.vision.utils.resize_images(path, max_workers=4, max_size=None, recurse=False, dest=Path('.'), n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=None, **kwargs)>,\n",
       "   'transforms': <module 'torchaudio.transforms' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/transforms.py'>,\n",
       "   'make_dataclass': <function dataclasses.make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)>,\n",
       "   'signature': <function inspect.signature(obj, *, follow_wrapped=True)>,\n",
       "   'save_audio': <function torchaudio.backend.sox_io_backend.save(filepath: str, src: torch.Tensor, sample_rate: int, channels_first: bool = True, compression: Union[float, NoneType] = None, format: Union[str, NoneType] = None, encoding: Union[str, NoneType] = None, bits_per_sample: Union[int, NoneType] = None)>,\n",
       "   'Resample': fastaudio.augment.preprocess.Resample,\n",
       "   'DownmixMono': fastaudio.augment.signal.DownmixMono,\n",
       "   'ResizeSignal': fastaudio.augment.signal.ResizeSignal,\n",
       "   'AudioTensor': fastaudio.core.signal.AudioTensor,\n",
       "   'get_audio_files': <function fastaudio.core.signal.get_audio_files(path, recurse=True, folders=None)>,\n",
       "   'audio_item_tfms': <function fastaudio.core.config.audio_item_tfms(sample_rate=16000, force_mono=True, crop_signal_to=None)>,\n",
       "   'PreprocessAudio': fastaudio.core.config.PreprocessAudio,\n",
       "   'preprocess_audio_folder': <function fastaudio.core.config.preprocess_audio_folder(path, folders=None, output_dir=None, sample_rate=16000, force_mono=True, crop_signal_to=None, **kwargs)>,\n",
       "   'AudioBlock': fastaudio.core.config.AudioBlock,\n",
       "   'config_from_func': <function fastaudio.core.config.config_from_func(func, name, **kwargs)>,\n",
       "   'AudioConfig': fastaudio.core.config.AudioConfig,\n",
       "   'torchaudio': <module 'torchaudio' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/__init__.py'>,\n",
       "   'Audio': IPython.lib.display.Audio,\n",
       "   'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
       "   'waveplot': <function librosa.display.waveplot(y, sr=22050, max_points=50000.0, x_axis='time', offset=0.0, max_sr=1000, ax=None, **kwargs)>,\n",
       "   'path': <module 'posixpath' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/posixpath.py'>,\n",
       "   'audio_extensions': ('.m3u',\n",
       "    '.ram',\n",
       "    '.au',\n",
       "    '.snd',\n",
       "    '.mp3',\n",
       "    '.mp2',\n",
       "    '.aif',\n",
       "    '.aifc',\n",
       "    '.aiff',\n",
       "    '.ra',\n",
       "    '.wav',\n",
       "    '.amr',\n",
       "    '.awb',\n",
       "    '.axa',\n",
       "    '.csd',\n",
       "    '.orc',\n",
       "    '.sco',\n",
       "    '.flac',\n",
       "    '.mid',\n",
       "    '.midi',\n",
       "    '.kar',\n",
       "    '.mpga',\n",
       "    '.mpega',\n",
       "    '.m4a',\n",
       "    '.oga',\n",
       "    '.ogg',\n",
       "    '.opus',\n",
       "    '.spx',\n",
       "    '.sid',\n",
       "    '.gsm',\n",
       "    '.wma',\n",
       "    '.wax',\n",
       "    '.rm',\n",
       "    '.pls',\n",
       "    '.sd2'),\n",
       "   'AudioGetter': <function fastaudio.core.signal.AudioGetter(suf='', recurse=True, folders=None)>,\n",
       "   'tar_extract_at_filename': <function fastaudio.core.signal.tar_extract_at_filename(fname, dest)>,\n",
       "   'show_audio_signal': <function fastaudio.core.signal.show_audio_signal(ai, ctx, ax=None, title='', **kwargs)>,\n",
       "   'OpenAudio': fastaudio.core.signal.OpenAudio,\n",
       "   ...}},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f354f4bc590>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       " '_': {'__name__': '__main__',\n",
       "  '__doc__': 'Automatically created module for IPython interactive environment',\n",
       "  '__package__': None,\n",
       "  '__loader__': None,\n",
       "  '__spec__': None,\n",
       "  '__builtin__': <module 'builtins' (built-in)>,\n",
       "  '__builtins__': <module 'builtins' (built-in)>,\n",
       "  '_ih': ['',\n",
       "   \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "   'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "   \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "   \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "   \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "   \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "   'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "   \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "   \"p = Path('data/pitch_accent')\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "   'import fastai\\nfastai.__version__',\n",
       "   'AudioConfig.Voice',\n",
       "   \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "   'my_dict = object()',\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "   'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "   'd.__setattr__(b=b)',\n",
       "   'd.__setattr__(b,b)',\n",
       "   \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "   \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "   'locals()',\n",
       "   \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       "  '_oh': {8:                                         path pattern  kana  morae  drop  \\\n",
       "   0       accentAudio/ある.yomi000142BB_0596.mp3      頭高    アル      2     1   \n",
       "   1       accentAudio/思う.yomi0006C617_043A.mp3      中高   オモウ      3     2   \n",
       "   2       accentAudio/など.yomi000240B7_0028.mp3      頭高    ナド      2     1   \n",
       "   3        accentAudio/私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0   \n",
       "   4       accentAudio/見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1   \n",
       "   ...                                      ...     ...   ...    ...   ...   \n",
       "   163962      OjadMedia/立て-377_10_1_female.mp3      頭高    たて      2     1   \n",
       "   163963       OjadMedia/立てる-377_11_1_male.mp3      中高   たてる      3     2   \n",
       "   163964     OjadMedia/立てる-377_11_1_female.mp3      中高   たてる      3     2   \n",
       "   163965       OjadMedia/立とう-377_12_1_male.mp3      中高   たとう      3     2   \n",
       "   163966     OjadMedia/立とう-377_12_1_female.mp3      中高   たとう      3     2   \n",
       "   \n",
       "                  type  \n",
       "   0               nhk  \n",
       "   1               nhk  \n",
       "   2               nhk  \n",
       "   3               nhk  \n",
       "   4               nhk  \n",
       "   ...             ...  \n",
       "   163962  ojad female  \n",
       "   163963    ojad male  \n",
       "   163964  ojad female  \n",
       "   163965    ojad male  \n",
       "   163966  ojad female  \n",
       "   \n",
       "   [163967 rows x 6 columns],\n",
       "   10:                                       path pattern        kana  morae  drop  \\\n",
       "   0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "   1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "   2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "   3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "   4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "   ...                                    ...     ...         ...    ...   ...   \n",
       "   79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "   79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "   79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "   79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "   79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "   \n",
       "           type  \n",
       "   0      dict1  \n",
       "   1      dict1  \n",
       "   2      dict1  \n",
       "   3      dict1  \n",
       "   4      dict1  \n",
       "   ...      ...  \n",
       "   79480  dict1  \n",
       "   79481  dict1  \n",
       "   79482  dict1  \n",
       "   79483  dict1  \n",
       "   79484  dict1  \n",
       "   \n",
       "   [79485 rows x 6 columns],\n",
       "   12:                                       path pattern        kana  morae  drop  \\\n",
       "   0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "   1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "   2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "   3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "   4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "   ...                                    ...     ...         ...    ...   ...   \n",
       "   79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "   79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "   79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "   79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "   79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "   \n",
       "           type  \n",
       "   0      dict1  \n",
       "   1      dict1  \n",
       "   2      dict1  \n",
       "   3      dict1  \n",
       "   4      dict1  \n",
       "   ...      ...  \n",
       "   79480  dict1  \n",
       "   79481  dict1  \n",
       "   79482  dict1  \n",
       "   79483  dict1  \n",
       "   79484  dict1  \n",
       "   \n",
       "   [79485 rows x 6 columns],\n",
       "   13:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84482 rows x 6 columns],\n",
       "   16:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84481 rows x 6 columns],\n",
       "   18:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84482 rows x 6 columns],\n",
       "   19:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84481 rows x 6 columns],\n",
       "   20:                                                      path pattern      kana  \\\n",
       "   0         ある-66_1_1_male.mp3dict1ある.yomi000142BB_0596.mp3    頭高頭高      あるアル   \n",
       "   1       ある-66_1_1_female.mp3dict1思う.yomi0006C617_043A.mp3    頭高中高     あるオモウ   \n",
       "   2       あります-66_2_1_male.mp3dict1など.yomi000240B7_0028.mp3    中高頭高    ありますナド   \n",
       "   3      あります-66_2_1_female.mp3dict1私.yomi00092F63_0072.mp3    中高平板  ありますワタくシ   \n",
       "   4        あって-66_3_1_male.mp3dict1見る.yomi000A41BD_001E.mp3    頭高頭高     あってミル   \n",
       "   ...                                                   ...     ...       ...   \n",
       "   84477                                                 NaN     NaN       NaN   \n",
       "   84478                                                 NaN     NaN       NaN   \n",
       "   84479                                                 NaN     NaN       NaN   \n",
       "   84480                                                 NaN     NaN       NaN   \n",
       "   84481                                                 NaN     NaN       NaN   \n",
       "   \n",
       "          morae  drop               type  \n",
       "   0        4.0   2.0    dict2 maledict1  \n",
       "   1        5.0   3.0  dict2 femaledict1  \n",
       "   2        6.0   4.0    dict2 maledict1  \n",
       "   3        8.0   3.0  dict2 femaledict1  \n",
       "   4        5.0   2.0    dict2 maledict1  \n",
       "   ...      ...   ...                ...  \n",
       "   84477    NaN   NaN                NaN  \n",
       "   84478    NaN   NaN                NaN  \n",
       "   84479    NaN   NaN                NaN  \n",
       "   84480    NaN   NaN                NaN  \n",
       "   84481    NaN   NaN                NaN  \n",
       "   \n",
       "   [84482 rows x 6 columns],\n",
       "   23:                                 path pattern  kana  morae  drop          type\n",
       "   0      dict1ある.yomi000142BB_0596.mp3      頭高    アル      2     1         dict1\n",
       "   1      dict1思う.yomi0006C617_043A.mp3      中高   オモウ      3     2         dict1\n",
       "   2      dict1など.yomi000240B7_0028.mp3      頭高    ナド      2     1         dict1\n",
       "   3       dict1私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0         dict1\n",
       "   4      dict1見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1         dict1\n",
       "   ...                              ...     ...   ...    ...   ...           ...\n",
       "   84477         立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478          立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479        立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480          立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481        立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [163966 rows x 6 columns],\n",
       "   24: '2.3.1',\n",
       "   25: types.Voice,\n",
       "   37: {'k': 3.0},\n",
       "   43: {...}},\n",
       "  '_dh': ['/home/mizoru/ML/japanese-ml'],\n",
       "  'In': ['',\n",
       "   \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "   'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "   \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "   \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "   \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "   \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "   'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "   \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "   \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "   \"p = Path('data/pitch_accent')\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "   \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "   'import fastai\\nfastai.__version__',\n",
       "   'AudioConfig.Voice',\n",
       "   \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "   'my_dict = object()',\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "   'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "   \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "   'd.__setattr__(b=b)',\n",
       "   'd.__setattr__(b,b)',\n",
       "   \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "   \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "   'locals()',\n",
       "   \"{k:v for k,v in locals().copy().items() if k[:2] != '__'}\"],\n",
       "  'Out': {8:                                         path pattern  kana  morae  drop  \\\n",
       "   0       accentAudio/ある.yomi000142BB_0596.mp3      頭高    アル      2     1   \n",
       "   1       accentAudio/思う.yomi0006C617_043A.mp3      中高   オモウ      3     2   \n",
       "   2       accentAudio/など.yomi000240B7_0028.mp3      頭高    ナド      2     1   \n",
       "   3        accentAudio/私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0   \n",
       "   4       accentAudio/見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1   \n",
       "   ...                                      ...     ...   ...    ...   ...   \n",
       "   163962      OjadMedia/立て-377_10_1_female.mp3      頭高    たて      2     1   \n",
       "   163963       OjadMedia/立てる-377_11_1_male.mp3      中高   たてる      3     2   \n",
       "   163964     OjadMedia/立てる-377_11_1_female.mp3      中高   たてる      3     2   \n",
       "   163965       OjadMedia/立とう-377_12_1_male.mp3      中高   たとう      3     2   \n",
       "   163966     OjadMedia/立とう-377_12_1_female.mp3      中高   たとう      3     2   \n",
       "   \n",
       "                  type  \n",
       "   0               nhk  \n",
       "   1               nhk  \n",
       "   2               nhk  \n",
       "   3               nhk  \n",
       "   4               nhk  \n",
       "   ...             ...  \n",
       "   163962  ojad female  \n",
       "   163963    ojad male  \n",
       "   163964  ojad female  \n",
       "   163965    ojad male  \n",
       "   163966  ojad female  \n",
       "   \n",
       "   [163967 rows x 6 columns],\n",
       "   10:                                       path pattern        kana  morae  drop  \\\n",
       "   0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "   1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "   2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "   3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "   4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "   ...                                    ...     ...         ...    ...   ...   \n",
       "   79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "   79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "   79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "   79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "   79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "   \n",
       "           type  \n",
       "   0      dict1  \n",
       "   1      dict1  \n",
       "   2      dict1  \n",
       "   3      dict1  \n",
       "   4      dict1  \n",
       "   ...      ...  \n",
       "   79480  dict1  \n",
       "   79481  dict1  \n",
       "   79482  dict1  \n",
       "   79483  dict1  \n",
       "   79484  dict1  \n",
       "   \n",
       "   [79485 rows x 6 columns],\n",
       "   12:                                       path pattern        kana  morae  drop  \\\n",
       "   0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "   1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "   2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "   3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "   4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "   ...                                    ...     ...         ...    ...   ...   \n",
       "   79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "   79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "   79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "   79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "   79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "   \n",
       "           type  \n",
       "   0      dict1  \n",
       "   1      dict1  \n",
       "   2      dict1  \n",
       "   3      dict1  \n",
       "   4      dict1  \n",
       "   ...      ...  \n",
       "   79480  dict1  \n",
       "   79481  dict1  \n",
       "   79482  dict1  \n",
       "   79483  dict1  \n",
       "   79484  dict1  \n",
       "   \n",
       "   [79485 rows x 6 columns],\n",
       "   13:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84482 rows x 6 columns],\n",
       "   16:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84481 rows x 6 columns],\n",
       "   18:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84482 rows x 6 columns],\n",
       "   19:                           path pattern  kana  morae  drop          type\n",
       "   0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "   1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "   2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "   3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "   4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "   ...                        ...     ...   ...    ...   ...           ...\n",
       "   84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [84481 rows x 6 columns],\n",
       "   20:                                                      path pattern      kana  \\\n",
       "   0         ある-66_1_1_male.mp3dict1ある.yomi000142BB_0596.mp3    頭高頭高      あるアル   \n",
       "   1       ある-66_1_1_female.mp3dict1思う.yomi0006C617_043A.mp3    頭高中高     あるオモウ   \n",
       "   2       あります-66_2_1_male.mp3dict1など.yomi000240B7_0028.mp3    中高頭高    ありますナド   \n",
       "   3      あります-66_2_1_female.mp3dict1私.yomi00092F63_0072.mp3    中高平板  ありますワタくシ   \n",
       "   4        あって-66_3_1_male.mp3dict1見る.yomi000A41BD_001E.mp3    頭高頭高     あってミル   \n",
       "   ...                                                   ...     ...       ...   \n",
       "   84477                                                 NaN     NaN       NaN   \n",
       "   84478                                                 NaN     NaN       NaN   \n",
       "   84479                                                 NaN     NaN       NaN   \n",
       "   84480                                                 NaN     NaN       NaN   \n",
       "   84481                                                 NaN     NaN       NaN   \n",
       "   \n",
       "          morae  drop               type  \n",
       "   0        4.0   2.0    dict2 maledict1  \n",
       "   1        5.0   3.0  dict2 femaledict1  \n",
       "   2        6.0   4.0    dict2 maledict1  \n",
       "   3        8.0   3.0  dict2 femaledict1  \n",
       "   4        5.0   2.0    dict2 maledict1  \n",
       "   ...      ...   ...                ...  \n",
       "   84477    NaN   NaN                NaN  \n",
       "   84478    NaN   NaN                NaN  \n",
       "   84479    NaN   NaN                NaN  \n",
       "   84480    NaN   NaN                NaN  \n",
       "   84481    NaN   NaN                NaN  \n",
       "   \n",
       "   [84482 rows x 6 columns],\n",
       "   23:                                 path pattern  kana  morae  drop          type\n",
       "   0      dict1ある.yomi000142BB_0596.mp3      頭高    アル      2     1         dict1\n",
       "   1      dict1思う.yomi0006C617_043A.mp3      中高   オモウ      3     2         dict1\n",
       "   2      dict1など.yomi000240B7_0028.mp3      頭高    ナド      2     1         dict1\n",
       "   3       dict1私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0         dict1\n",
       "   4      dict1見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1         dict1\n",
       "   ...                              ...     ...   ...    ...   ...           ...\n",
       "   84477         立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "   84478          立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "   84479        立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "   84480          立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "   84481        立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "   \n",
       "   [163966 rows x 6 columns],\n",
       "   24: '2.3.1',\n",
       "   25: types.Voice,\n",
       "   37: {'k': 3.0},\n",
       "   43: {...}},\n",
       "  'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f354f4bc590>>,\n",
       "  'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       "  'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       "  '_': {...},\n",
       "  '__': {'k': 3.0},\n",
       "  '___': types.Voice,\n",
       "  'os': <module 'os' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/os.py'>,\n",
       "  'sys': <module 'sys' (built-in)>,\n",
       "  '__vsc_ipynb_file__': '/home/mizoru/ML/japanese-ml/get_data.ipynb',\n",
       "  '_i': 'locals()',\n",
       "  '_ii': \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "  '_iii': \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "  '_i1': \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  '_i2': 'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "  'models': <module 'fastai.vision.models' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/fastai/vision/models/__init__.py'>,\n",
       "  'multiprocessing': <module 'multiprocessing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/__init__.py'>,\n",
       "  'platform': <module 'platform' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/platform.py'>,\n",
       "  'np': <module 'numpy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/numpy/__init__.py'>,\n",
       "  'io': <module 'io' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/io.py'>,\n",
       "  'operator': <module 'operator' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/operator.py'>,\n",
       "  're': <module 're' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/re.py'>,\n",
       "  'mimetypes': <module 'mimetypes' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/mimetypes.py'>,\n",
       "  'csv': <module 'csv' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/csv.py'>,\n",
       "  'itertools': <module 'itertools' (built-in)>,\n",
       "  'json': <module 'json' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/json/__init__.py'>,\n",
       "  'shutil': <module 'shutil' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/shutil.py'>,\n",
       "  'glob': <module 'glob' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/glob.py'>,\n",
       "  'pickle': <module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>,\n",
       "  'tarfile': <module 'tarfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tarfile.py'>,\n",
       "  'collections': <module 'collections' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/collections/__init__.py'>,\n",
       "  'hashlib': <module 'hashlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/hashlib.py'>,\n",
       "  'types': <module 'types' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/types.py'>,\n",
       "  'inspect': <module 'inspect' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/inspect.py'>,\n",
       "  'functools': <module 'functools' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/functools.py'>,\n",
       "  'random': <module 'random' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/random.py'>,\n",
       "  'time': <module 'time' (built-in)>,\n",
       "  'math': <module 'math' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so'>,\n",
       "  'bz2': <module 'bz2' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/bz2.py'>,\n",
       "  'typing': <module 'typing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/typing.py'>,\n",
       "  'numbers': <module 'numbers' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/numbers.py'>,\n",
       "  'string': <module 'string' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/string.py'>,\n",
       "  'threading': <module 'threading' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/threading.py'>,\n",
       "  'urllib': <module 'urllib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/urllib/__init__.py'>,\n",
       "  'tempfile': <module 'tempfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tempfile.py'>,\n",
       "  'concurrent': <module 'concurrent' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/concurrent/__init__.py'>,\n",
       "  'matplotlib': <module 'matplotlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/__init__.py'>,\n",
       "  'warnings': <module 'warnings' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/warnings.py'>,\n",
       "  'zipfile': <module 'zipfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/zipfile.py'>,\n",
       "  'as_completed': <function concurrent.futures._base.as_completed(fs, timeout=None)>,\n",
       "  'partial': functools.partial,\n",
       "  'reduce': <function _functools.reduce>,\n",
       "  'starmap': itertools.starmap,\n",
       "  'dropwhile': itertools.dropwhile,\n",
       "  'takewhile': itertools.takewhile,\n",
       "  'zip_longest': itertools.zip_longest,\n",
       "  'copy': <function copy.copy(x)>,\n",
       "  'deepcopy': <function copy.deepcopy(x, memo=None, _nil=[])>,\n",
       "  'Lock': <bound method BaseContext.Lock of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       "  'Process': multiprocessing.context.Process,\n",
       "  'Queue': <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       "  'queues': <module 'multiprocessing.queues' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/queues.py'>,\n",
       "  'datetime': datetime.datetime,\n",
       "  'redirect_stdout': contextlib.redirect_stdout,\n",
       "  'contextmanager': <function contextlib.contextmanager(func)>,\n",
       "  'Iterable': typing.Iterable,\n",
       "  'Iterator': typing.Iterator,\n",
       "  'Generator': typing.Generator,\n",
       "  'Sequence': typing.Sequence,\n",
       "  'Union': typing.Union,\n",
       "  'Optional': typing.Optional,\n",
       "  'SimpleNamespace': types.SimpleNamespace,\n",
       "  'Path': pathlib.Path,\n",
       "  'OrderedDict': collections.OrderedDict,\n",
       "  'defaultdict': collections.defaultdict,\n",
       "  'Counter': collections.Counter,\n",
       "  'namedtuple': <function collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)>,\n",
       "  'Enum': <enum 'Enum'>,\n",
       "  'IntEnum': <enum 'IntEnum'>,\n",
       "  'TextWrapper': textwrap.TextWrapper,\n",
       "  'itemgetter': operator.itemgetter,\n",
       "  'attrgetter': operator.attrgetter,\n",
       "  'methodcaller': operator.methodcaller,\n",
       "  'urlopen': <function fastcore.net.urlopen(url, data=None, headers=None, **kwargs)>,\n",
       "  'requests': <module 'requests' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/requests/__init__.py'>,\n",
       "  'yaml': <module 'yaml' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/yaml/__init__.py'>,\n",
       "  'plt': <module 'matplotlib.pyplot' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/pyplot.py'>,\n",
       "  'pd': <module 'pandas' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/pandas/__init__.py'>,\n",
       "  'scipy': <module 'scipy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/__init__.py'>,\n",
       "  'is_categorical_dtype': <function pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype) -> 'bool'>,\n",
       "  'is_numeric_dtype': <function pandas.core.dtypes.common.is_numeric_dtype(arr_or_dtype) -> 'bool'>,\n",
       "  'array': <function numpy.array>,\n",
       "  'ndarray': numpy.ndarray,\n",
       "  'ndimage': <module 'scipy.ndimage' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/ndimage/__init__.py'>,\n",
       "  'set_trace': <function IPython.core.debugger.set_trace(frame=None)>,\n",
       "  'enum': <module 'enum' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/enum.py'>,\n",
       "  'warn': <function _warnings.warn(message, category=None, stacklevel=1, source=None)>,\n",
       "  'WrapperDescriptorType': wrapper_descriptor,\n",
       "  'MethodWrapperType': method-wrapper,\n",
       "  'MethodDescriptorType': method_descriptor,\n",
       "  'BuiltinFunctionType': builtin_function_or_method,\n",
       "  'BuiltinMethodType': builtin_function_or_method,\n",
       "  'MethodType': method,\n",
       "  'FunctionType': function,\n",
       "  'NoneType': NoneType,\n",
       "  'string_classes': (str, bytes),\n",
       "  'is_iter': <function fastai.imports.is_iter(o)>,\n",
       "  'is_coll': <function fastai.imports.is_coll(o)>,\n",
       "  'all_equal': <function fastai.imports.all_equal(a, b)>,\n",
       "  'noop': <function fastai.imports.noop(x=None, *args, **kwargs)>,\n",
       "  'noops': <function fastai.imports.noops(self, x=None, *args, **kwargs)>,\n",
       "  'any_is_instance': <function fastcore.imports.any_is_instance(t, *args)>,\n",
       "  'isinstance_str': <function fastcore.imports.isinstance_str(x, cls_name)>,\n",
       "  'array_equal': <function fastcore.imports.array_equal(a, b)>,\n",
       "  'df_equal': <function fastcore.imports.df_equal(a, b)>,\n",
       "  'equals': <function fastai.imports.equals(a, b)>,\n",
       "  'ipython_shell': <function fastcore.imports.ipython_shell()>,\n",
       "  'in_ipython': <function fastcore.imports.in_ipython()>,\n",
       "  'in_colab': <function fastcore.imports.in_colab()>,\n",
       "  'in_jupyter': <function fastcore.imports.in_jupyter()>,\n",
       "  'in_notebook': <function fastcore.imports.in_notebook()>,\n",
       "  'IN_IPYTHON': True,\n",
       "  'IN_JUPYTER': True,\n",
       "  'IN_COLAB': False,\n",
       "  'IN_NOTEBOOK': True,\n",
       "  'remove_prefix': <function fastcore.imports.remove_prefix(text, prefix)>,\n",
       "  'remove_suffix': <function fastcore.imports.remove_suffix(text, suffix)>,\n",
       "  'working_directory': <function fastcore.foundation.working_directory(path)>,\n",
       "  'add_docs': <function fastcore.foundation.add_docs(cls, cls_doc=None, **docs)>,\n",
       "  'docs': <function fastcore.foundation.docs(cls)>,\n",
       "  'coll_repr': <function fastcore.foundation.coll_repr(c, max_n=10)>,\n",
       "  'is_bool': <function fastcore.foundation.is_bool(x)>,\n",
       "  'mask2idxs': <function fastcore.foundation.mask2idxs(mask)>,\n",
       "  'cycle': <function fastcore.basics.cycle(o)>,\n",
       "  'zip_cycle': <function fastcore.basics.zip_cycle(x, *args)>,\n",
       "  'is_indexer': <function fastcore.foundation.is_indexer(idx)>,\n",
       "  'CollBase': fastcore.foundation.CollBase,\n",
       "  'L': fastcore.foundation.L,\n",
       "  'save_config_file': <function fastcore.foundation.save_config_file(file, d, **kwargs)>,\n",
       "  'read_config_file': <function fastcore.foundation.read_config_file(file, **kwargs)>,\n",
       "  'Config': fastai.data.external.Config,\n",
       "  'lenient_issubclass': <function fastcore.dispatch.lenient_issubclass(cls, types)>,\n",
       "  'sorted_topologically': <function fastcore.dispatch.sorted_topologically(iterable, *, cmp=<built-in function lt>, reverse=False)>,\n",
       "  'TypeDispatch': fastcore.dispatch.TypeDispatch,\n",
       "  'DispatchReg': fastcore.dispatch.DispatchReg,\n",
       "  'typedispatch': <fastcore.dispatch.DispatchReg at 0x7f34c6df11d0>,\n",
       "  'cast': (object,object) -> cast,\n",
       "  'retain_meta': <function fastcore.dispatch.retain_meta(x, res, as_copy=False)>,\n",
       "  'default_set_meta': <function fastcore.dispatch.default_set_meta(self, x, as_copy=False)>,\n",
       "  'retain_type': <function fastcore.dispatch.retain_type(new, old=None, typ=None, as_copy=False)>,\n",
       "  'retain_types': <function fastcore.dispatch.retain_types(new, old=None, typs=None)>,\n",
       "  'explode_types': <function fastcore.dispatch.explode_types(o)>,\n",
       "  'test_fail': <function fastcore.test.test_fail(f, msg='', contains='', args=None, kwargs=None)>,\n",
       "  'test': <function fastcore.test.test(a, b, cmp, cname=None)>,\n",
       "  'nequals': <function fastcore.test.nequals(a, b)>,\n",
       "  'test_eq': <function fastcore.test.test_eq(a, b)>,\n",
       "  'test_eq_type': <function fastcore.test.test_eq_type(a, b)>,\n",
       "  'test_ne': <function fastcore.test.test_ne(a, b)>,\n",
       "  'is_close': <function fastcore.test.is_close(a, b, eps=1e-05)>,\n",
       "  'test_close': <function fastcore.test.test_close(a, b, eps=1e-05)>,\n",
       "  'test_is': <function fastcore.test.test_is(a, b)>,\n",
       "  'test_shuffled': <function fastcore.test.test_shuffled(a, b)>,\n",
       "  'test_stdout': <function fastcore.test.test_stdout(f, exp, regex=False)>,\n",
       "  'test_warns': <function fastcore.test.test_warns(f, show=False)>,\n",
       "  'TEST_IMAGE': 'images/puppy.jpg',\n",
       "  'TEST_IMAGE_BW': 'images/mnist3.png',\n",
       "  'test_fig_exists': <function fastcore.test.test_fig_exists(ax)>,\n",
       "  'ExceptionExpected': fastcore.test.ExceptionExpected,\n",
       "  'exception': <fastcore.test.ExceptionExpected at 0x7f34c0dcc550>,\n",
       "  'defaults': namespace(cpus=4,\n",
       "            use_cuda=None,\n",
       "            activation=torch.nn.modules.activation.ReLU,\n",
       "            callbacks=[fastai.callback.core.TrainEvalCallback,\n",
       "                       fastai.learner.Recorder,\n",
       "                       fastai.callback.progress.ProgressCallback],\n",
       "            lr=0.001),\n",
       "  'ifnone': <function fastcore.basics.ifnone(a, b)>,\n",
       "  'maybe_attr': <function fastcore.basics.maybe_attr(o, attr)>,\n",
       "  'basic_repr': <function fastcore.basics.basic_repr(flds=None)>,\n",
       "  'is_array': <function fastcore.basics.is_array(x)>,\n",
       "  'listify': <function fastcore.basics.listify(o=None, *rest, use_list=False, match=None)>,\n",
       "  'tuplify': <function fastcore.basics.tuplify(o, use_list=False, match=None)>,\n",
       "  'true': <function fastcore.basics.true(*args, **kwargs)>,\n",
       "  'NullType': fastcore.basics.NullType,\n",
       "  'null': <fastcore.basics.NullType at 0x7f34c0e2dbd0>,\n",
       "  'tonull': <function fastcore.basics.tonull(x)>,\n",
       "  'get_class': <function fastcore.basics.get_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       "  'mk_class': <function fastcore.basics.mk_class(nm, *fld_names, sup=None, doc=None, funcs=None, mod=None, **flds)>,\n",
       "  'wrap_class': <function fastcore.basics.wrap_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       "  'ignore_exceptions': fastcore.basics.ignore_exceptions,\n",
       "  'exec_local': <function fastcore.basics.exec_local(code, var_name)>,\n",
       "  'risinstance': <function fastcore.basics.risinstance(types, obj=None)>,\n",
       "  'Inf': fastcore.basics.Inf,\n",
       "  'in_': <function fastcore.basics.in_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'lt': <function fastcore.basics.lt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'gt': <function fastcore.basics.gt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'le': <function fastcore.basics.le(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'ge': <function fastcore.basics.ge(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'eq': <function fastcore.basics.eq(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'ne': <function fastcore.basics.ne(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'add': <function fastcore.basics.add(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'sub': <function fastcore.basics.sub(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'mul': <function fastcore.basics.mul(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'truediv': <function fastcore.basics.truediv(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'is_': <function fastcore.basics.is_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'is_not': <function fastcore.basics.is_not(a, b=<object object at 0x7f34c27172e0>)>,\n",
       "  'stop': <function fastcore.basics.stop(e=<class 'StopIteration'>)>,\n",
       "  'gen': <function fastcore.basics.gen(func, seq, cond=<function true at 0x7f34c0e30e60>)>,\n",
       "  'chunked': <function fastcore.basics.chunked(it, chunk_sz=None, drop_last=False, n_chunks=None)>,\n",
       "  'otherwise': <function fastcore.basics.otherwise(x, tst, y)>,\n",
       "  'custom_dir': <function fastcore.basics.custom_dir(c, add)>,\n",
       "  'AttrDict': fastcore.basics.AttrDict,\n",
       "  'type_hints': <function fastcore.basics.type_hints(f)>,\n",
       "  'annotations': <function fastcore.basics.annotations(o)>,\n",
       "  'anno_ret': <function fastcore.basics.anno_ret(func)>,\n",
       "  'argnames': <function fastcore.basics.argnames(f, frame=False)>,\n",
       "  'with_cast': <function fastcore.basics.with_cast(f)>,\n",
       "  'store_attr': <function fastcore.basics.store_attr(names=None, self=None, but='', cast=False, store_args=None, **attrs)>,\n",
       "  'attrdict': <function fastcore.basics.attrdict(o, *ks, default=None)>,\n",
       "  'properties': <function fastcore.basics.properties(cls, *ps)>,\n",
       "  'camel2words': <function fastcore.basics.camel2words(s, space=' ')>,\n",
       "  'camel2snake': <function fastcore.basics.camel2snake(name)>,\n",
       "  'snake2camel': <function fastcore.basics.snake2camel(s)>,\n",
       "  'class2attr': <function fastcore.basics.class2attr(self, cls_name)>,\n",
       "  'getattrs': <function fastcore.basics.getattrs(o, *attrs, default=None)>,\n",
       "  'hasattrs': <function fastcore.basics.hasattrs(o, attrs)>,\n",
       "  'setattrs': <function fastcore.basics.setattrs(dest, flds, src)>,\n",
       "  'try_attrs': <function fastcore.basics.try_attrs(obj, *attrs)>,\n",
       "  'GetAttrBase': fastcore.basics.GetAttrBase,\n",
       "  'GetAttr': fastcore.basics.GetAttr,\n",
       "  'delegate_attr': <function fastcore.basics.delegate_attr(self, k, to)>,\n",
       "  'ShowPrint': fastcore.basics.ShowPrint,\n",
       "  'Int': fastcore.basics.Int,\n",
       "  'Str': fastcore.basics.Str,\n",
       "  'Float': fastcore.basics.Float,\n",
       "  'concat': <function fastai.torch_core.concat(*ls)>,\n",
       "  'strcat': <function fastcore.basics.strcat(its, sep: str = '') -> str>,\n",
       "  'detuplify': <function fastcore.basics.detuplify(x)>,\n",
       "  'replicate': <function fastcore.basics.replicate(item, match)>,\n",
       "  'setify': <function fastcore.basics.setify(o)>,\n",
       "  'merge': <function fastcore.basics.merge(*ds)>,\n",
       "  'range_of': <function fastcore.basics.range_of(a, b=None, step=None)>,\n",
       "  'groupby': <function fastcore.basics.groupby(x, key, val=<function noop at 0x7f34c0dfed40>)>,\n",
       "  'last_index': <function fastcore.basics.last_index(x, o)>,\n",
       "  'filter_dict': <function fastcore.basics.filter_dict(d, func)>,\n",
       "  'filter_keys': <function fastcore.basics.filter_keys(d, func)>,\n",
       "  'filter_values': <function fastcore.basics.filter_values(d, func)>,\n",
       "  'sorted_ex': <function fastcore.basics.sorted_ex(iterable, key=None, reverse=False)>,\n",
       "  'not_': <function fastcore.basics.not_(f)>,\n",
       "  'argwhere': <function fastcore.basics.argwhere(iterable, f, negate=False, **kwargs)>,\n",
       "  'filter_ex': <function fastcore.basics.filter_ex(iterable, f=<function noop at 0x7f34c0dfed40>, negate=False, gen=False, **kwargs)>,\n",
       "  'renumerate': <function fastcore.basics.renumerate(iterable, start=0)>,\n",
       "  'first': <function fastcore.basics.first(x, f=None, negate=False, **kwargs)>,\n",
       "  'nested_attr': <function fastcore.basics.nested_attr(o, attr, default=None)>,\n",
       "  'nested_idx': <function fastcore.basics.nested_idx(coll, *idxs)>,\n",
       "  'val2idx': <function fastcore.basics.val2idx(x)>,\n",
       "  'uniqueify': <function fastcore.basics.uniqueify(x, sort=False, bidir=False, start=None)>,\n",
       "  'num_methods': ['__add__',\n",
       "   '__sub__',\n",
       "   '__mul__',\n",
       "   '__matmul__',\n",
       "   '__truediv__',\n",
       "   '__floordiv__',\n",
       "   '__mod__',\n",
       "   '__divmod__',\n",
       "   '__pow__',\n",
       "   '__lshift__',\n",
       "   '__rshift__',\n",
       "   '__and__',\n",
       "   '__xor__',\n",
       "   '__or__',\n",
       "   '__neg__',\n",
       "   '__pos__',\n",
       "   '__abs__'],\n",
       "  'rnum_methods': ['__radd__',\n",
       "   '__rsub__',\n",
       "   '__rmul__',\n",
       "   '__rmatmul__',\n",
       "   '__rtruediv__',\n",
       "   '__rfloordiv__',\n",
       "   '__rmod__',\n",
       "   '__rdivmod__',\n",
       "   '__rpow__',\n",
       "   '__rlshift__',\n",
       "   '__rrshift__',\n",
       "   '__rand__',\n",
       "   '__rxor__',\n",
       "   '__ror__'],\n",
       "  'inum_methods': ['__iadd__',\n",
       "   '__isub__',\n",
       "   '__imul__',\n",
       "   '__imatmul__',\n",
       "   '__itruediv__',\n",
       "   '__ifloordiv__',\n",
       "   '__imod__',\n",
       "   '__ipow__',\n",
       "   '__ilshift__',\n",
       "   '__irshift__',\n",
       "   '__iand__',\n",
       "   '__ixor__',\n",
       "   '__ior__'],\n",
       "  'fastuple': fastcore.basics.fastuple,\n",
       "  'arg0': <fastcore.basics._Arg at 0x7f34c0dbc410>,\n",
       "  'arg1': <fastcore.basics._Arg at 0x7f34c0dbc450>,\n",
       "  'arg2': <fastcore.basics._Arg at 0x7f34c0dbc490>,\n",
       "  'arg3': <fastcore.basics._Arg at 0x7f34c0dbc4d0>,\n",
       "  'arg4': <fastcore.basics._Arg at 0x7f34c0dbc510>,\n",
       "  'bind': fastcore.basics.bind,\n",
       "  'mapt': <function fastcore.basics.mapt(func, *iterables)>,\n",
       "  'map_ex': <function fastcore.basics.map_ex(iterable, f, *args, gen=False, **kwargs)>,\n",
       "  'compose': <function fastcore.basics.compose(*funcs, order=None)>,\n",
       "  'maps': <function fastcore.basics.maps(*args, retain=<function noop at 0x7f34c0dfed40>)>,\n",
       "  'partialler': <function fastcore.basics.partialler(f, *args, order=None, **kwargs)>,\n",
       "  'instantiate': <function fastcore.basics.instantiate(t)>,\n",
       "  'using_attr': <function fastcore.basics.using_attr(f, attr)>,\n",
       "  'Self': <fastcore.basics._SelfCls at 0x7f34c0dbc5d0>,\n",
       "  'copy_func': <function fastcore.basics.copy_func(f)>,\n",
       "  'patch_to': <function fastcore.basics.patch_to(cls, as_prop=False, cls_method=False)>,\n",
       "  'patch': <function fastcore.basics.patch(f=None, *, as_prop=False, cls_method=False)>,\n",
       "  'patch_property': <function fastcore.basics.patch_property(f)>,\n",
       "  'ImportEnum': <enum 'ImportEnum'>,\n",
       "  'StrEnum': <enum 'StrEnum'>,\n",
       "  'str_enum': <function fastcore.basics.str_enum(name, *vals)>,\n",
       "  'Stateful': fastcore.basics.Stateful,\n",
       "  'PrettyString': fastcore.basics.PrettyString,\n",
       "  'even_mults': <function fastcore.basics.even_mults(start, stop, n)>,\n",
       "  'num_cpus': <function fastcore.basics.num_cpus()>,\n",
       "  'add_props': <function fastcore.basics.add_props(f, g=None, n=2)>,\n",
       "  'typed': <function fastcore.basics.typed(f)>,\n",
       "  'dict2obj': <function fastcore.xtras.dict2obj(d)>,\n",
       "  'obj2dict': <function fastcore.xtras.obj2dict(d)>,\n",
       "  'repr_dict': <function fastcore.xtras.repr_dict(d)>,\n",
       "  'is_listy': <function fastcore.xtras.is_listy(x)>,\n",
       "  'shufflish': <function fastcore.xtras.shufflish(x, pct=0.04)>,\n",
       "  'mapped': <function fastcore.xtras.mapped(f, it)>,\n",
       "  'IterLen': fastcore.xtras.IterLen,\n",
       "  'ReindexCollection': fastcore.xtras.ReindexCollection,\n",
       "  'maybe_open': <function fastcore.xtras.maybe_open(f, mode='r', **kwargs)>,\n",
       "  'image_size': <function fastcore.xtras.image_size(fn)>,\n",
       "  'bunzip': <function fastcore.xtras.bunzip(fn)>,\n",
       "  'join_path_file': <function fastcore.xtras.join_path_file(file, path, ext='')>,\n",
       "  'loads': <function fastcore.xtras.loads(s, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)>,\n",
       "  'loads_multi': <function fastcore.xtras.loads_multi(s: str)>,\n",
       "  'untar_dir': <function fastcore.xtras.untar_dir(file, dest)>,\n",
       "  'repo_details': <function fastcore.xtras.repo_details(url)>,\n",
       "  'run': <function fastcore.xtras.run(cmd, *rest, same_in_win=False, ignore_ex=False, as_bytes=False, stderr=False)>,\n",
       "  'open_file': <function fastcore.xtras.open_file(fn, mode='r', **kwargs)>,\n",
       "  'save_pickle': <function fastcore.xtras.save_pickle(fn, o)>,\n",
       "  'load_pickle': <function fastcore.xtras.load_pickle(fn)>,\n",
       "  'truncstr': <function fastcore.xtras.truncstr(s: str, maxlen: int, suf: str = '…', space='') -> str>,\n",
       "  'spark_chars': '▁▂▃▅▆▇',\n",
       "  'sparkline': <function fastcore.xtras.sparkline(data, mn=None, mx=None, empty_zero=False)>,\n",
       "  'autostart': <function fastcore.xtras.autostart(g)>,\n",
       "  'EventTimer': fastcore.xtras.EventTimer,\n",
       "  'stringfmt_names': <function fastcore.xtras.stringfmt_names(s: str) -> list>,\n",
       "  'PartialFormatter': fastcore.xtras.PartialFormatter,\n",
       "  'partial_format': <function fastcore.xtras.partial_format(s: str, **kwargs)>,\n",
       "  'utc2local': <function fastcore.xtras.utc2local(dt: datetime.datetime) -> datetime.datetime>,\n",
       "  'local2utc': <function fastcore.xtras.local2utc(dt: datetime.datetime) -> datetime.datetime>,\n",
       "  'trace': <function fastcore.xtras.trace(f)>,\n",
       "  'round_multiple': <function fastcore.xtras.round_multiple(x, mult, round_down=False)>,\n",
       "  'modified_env': <function fastcore.xtras.modified_env(*delete, **replace)>,\n",
       "  'ContextManagers': fastcore.xtras.ContextManagers,\n",
       "  'str2bool': <function fastcore.xtras.str2bool(s)>,\n",
       "  'sort_by_run': <function fastcore.xtras.sort_by_run(fs)>,\n",
       "  'threaded': <function fastcore.parallel.threaded(f)>,\n",
       "  'startthread': <function fastcore.parallel.startthread(f)>,\n",
       "  'set_num_threads': <function fastcore.parallel.set_num_threads(nt)>,\n",
       "  'parallelable': <function fastcore.parallel.parallelable(param_name, num_workers, f=None)>,\n",
       "  'ThreadPoolExecutor': fastcore.parallel.ThreadPoolExecutor,\n",
       "  'ProcessPoolExecutor': fastcore.parallel.ProcessPoolExecutor,\n",
       "  'parallel': <function fastcore.parallel.parallel(f, items, *args, n_workers=4, total=None, progress=None, pause=0, threadpool=False, timeout=None, chunksize=1, **kwargs)>,\n",
       "  'add_one': <function fastcore.parallel.add_one(x, a=1)>,\n",
       "  'run_procs': <function fastcore.parallel.run_procs(f, f_done, args)>,\n",
       "  'parallel_gen': <function fastcore.parallel.parallel_gen(cls, items, n_workers=4, **kwargs)>,\n",
       "  'url_default_headers': {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
       "   'Accept-Language': 'en-US,en;q=0.9',\n",
       "   'Cache-Control': 'max-age=0',\n",
       "   'Sec-Fetch-Dest': 'document',\n",
       "   'Sec-Fetch-Mode': 'navigate',\n",
       "   'Sec-Fetch-Site': 'none',\n",
       "   'Sec-Fetch-User': '?1',\n",
       "   'Upgrade-Insecure-Requests': '1',\n",
       "   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'},\n",
       "  'urlquote': <function fastcore.net.urlquote(url)>,\n",
       "  'urlwrap': <function fastcore.net.urlwrap(url, data=None, headers=None)>,\n",
       "  'ExceptionsHTTP': {400: fastcore.basics.HTTP400BadRequestError,\n",
       "   401: fastcore.basics.HTTP401UnauthorizedError,\n",
       "   402: fastcore.basics.HTTP402PaymentRequiredError,\n",
       "   403: fastcore.basics.HTTP403ForbiddenError,\n",
       "   404: fastcore.basics.HTTP404NotFoundError,\n",
       "   405: fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "   406: fastcore.basics.HTTP406NotAcceptableError,\n",
       "   407: fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "   408: fastcore.basics.HTTP408RequestTimeoutError,\n",
       "   409: fastcore.basics.HTTP409ConflictError,\n",
       "   410: fastcore.basics.HTTP410GoneError,\n",
       "   411: fastcore.basics.HTTP411LengthRequiredError,\n",
       "   412: fastcore.basics.HTTP412PreconditionFailedError,\n",
       "   413: fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "   414: fastcore.basics.HTTP414URITooLongError,\n",
       "   415: fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "   416: fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "   417: fastcore.basics.HTTP417ExpectationFailedError,\n",
       "   418: fastcore.basics.HTTP418AmAteapotError,\n",
       "   421: fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "   422: fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "   423: fastcore.basics.HTTP423LockedError,\n",
       "   424: fastcore.basics.HTTP424FailedDependencyError,\n",
       "   425: fastcore.basics.HTTP425TooEarlyError,\n",
       "   426: fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "   428: fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "   429: fastcore.basics.HTTP429TooManyRequestsError,\n",
       "   431: fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "   451: fastcore.basics.HTTP451LegalReasonsError},\n",
       "  'HTTP4xxClientError': fastcore.net.HTTP4xxClientError,\n",
       "  'HTTP5xxServerError': fastcore.net.HTTP5xxServerError,\n",
       "  'HTTP400BadRequestError': fastcore.basics.HTTP400BadRequestError,\n",
       "  'HTTP401UnauthorizedError': fastcore.basics.HTTP401UnauthorizedError,\n",
       "  'HTTP402PaymentRequiredError': fastcore.basics.HTTP402PaymentRequiredError,\n",
       "  'HTTP403ForbiddenError': fastcore.basics.HTTP403ForbiddenError,\n",
       "  'HTTP404NotFoundError': fastcore.basics.HTTP404NotFoundError,\n",
       "  'HTTP405MethodNotAllowedError': fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "  'HTTP406NotAcceptableError': fastcore.basics.HTTP406NotAcceptableError,\n",
       "  'HTTP407ProxyAuthRequiredError': fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "  'HTTP408RequestTimeoutError': fastcore.basics.HTTP408RequestTimeoutError,\n",
       "  'HTTP409ConflictError': fastcore.basics.HTTP409ConflictError,\n",
       "  'HTTP410GoneError': fastcore.basics.HTTP410GoneError,\n",
       "  'HTTP411LengthRequiredError': fastcore.basics.HTTP411LengthRequiredError,\n",
       "  'HTTP412PreconditionFailedError': fastcore.basics.HTTP412PreconditionFailedError,\n",
       "  'HTTP413PayloadTooLargeError': fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "  'HTTP414URITooLongError': fastcore.basics.HTTP414URITooLongError,\n",
       "  'HTTP415UnsupportedMediaTypeError': fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "  'HTTP416RangeNotSatisfiableError': fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "  'HTTP417ExpectationFailedError': fastcore.basics.HTTP417ExpectationFailedError,\n",
       "  'HTTP418AmAteapotError': fastcore.basics.HTTP418AmAteapotError,\n",
       "  'HTTP421MisdirectedRequestError': fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "  'HTTP422UnprocessableEntityError': fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "  'HTTP423LockedError': fastcore.basics.HTTP423LockedError,\n",
       "  'HTTP424FailedDependencyError': fastcore.basics.HTTP424FailedDependencyError,\n",
       "  'HTTP425TooEarlyError': fastcore.basics.HTTP425TooEarlyError,\n",
       "  'HTTP426UpgradeRequiredError': fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "  'HTTP428PreconditionRequiredError': fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "  'HTTP429TooManyRequestsError': fastcore.basics.HTTP429TooManyRequestsError,\n",
       "  'HTTP431HeaderFieldsTooLargeError': fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "  'HTTP451LegalReasonsError': fastcore.basics.HTTP451LegalReasonsError,\n",
       "  'urlread': <function fastcore.net.urlread(url, data=None, headers=None, decode=True, return_json=False, return_headers=False, **kwargs)>,\n",
       "  'urljson': <function fastcore.net.urljson(url, data=None)>,\n",
       "  'urlcheck': <function fastcore.net.urlcheck(url, timeout=10)>,\n",
       "  'urlclean': <function fastcore.net.urlclean(url)>,\n",
       "  'urlsave': <function fastcore.net.urlsave(url, dest=None)>,\n",
       "  'urlvalid': <function fastcore.net.urlvalid(x)>,\n",
       "  'urlrequest': <function fastcore.net.urlrequest(url, verb, headers=None, route=None, query=None, data=None, json_data=True)>,\n",
       "  'urlsend': <function fastcore.net.urlsend(url, verb, headers=None, route=None, query=None, data=None, json_data=True, return_json=True, return_headers=False, debug=None)>,\n",
       "  'do_request': <function fastcore.net.do_request(url, post=False, headers=None, **data)>,\n",
       "  'start_server': <function fastcore.net.start_server(port, host=None, dgram=False, reuse_addr=True, n_queue=None)>,\n",
       "  'start_client': <function fastcore.net.start_client(port, host=None, dgram=False)>,\n",
       "  'Transform': fastcore.transform.Transform,\n",
       "  'InplaceTransform': fastcore.transform.InplaceTransform,\n",
       "  'DisplayedTransform': fastcore.transform.DisplayedTransform,\n",
       "  'ItemTransform': fastcore.transform.ItemTransform,\n",
       "  'get_func': <function fastcore.transform.get_func(t, name, *args, **kwargs)>,\n",
       "  'Func': fastcore.transform.Func,\n",
       "  'Sig': <fastcore.transform._Sig at 0x7f34c0d37590>,\n",
       "  'compose_tfms': <function fastcore.transform.compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs)>,\n",
       "  'mk_transform': <function fastcore.transform.mk_transform(f)>,\n",
       "  'gather_attrs': <function fastcore.transform.gather_attrs(o, k, nm)>,\n",
       "  'gather_attr_names': <function fastcore.transform.gather_attr_names(o, nm)>,\n",
       "  'Pipeline': fastcore.transform.Pipeline,\n",
       "  'test_sig': <function fastcore.meta.test_sig(f, b)>,\n",
       "  'FixSigMeta': fastcore.meta.FixSigMeta,\n",
       "  'PrePostInitMeta': fastcore.meta.PrePostInitMeta,\n",
       "  'AutoInit': fastcore.meta.AutoInit,\n",
       "  'NewChkMeta': fastcore.meta.NewChkMeta,\n",
       "  'BypassNewMeta': fastcore.meta.BypassNewMeta,\n",
       "  'empty2none': <function fastcore.meta.empty2none(p)>,\n",
       "  'anno_dict': <function fastcore.meta.anno_dict(f)>,\n",
       "  'use_kwargs_dict': <function fastcore.meta.use_kwargs_dict(keep=False, **kwargs)>,\n",
       "  'use_kwargs': <function fastcore.meta.use_kwargs(names, keep=False)>,\n",
       "  'delegates': <function fastcore.meta.delegates(to=None, keep=False, but=None)>,\n",
       "  'method': <function fastcore.meta.method(f)>,\n",
       "  'funcs_kwargs': <function fastcore.meta.funcs_kwargs(as_method=False)>,\n",
       "  'store_true': <function fastcore.script.store_true()>,\n",
       "  'store_false': <function fastcore.script.store_false()>,\n",
       "  'bool_arg': <function fastcore.script.bool_arg(v)>,\n",
       "  'clean_type_str': <function fastcore.script.clean_type_str(x: str)>,\n",
       "  'Param': fastcore.script.Param,\n",
       "  'anno_parser': <function fastcore.script.anno_parser(func, prog=None, from_name=False)>,\n",
       "  'args_from_prog': <function fastcore.script.args_from_prog(func, prog)>,\n",
       "  'SCRIPT_INFO': namespace(func=None),\n",
       "  'call_parse': <function fastcore.script.call_parse(func)>,\n",
       "  'progress_bar': fastprogress.fastprogress.NBProgressBar,\n",
       "  'master_bar': fastprogress.fastprogress.NBMasterBar,\n",
       "  'LambdaType': function,\n",
       "  'one_is_instance': <function fastai.imports.one_is_instance(a, b, t)>,\n",
       "  'pv': <function fastai.imports.pv(text, verbose)>,\n",
       "  'torch': <module 'torch' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/__init__.py'>,\n",
       "  'as_tensor': <function _VariableFunctionsClass.as_tensor>,\n",
       "  'Tensor': torch.Tensor,\n",
       "  'ByteTensor': torch.ByteTensor,\n",
       "  'LongTensor': torch.LongTensor,\n",
       "  'FloatTensor': torch.FloatTensor,\n",
       "  'HalfTensor': torch.HalfTensor,\n",
       "  'DoubleTensor': torch.DoubleTensor,\n",
       "  'nn': <module 'torch.nn' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/__init__.py'>,\n",
       "  'F': <module 'torch.nn.functional' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/functional.py'>,\n",
       "  'SequentialSampler': torch.utils.data.sampler.SequentialSampler,\n",
       "  'RandomSampler': torch.utils.data.sampler.RandomSampler,\n",
       "  'Sampler': torch.utils.data.sampler.Sampler,\n",
       "  'BatchSampler': torch.utils.data.sampler.BatchSampler,\n",
       "  'IterableDataset': torch.utils.data.dataset.IterableDataset,\n",
       "  'get_worker_info': <function torch.utils.data._utils.worker.get_worker_info()>,\n",
       "  'default_collate': <function torch.utils.data._utils.collate.default_collate(batch)>,\n",
       "  'default_convert': <function torch.utils.data._utils.collate.default_convert(data)>,\n",
       "  'subplots': <function fastai.torch_core.subplots(nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **kwargs)>,\n",
       "  'show_image': <function fastai.torch_core.show_image(im, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       "  'show_titled_image': <function fastai.torch_core.show_titled_image(o, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       "  'show_images': <function fastai.torch_core.show_images(ims, nrows=1, ncols=None, titles=None, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       "  'ArrayBase': fastai.torch_core.ArrayBase,\n",
       "  'ArrayImageBase': fastai.torch_core.ArrayImageBase,\n",
       "  'ArrayImage': fastai.torch_core.ArrayImage,\n",
       "  'ArrayImageBW': fastai.torch_core.ArrayImageBW,\n",
       "  'ArrayMask': fastai.torch_core.ArrayMask,\n",
       "  'tensor': <function fastai.torch_core.tensor(x, *rest, dtype=None, device=None, requires_grad=False, pin_memory=False)>,\n",
       "  'set_seed': <function fastai.torch_core.set_seed(s, reproducible=False)>,\n",
       "  'get_random_states': <function fastai.torch_core.get_random_states()>,\n",
       "  'set_random_states': <function fastai.torch_core.set_random_states(random_state, numpy_state, torch_state, torch_cuda_state, torch_deterministic, torch_benchmark)>,\n",
       "  'no_random': <function fastai.torch_core.no_random(seed=42, reproducible=True)>,\n",
       "  'unsqueeze': <function fastai.torch_core.unsqueeze(x, dim=-1, n=1)>,\n",
       "  'unsqueeze_': <function fastai.torch_core.unsqueeze_(x, dim=-1, n=1)>,\n",
       "  'apply': <function fastai.torch_core.apply(func, x, *args, **kwargs)>,\n",
       "  'maybe_gather': <function fastai.torch_core.maybe_gather(x, axis=0)>,\n",
       "  'to_detach': <function fastai.torch_core.to_detach(b, cpu=True, gather=True)>,\n",
       "  'to_half': <function fastai.torch_core.to_half(b)>,\n",
       "  'to_float': <function fastai.torch_core.to_float(b)>,\n",
       "  'default_device': <function fastai.torch_core.default_device(use_cuda=-1)>,\n",
       "  'to_device': <function fastai.torch_core.to_device(b, device=None, non_blocking=False)>,\n",
       "  'to_cpu': <function fastai.torch_core.to_cpu(b)>,\n",
       "  'to_np': <function fastai.torch_core.to_np(x)>,\n",
       "  'to_concat': <function fastai.torch_core.to_concat(xs, dim=0)>,\n",
       "  'TensorBase': fastai.torch_core.TensorBase,\n",
       "  'TensorImageBase': fastai.torch_core.TensorImageBase,\n",
       "  'TensorImage': fastai.torch_core.TensorImage,\n",
       "  'TensorImageBW': fastai.torch_core.TensorImageBW,\n",
       "  'TensorMask': fastai.torch_core.TensorMask,\n",
       "  'TensorFlowField': fastai.torch_core.TensorFlowField,\n",
       "  'TensorCategory': fastai.torch_core.TensorCategory,\n",
       "  'TensorMultiCategory': fastai.torch_core.TensorMultiCategory,\n",
       "  'TitledTensorScalar': fastai.torch_core.TitledTensorScalar,\n",
       "  'Chunks': fastai.torch_core.Chunks,\n",
       "  'show_title': <function fastai.torch_core.show_title(o, ax=None, ctx=None, label=None, color='black', **kwargs)>,\n",
       "  'ShowTitle': fastai.torch_core.ShowTitle,\n",
       "  'TitledInt': fastai.torch_core.TitledInt,\n",
       "  'TitledFloat': fastai.torch_core.TitledFloat,\n",
       "  'TitledStr': fastai.torch_core.TitledStr,\n",
       "  'TitledTuple': fastai.torch_core.TitledTuple,\n",
       "  'get_empty_df': <function fastai.torch_core.get_empty_df(n)>,\n",
       "  'display_df': <function fastai.torch_core.display_df(df)>,\n",
       "  'get_first': <function fastai.torch_core.get_first(c)>,\n",
       "  'one_param': <function fastai.torch_core.one_param(m)>,\n",
       "  'item_find': <function fastai.torch_core.item_find(x, idx=0)>,\n",
       "  'find_device': <function fastai.torch_core.find_device(b)>,\n",
       "  'find_bs': <function fastai.torch_core.find_bs(b)>,\n",
       "  'np_func': <function fastai.torch_core.np_func(f)>,\n",
       "  'Module': fastai.torch_core.Module,\n",
       "  'get_model': <function fastai.torch_core.get_model(model)>,\n",
       "  'one_hot': <function fastai.torch_core.one_hot(x, c)>,\n",
       "  'one_hot_decode': <function fastai.torch_core.one_hot_decode(x, vocab=None)>,\n",
       "  'params': <function fastai.torch_core.params(m)>,\n",
       "  'trainable_params': <function fastai.torch_core.trainable_params(m)>,\n",
       "  'norm_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "   torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "   torch.nn.modules.batchnorm.BatchNorm3d,\n",
       "   torch.nn.modules.instancenorm.InstanceNorm1d,\n",
       "   torch.nn.modules.instancenorm.InstanceNorm2d,\n",
       "   torch.nn.modules.instancenorm.InstanceNorm3d,\n",
       "   torch.nn.modules.normalization.LayerNorm),\n",
       "  'norm_bias_params': <function fastai.torch_core.norm_bias_params(m, with_bias=True)>,\n",
       "  'batch_to_samples': <function fastai.torch_core.batch_to_samples(b, max_n=10)>,\n",
       "  'logit': <function fastai.torch_core.logit(x)>,\n",
       "  'num_distrib': <function fastai.torch_core.num_distrib()>,\n",
       "  'rank_distrib': <function fastai.torch_core.rank_distrib()>,\n",
       "  'distrib_barrier': <function fastai.torch_core.distrib_barrier()>,\n",
       "  'base_doc': <function fastai.torch_core.base_doc(elt)>,\n",
       "  'doc': <function fastai.torch_core.doc(elt)>,\n",
       "  'nested_reorder': <function fastai.torch_core.nested_reorder(t, idxs)>,\n",
       "  'make_cross_image': <function fastai.torch_core.make_cross_image(bw=True)>,\n",
       "  'show_image_batch': <function fastai.torch_core.show_image_batch(b, show=<function show_titled_image at 0x7f34c0cf3170>, items=9, cols=3, figsize=None, **kwargs)>,\n",
       "  'requires_grad': <function fastai.torch_core.requires_grad(m)>,\n",
       "  'init_default': <function fastai.layers.init_default(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "  'cond_init': <function fastai.torch_core.cond_init(m, func)>,\n",
       "  'apply_leaf': <function fastai.torch_core.apply_leaf(m, f)>,\n",
       "  'apply_init': <function fastai.torch_core.apply_init(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "  'script_use_ctx': <function fastai.torch_core.script_use_ctx(f)>,\n",
       "  'script_save_ctx': <function fastai.torch_core.script_save_ctx(static, *argidx)>,\n",
       "  'script_fwd': <function fastai.torch_core.script_fwd(*argidx)>,\n",
       "  'script_bwd': <function fastai.torch_core.script_bwd(f)>,\n",
       "  'grad_module': <function fastai.torch_core.grad_module(cls)>,\n",
       "  'flatten_check': <function fastai.torch_core.flatten_check(inp, targ)>,\n",
       "  'module': <function fastai.layers.module(*flds, **defaults)>,\n",
       "  'Identity': fastai.layers.Identity,\n",
       "  'Lambda': fastai.layers.Lambda,\n",
       "  'PartialLambda': fastai.layers.PartialLambda,\n",
       "  'Flatten': fastai.layers.Flatten,\n",
       "  'View': fastai.layers.View,\n",
       "  'ResizeBatch': fastai.layers.ResizeBatch,\n",
       "  'Debugger': fastai.layers.Debugger,\n",
       "  'sigmoid_range': <function fastai.layers.sigmoid_range(x, low, high)>,\n",
       "  'SigmoidRange': fastai.layers.SigmoidRange,\n",
       "  'AdaptiveConcatPool1d': fastai.layers.AdaptiveConcatPool1d,\n",
       "  'AdaptiveConcatPool2d': fastai.layers.AdaptiveConcatPool2d,\n",
       "  'PoolType': fastai.layers.PoolType,\n",
       "  'adaptive_pool': <function fastai.layers.adaptive_pool(pool_type)>,\n",
       "  'PoolFlatten': fastai.layers.PoolFlatten,\n",
       "  'NormType': <enum 'NormType'>,\n",
       "  'BatchNorm': <function fastai.layers.BatchNorm(nf, ndim=2, norm_type=<NormType.Batch: 1>, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)>,\n",
       "  'InstanceNorm': <function fastai.layers.InstanceNorm(nf, ndim=2, norm_type=<NormType.Instance: 5>, affine=True, eps: float = 1e-05, momentum: float = 0.1, track_running_stats: bool = False)>,\n",
       "  'BatchNorm1dFlat': fastai.layers.BatchNorm1dFlat,\n",
       "  'LinBnDrop': fastai.layers.LinBnDrop,\n",
       "  'sigmoid': <function fastai.layers.sigmoid(input, eps=1e-07)>,\n",
       "  'sigmoid_': <function fastai.layers.sigmoid_(input, eps=1e-07)>,\n",
       "  'vleaky_relu': <function fastai.layers.vleaky_relu(input, inplace=True)>,\n",
       "  'init_linear': <function fastai.layers.init_linear(m, act_func=None, init='auto', bias_std=0.01)>,\n",
       "  'ConvLayer': fastai.layers.ConvLayer,\n",
       "  'AdaptiveAvgPool': <function fastai.layers.AdaptiveAvgPool(sz=1, ndim=2)>,\n",
       "  'MaxPool': <function fastai.layers.MaxPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       "  'AvgPool': <function fastai.layers.AvgPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       "  'trunc_normal_': <function fastai.layers.trunc_normal_(x, mean=0.0, std=1.0)>,\n",
       "  'Embedding': fastai.layers.Embedding,\n",
       "  'SelfAttention': fastai.layers.SelfAttention,\n",
       "  'PooledSelfAttention2d': fastai.layers.PooledSelfAttention2d,\n",
       "  'SimpleSelfAttention': fastai.layers.SimpleSelfAttention,\n",
       "  'icnr_init': <function fastai.layers.icnr_init(x, scale=2, init=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       "  'PixelShuffle_ICNR': fastai.layers.PixelShuffle_ICNR,\n",
       "  'sequential': <function fastai.layers.sequential(*args)>,\n",
       "  'SequentialEx': fastai.layers.SequentialEx,\n",
       "  'MergeLayer': fastai.layers.MergeLayer,\n",
       "  'Cat': fastai.layers.Cat,\n",
       "  'SimpleCNN': fastai.layers.SimpleCNN,\n",
       "  'ProdLayer': fastai.layers.ProdLayer,\n",
       "  'inplace_relu': functools.partial(<class 'torch.nn.modules.activation.ReLU'>, inplace=True),\n",
       "  'SEModule': <function fastai.layers.SEModule(ch, reduction, act_cls=<class 'torch.nn.modules.activation.ReLU'>)>,\n",
       "  'ResBlock': fastai.layers.ResBlock,\n",
       "  'SEBlock': <function fastai.layers.SEBlock(expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)>,\n",
       "  'SEResNeXtBlock': <function fastai.layers.SEResNeXtBlock(expansion, ni, nf, groups=32, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       "  'SeparableBlock': <function fastai.layers.SeparableBlock(expansion, ni, nf, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       "  'TimeDistributed': fastai.layers.TimeDistributed,\n",
       "  'swish': <function fastai.layers.swish(x, inplace=False)>,\n",
       "  'Swish': fastai.layers.Swish,\n",
       "  'MishJitAutoFn': fastai.layers.MishJitAutoFn,\n",
       "  'mish': <function fastai.layers.mish(x)>,\n",
       "  'Mish': fastai.layers.Mish,\n",
       "  'ParameterModule': fastai.layers.ParameterModule,\n",
       "  'children_and_parameters': <function fastai.layers.children_and_parameters(m)>,\n",
       "  'has_children': <function fastai.layers.has_children(m)>,\n",
       "  'flatten_model': <function fastai.layers.flatten_model(m)>,\n",
       "  'NoneReduce': fastai.layers.NoneReduce,\n",
       "  'in_channels': <function fastai.layers.in_channels(m)>,\n",
       "  'BaseLoss': fastai.losses.BaseLoss,\n",
       "  'CrossEntropyLossFlat': fastai.losses.CrossEntropyLossFlat,\n",
       "  'FocalLossFlat': fastai.losses.FocalLossFlat,\n",
       "  'BCEWithLogitsLossFlat': fastai.losses.BCEWithLogitsLossFlat,\n",
       "  'BCELossFlat': <function fastai.losses.BCELossFlat(*args, axis=-1, floatify=True, weight=None, reduction='mean')>,\n",
       "  'MSELossFlat': <function fastai.losses.MSELossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       "  'L1LossFlat': <function fastai.losses.L1LossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       "  'LabelSmoothingCrossEntropy': fastai.losses.LabelSmoothingCrossEntropy,\n",
       "  'LabelSmoothingCrossEntropyFlat': fastai.losses.LabelSmoothingCrossEntropyFlat,\n",
       "  'show_batch': (TensorImage,TensorImage) -> show_batch\n",
       "  (TensorImage,object) -> show_batch\n",
       "  (AudioTensor,object) -> show_batch\n",
       "  (AudioSpectrogram,object) -> show_batch\n",
       "  (object,object) -> show_batch,\n",
       "  'show_results': (TensorImage,TensorCategory) -> show_results\n",
       "  (TensorImage,TensorMask) -> show_results\n",
       "  (TensorImage,TensorBBox) -> show_results\n",
       "  (TensorImage,TensorPoint) -> show_results\n",
       "  (TensorImage,TensorImage) -> show_results\n",
       "  (TensorImage,object) -> show_results\n",
       "  (object,object) -> show_results,\n",
       "  'TfmdDL': fastai.data.core.TfmdDL,\n",
       "  'DataLoaders': fastai.data.core.DataLoaders,\n",
       "  'FilteredBase': fastai.data.core.FilteredBase,\n",
       "  'TfmdLists': fastai.data.core.TfmdLists,\n",
       "  'decode_at': <function fastai.data.core.decode_at(o, idx)>,\n",
       "  'show_at': <function fastai.data.core.show_at(o, idx, **kwargs)>,\n",
       "  'Datasets': fastai.data.core.Datasets,\n",
       "  'test_set': <function fastai.data.core.test_set(dsets, test_items, rm_tfms=None, with_labels=False)>,\n",
       "  'fa_collate': <function fastai.data.load.fa_collate(t)>,\n",
       "  'fa_convert': <function fastai.data.load.fa_convert(t)>,\n",
       "  'SkipItemException': fastai.data.load.SkipItemException,\n",
       "  'DataLoader': fastai.data.load.DataLoader,\n",
       "  'URLs': fastai.data.external.URLs,\n",
       "  'download_url': <function fastai.data.external.download_url(url, dest, overwrite=False, pbar=None, show_progress=True, chunk_size=1048576, timeout=4, retries=5)>,\n",
       "  'download_data': <function fastai.data.external.download_data(url, fname=None, c_key='archive', force_download=False, timeout=4)>,\n",
       "  'file_extract': <function fastai.data.external.file_extract(fname, dest=None)>,\n",
       "  'newest_folder': <function fastai.data.external.newest_folder(path)>,\n",
       "  'rename_extracted': <function fastai.data.external.rename_extracted(dest)>,\n",
       "  'untar_data': <function fastai.data.external.untar_data(url, fname=None, dest=None, c_key='data', force_download=False, extract_func=<function file_extract at 0x7f34bf3bec20>, timeout=4)>,\n",
       "  'get_files': <function fastai.data.transforms.get_files(path, extensions=None, recurse=True, folders=None, followlinks=True)>,\n",
       "  'FileGetter': <function fastai.data.transforms.FileGetter(suf='', extensions=None, recurse=True, folders=None)>,\n",
       "  'image_extensions': {'.art',\n",
       "   '.bmp',\n",
       "   '.cdr',\n",
       "   '.cdt',\n",
       "   '.cpt',\n",
       "   '.cr2',\n",
       "   '.crw',\n",
       "   '.djv',\n",
       "   '.djvu',\n",
       "   '.erf',\n",
       "   '.gif',\n",
       "   '.ico',\n",
       "   '.ief',\n",
       "   '.jng',\n",
       "   '.jp2',\n",
       "   '.jpe',\n",
       "   '.jpeg',\n",
       "   '.jpf',\n",
       "   '.jpg',\n",
       "   '.jpg2',\n",
       "   '.jpm',\n",
       "   '.jpx',\n",
       "   '.nef',\n",
       "   '.orf',\n",
       "   '.pat',\n",
       "   '.pbm',\n",
       "   '.pcx',\n",
       "   '.pgm',\n",
       "   '.png',\n",
       "   '.pnm',\n",
       "   '.ppm',\n",
       "   '.psd',\n",
       "   '.ras',\n",
       "   '.rgb',\n",
       "   '.svg',\n",
       "   '.svgz',\n",
       "   '.tif',\n",
       "   '.tiff',\n",
       "   '.wbmp',\n",
       "   '.xbm',\n",
       "   '.xpm',\n",
       "   '.xwd'},\n",
       "  'get_image_files': <function fastai.data.transforms.get_image_files(path, recurse=True, folders=None)>,\n",
       "  'ImageGetter': <function fastai.data.transforms.ImageGetter(suf='', recurse=True, folders=None)>,\n",
       "  'get_text_files': <function fastai.data.transforms.get_text_files(path, recurse=True, folders=None)>,\n",
       "  'ItemGetter': fastai.data.transforms.ItemGetter,\n",
       "  'AttrGetter': fastai.data.transforms.AttrGetter,\n",
       "  'RandomSplitter': <function fastai.data.transforms.RandomSplitter(valid_pct=0.2, seed=None)>,\n",
       "  'TrainTestSplitter': <function fastai.data.transforms.TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, train_size=None, shuffle=True)>,\n",
       "  'IndexSplitter': <function fastai.data.transforms.IndexSplitter(valid_idx)>,\n",
       "  'GrandparentSplitter': <function fastai.data.transforms.GrandparentSplitter(train_name='train', valid_name='valid')>,\n",
       "  'FuncSplitter': <function fastai.data.transforms.FuncSplitter(func)>,\n",
       "  'MaskSplitter': <function fastai.data.transforms.MaskSplitter(mask)>,\n",
       "  'FileSplitter': <function fastai.data.transforms.FileSplitter(fname)>,\n",
       "  'ColSplitter': <function fastai.data.transforms.ColSplitter(col='is_valid')>,\n",
       "  'RandomSubsetSplitter': <function fastai.data.transforms.RandomSubsetSplitter(train_sz, valid_sz, seed=None)>,\n",
       "  'parent_label': <function fastai.data.transforms.parent_label(o)>,\n",
       "  'RegexLabeller': fastai.data.transforms.RegexLabeller,\n",
       "  'ColReader': fastai.data.transforms.ColReader,\n",
       "  'CategoryMap': fastai.data.transforms.CategoryMap,\n",
       "  'Categorize': fastai.data.transforms.Categorize,\n",
       "  'Category': fastai.data.transforms.Category,\n",
       "  'MultiCategorize': fastai.data.transforms.MultiCategorize,\n",
       "  'MultiCategory': fastai.data.transforms.MultiCategory,\n",
       "  'OneHotEncode': fastai.data.transforms.OneHotEncode,\n",
       "  'EncodedMultiCategorize': fastai.data.transforms.EncodedMultiCategorize,\n",
       "  'RegressionSetup': fastai.data.transforms.RegressionSetup,\n",
       "  'get_c': <function fastai.data.transforms.get_c(dls)>,\n",
       "  'ToTensor': fastai.data.transforms.ToTensor,\n",
       "  'IntToFloatTensor': fastai.data.transforms.IntToFloatTensor,\n",
       "  'broadcast_vec': <function fastai.data.transforms.broadcast_vec(dim, ndim, *t, cuda=True)>,\n",
       "  'Normalize': fastai.data.transforms.Normalize,\n",
       "  'TransformBlock': fastai.data.block.TransformBlock,\n",
       "  'CategoryBlock': <function fastai.data.block.CategoryBlock(vocab=None, sort=True, add_na=False)>,\n",
       "  'MultiCategoryBlock': <function fastai.data.block.MultiCategoryBlock(encoded=False, vocab=None, add_na=False)>,\n",
       "  'RegressionBlock': <function fastai.data.block.RegressionBlock(n_out=None)>,\n",
       "  'DataBlock': fastai.data.block.DataBlock,\n",
       "  'Optimizer': fastai.optimizer.Optimizer,\n",
       "  'sgd_step': <function fastai.optimizer.sgd_step(p, lr, **kwargs)>,\n",
       "  'weight_decay': <function fastai.optimizer.weight_decay(p, lr, wd, do_wd=True, **kwargs)>,\n",
       "  'l2_reg': <function fastai.optimizer.l2_reg(p, lr, wd, do_wd=True, **kwargs)>,\n",
       "  'average_grad': <function fastai.optimizer.average_grad(p, mom, dampening=False, grad_avg=None, **kwargs)>,\n",
       "  'average_sqr_grad': <function fastai.optimizer.average_sqr_grad(p, sqr_mom, dampening=True, sqr_avg=None, **kwargs)>,\n",
       "  'momentum_step': <function fastai.optimizer.momentum_step(p, lr, grad_avg, **kwargs)>,\n",
       "  'SGD': <function fastai.optimizer.SGD(params, lr, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       "  'rms_prop_step': <function fastai.optimizer.rms_prop_step(p, lr, sqr_avg, eps, grad_avg=None, **kwargs)>,\n",
       "  'RMSProp': <function fastai.optimizer.RMSProp(params, lr, sqr_mom=0.99, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       "  'step_stat': <function fastai.optimizer.step_stat(p, step=0, **kwargs)>,\n",
       "  'debias': <function fastai.optimizer.debias(mom, damp, step)>,\n",
       "  'adam_step': <function fastai.optimizer.adam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       "  'Adam': <function fastai.optimizer.Adam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.01, decouple_wd=True)>,\n",
       "  'radam_step': <function fastai.optimizer.radam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, beta, **kwargs)>,\n",
       "  'RAdam': <function fastai.optimizer.RAdam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, beta=0.0, decouple_wd=True)>,\n",
       "  'qhadam_step': <function fastai.optimizer.qhadam_step(p, lr, mom, sqr_mom, sqr_avg, nu_1, nu_2, step, grad_avg, eps, **kwargs)>,\n",
       "  'QHAdam': <function fastai.optimizer.QHAdam(params, lr, mom=0.999, sqr_mom=0.999, nu_1=0.7, nu_2=1.0, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       "  'larc_layer_lr': <function fastai.optimizer.larc_layer_lr(p, lr, trust_coeff, wd, eps, clip=True, **kwargs)>,\n",
       "  'larc_step': <function fastai.optimizer.larc_step(p, local_lr, grad_avg=None, **kwargs)>,\n",
       "  'Larc': <function fastai.optimizer.Larc(params, lr, mom=0.9, clip=True, trust_coeff=0.02, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       "  'lamb_step': <function fastai.optimizer.lamb_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       "  'Lamb': <function fastai.optimizer.Lamb(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, decouple_wd=True)>,\n",
       "  'Lookahead': fastai.optimizer.Lookahead,\n",
       "  'ranger': <function fastai.optimizer.ranger(p, lr, mom=0.95, wd=0.01, eps=1e-06, sqr_mom=0.99, beta=0.0, decouple_wd=True)>,\n",
       "  'detuplify_pg': <function fastai.optimizer.detuplify_pg(d)>,\n",
       "  'set_item_pg': <function fastai.optimizer.set_item_pg(pg, k, v)>,\n",
       "  'pytorch_hp_map': {'momentum': 'mom',\n",
       "   'weight_decay': 'wd',\n",
       "   'alpha': 'sqr_mom',\n",
       "   'betas__0': 'mom',\n",
       "   'betas__1': 'sqr_mom'},\n",
       "  'OptimWrapper': fastai.optimizer.OptimWrapper,\n",
       "  'CancelStepException': fastcore.basics.CancelStepException,\n",
       "  'CancelFitException': fastcore.basics.CancelFitException,\n",
       "  'CancelEpochException': fastcore.basics.CancelEpochException,\n",
       "  'CancelTrainException': fastcore.basics.CancelTrainException,\n",
       "  'CancelValidException': fastcore.basics.CancelValidException,\n",
       "  'CancelBatchException': fastcore.basics.CancelBatchException,\n",
       "  'event': fastcore.basics.event,\n",
       "  'Callback': fastai.callback.core.Callback,\n",
       "  'TrainEvalCallback': fastai.callback.core.TrainEvalCallback,\n",
       "  'GatherPredsCallback': fastai.callback.core.GatherPredsCallback,\n",
       "  'FetchPredsCallback': fastai.callback.core.FetchPredsCallback,\n",
       "  'replacing_yield': <function fastai.learner.replacing_yield(o, attr, val)>,\n",
       "  'mk_metric': <function fastai.learner.mk_metric(m)>,\n",
       "  'save_model': <function fastai.learner.save_model(file, model, opt, with_opt=True, pickle_protocol=2)>,\n",
       "  'load_model': <function fastai.learner.load_model(file, model, opt, with_opt=True, device=None, strict=True)>,\n",
       "  'Learner': fastai.learner.Learner,\n",
       "  'before_batch_cb': <function fastai.learner.before_batch_cb(f)>,\n",
       "  'load_learner': <function fastai.learner.load_learner(fname, cpu=True, pickle_module=<module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>)>,\n",
       "  'to_detach_from_dl': <function fastai.learner.to_detach_from_dl(learn: (<class 'fastai.learner.Learner'>, <class 'NoneType'>), b: object, cpu: bool = True, gather: bool = True)>,\n",
       "  'Metric': fastai.learner.Metric,\n",
       "  'AvgMetric': fastai.learner.AvgMetric,\n",
       "  'AvgLoss': fastai.learner.AvgLoss,\n",
       "  'AvgSmoothLoss': fastai.learner.AvgSmoothLoss,\n",
       "  'ValueMetric': fastai.learner.ValueMetric,\n",
       "  'Recorder': fastai.learner.Recorder,\n",
       "  'AccumMetric': fastai.metrics.AccumMetric,\n",
       "  'skm_to_fastai': <function fastai.metrics.skm_to_fastai(func, is_class=True, thresh=None, axis=-1, activation=None, **kwargs)>,\n",
       "  'optim_metric': <function fastai.metrics.optim_metric(f, argname, bounds, tol=0.01, do_neg=True, get_x=False)>,\n",
       "  'accuracy': <function fastai.metrics.accuracy(inp, targ, axis=-1)>,\n",
       "  'error_rate': <function fastai.metrics.error_rate(inp, targ, axis=-1)>,\n",
       "  'top_k_accuracy': <function fastai.metrics.top_k_accuracy(inp, targ, k=5, axis=-1)>,\n",
       "  'APScoreBinary': <function fastai.metrics.APScoreBinary(axis=-1, average='macro', pos_label=1, sample_weight=None)>,\n",
       "  'BalancedAccuracy': <function fastai.metrics.BalancedAccuracy(axis=-1, sample_weight=None, adjusted=False)>,\n",
       "  'BrierScore': <function fastai.metrics.BrierScore(axis=-1, sample_weight=None, pos_label=None)>,\n",
       "  'CohenKappa': <function fastai.metrics.CohenKappa(axis=-1, labels=None, weights=None, sample_weight=None)>,\n",
       "  'F1Score': <function fastai.metrics.F1Score(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "  'FBeta': <function fastai.metrics.FBeta(beta, axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "  'HammingLoss': <function fastai.metrics.HammingLoss(axis=-1, sample_weight=None)>,\n",
       "  'Jaccard': <function fastai.metrics.Jaccard(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "  'Precision': <function fastai.metrics.Precision(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "  'Recall': <function fastai.metrics.Recall(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       "  'RocAuc': <function fastai.metrics.RocAuc(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='ovr')>,\n",
       "  'RocAucBinary': <function fastai.metrics.RocAucBinary(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='raise')>,\n",
       "  'MatthewsCorrCoef': <function fastai.metrics.MatthewsCorrCoef(sample_weight=None, **kwargs)>,\n",
       "  'Perplexity': fastai.metrics.Perplexity,\n",
       "  'perplexity': <fastai.metrics.Perplexity at 0x7f34b7101810>,\n",
       "  'accuracy_multi': <function fastai.metrics.accuracy_multi(inp, targ, thresh=0.5, sigmoid=True)>,\n",
       "  'APScoreMulti': <function fastai.metrics.APScoreMulti(sigmoid=True, average='macro', pos_label=1, sample_weight=None)>,\n",
       "  'BrierScoreMulti': <function fastai.metrics.BrierScoreMulti(thresh=0.5, sigmoid=True, sample_weight=None, pos_label=None)>,\n",
       "  'F1ScoreMulti': <function fastai.metrics.F1ScoreMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "  'FBetaMulti': <function fastai.metrics.FBetaMulti(beta, thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "  'HammingLossMulti': <function fastai.metrics.HammingLossMulti(thresh=0.5, sigmoid=True, labels=None, sample_weight=None)>,\n",
       "  'JaccardMulti': <function fastai.metrics.JaccardMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "  'MatthewsCorrCoefMulti': <function fastai.metrics.MatthewsCorrCoefMulti(thresh=0.5, sigmoid=True, sample_weight=None)>,\n",
       "  'PrecisionMulti': <function fastai.metrics.PrecisionMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "  'RecallMulti': <function fastai.metrics.RecallMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       "  'RocAucMulti': <function fastai.metrics.RocAucMulti(sigmoid=True, average='macro', sample_weight=None, max_fpr=None)>,\n",
       "  'mse': <function fastai.metrics.mse(inp, targ)>,\n",
       "  'rmse': <fastai.metrics.AccumMetric at 0x7f34b7101850>,\n",
       "  'mae': <function fastai.metrics.mae(inp, targ)>,\n",
       "  'msle': <function fastai.metrics.msle(inp, targ)>,\n",
       "  'exp_rmspe': <fastai.metrics.AccumMetric at 0x7f34b71018d0>,\n",
       "  'ExplainedVariance': <function fastai.metrics.ExplainedVariance(sample_weight=None)>,\n",
       "  'R2Score': <function fastai.metrics.R2Score(sample_weight=None)>,\n",
       "  'PearsonCorrCoef': <function fastai.metrics.PearsonCorrCoef(dim_argmax=None, activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       "  'SpearmanCorrCoef': <function fastai.metrics.SpearmanCorrCoef(dim_argmax=None, axis=0, nan_policy='propagate', activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       "  'foreground_acc': <function fastai.metrics.foreground_acc(inp, targ, bkg_idx=0, axis=1)>,\n",
       "  'Dice': fastai.metrics.Dice,\n",
       "  'DiceMulti': fastai.metrics.DiceMulti,\n",
       "  'JaccardCoeff': fastai.metrics.JaccardCoeff,\n",
       "  'CorpusBLEUMetric': fastai.metrics.CorpusBLEUMetric,\n",
       "  'LossMetric': fastai.metrics.LossMetric,\n",
       "  'LossMetrics': <function fastai.metrics.LossMetrics(attrs, nms=None)>,\n",
       "  'plot_top_losses': (TensorImage,TensorMultiCategory) -> plot_top_losses\n",
       "  (TensorImage,TensorCategory) -> plot_top_losses\n",
       "  (TensorImage,TensorMask) -> plot_top_losses\n",
       "  (object,object) -> plot_top_losses,\n",
       "  'Interpretation': fastai.interpret.Interpretation,\n",
       "  'ClassificationInterpretation': fastai.interpret.ClassificationInterpretation,\n",
       "  'SegmentationInterpretation': fastai.interpret.SegmentationInterpretation,\n",
       "  'CollectDataCallback': fastai.callback.data.CollectDataCallback,\n",
       "  'WeightedDL': fastai.callback.data.WeightedDL,\n",
       "  'PartialDL': fastai.callback.data.PartialDL,\n",
       "  'MixedPrecision': fastai.callback.fp16.MixedPrecision,\n",
       "  'FP16TestCallback': fastai.callback.fp16.FP16TestCallback,\n",
       "  'get_master': <function fastai.callback.fp16.get_master(opt, flat_master=False)>,\n",
       "  'to_master_grads': <function fastai.callback.fp16.to_master_grads(model_pgs, master_pgs, flat_master=False)>,\n",
       "  'to_model_params': <function fastai.callback.fp16.to_model_params(model_pgs, master_pgs, flat_master=False) -> None>,\n",
       "  'test_overflow': <function fastai.callback.fp16.test_overflow(x)>,\n",
       "  'grad_overflow': <function fastai.callback.fp16.grad_overflow(pgs)>,\n",
       "  'copy_clone': <function fastai.callback.fp16.copy_clone(d)>,\n",
       "  'ModelToHalf': fastai.callback.fp16.ModelToHalf,\n",
       "  'NonNativeMixedPrecision': fastai.callback.fp16.NonNativeMixedPrecision,\n",
       "  'Hook': fastai.callback.hook.Hook,\n",
       "  'hook_output': <function fastai.callback.hook.hook_output(module, detach=True, cpu=False, grad=False)>,\n",
       "  'Hooks': fastai.callback.hook.Hooks,\n",
       "  'hook_outputs': <function fastai.callback.hook.hook_outputs(modules, detach=True, cpu=False, grad=False)>,\n",
       "  'dummy_eval': <function fastai.callback.hook.dummy_eval(m, size=(64, 64))>,\n",
       "  'model_sizes': <function fastai.callback.hook.model_sizes(m, size=(64, 64))>,\n",
       "  'num_features_model': <function fastai.callback.hook.num_features_model(m)>,\n",
       "  'has_params': <function fastai.callback.hook.has_params(m)>,\n",
       "  'HookCallback': fastai.callback.hook.HookCallback,\n",
       "  'total_params': <function fastai.callback.hook.total_params(m)>,\n",
       "  'layer_info': <function fastai.callback.hook.layer_info(learn, *xb)>,\n",
       "  'module_summary': <function fastai.callback.hook.module_summary(learn, *xb)>,\n",
       "  'ActivationStats': fastai.callback.hook.ActivationStats,\n",
       "  'reduce_loss': <function fastai.callback.mixup.reduce_loss(loss, reduction='mean')>,\n",
       "  'MixHandler': fastai.callback.mixup.MixHandler,\n",
       "  'MixUp': fastai.callback.mixup.MixUp,\n",
       "  'CutMix': fastai.callback.mixup.CutMix,\n",
       "  'ProgressCallback': fastai.callback.progress.ProgressCallback,\n",
       "  'ShowGraphCallback': fastai.callback.progress.ShowGraphCallback,\n",
       "  'CSVLogger': fastai.callback.progress.CSVLogger,\n",
       "  'annealer': <function fastai.callback.schedule.annealer(f)>,\n",
       "  'sched_lin': <function fastai.callback.schedule.sched_lin(start, end, pos)>,\n",
       "  'sched_cos': <function fastai.callback.schedule.sched_cos(start, end, pos)>,\n",
       "  'sched_no': <function fastai.callback.schedule.sched_no(start, end, pos)>,\n",
       "  'sched_exp': <function fastai.callback.schedule.sched_exp(start, end, pos)>,\n",
       "  'SchedLin': <function fastai.callback.schedule.SchedLin(start, end)>,\n",
       "  'SchedCos': <function fastai.callback.schedule.SchedCos(start, end)>,\n",
       "  'SchedNo': <function fastai.callback.schedule.SchedNo(start, end)>,\n",
       "  'SchedExp': <function fastai.callback.schedule.SchedExp(start, end)>,\n",
       "  'SchedPoly': <function fastai.callback.schedule.SchedPoly(start, end, power)>,\n",
       "  'combine_scheds': <function fastai.callback.schedule.combine_scheds(pcts, scheds)>,\n",
       "  'combined_cos': <function fastai.callback.schedule.combined_cos(pct, start, middle, end)>,\n",
       "  'ParamScheduler': fastai.callback.schedule.ParamScheduler,\n",
       "  'LRFinder': fastai.callback.schedule.LRFinder,\n",
       "  'SuggestedLRs': fastai.callback.schedule.SuggestedLRs,\n",
       "  'TerminateOnNaNCallback': fastai.callback.tracker.TerminateOnNaNCallback,\n",
       "  'TrackerCallback': fastai.callback.tracker.TrackerCallback,\n",
       "  'EarlyStoppingCallback': fastai.callback.tracker.EarlyStoppingCallback,\n",
       "  'SaveModelCallback': fastai.callback.tracker.SaveModelCallback,\n",
       "  'ReduceLROnPlateau': fastai.callback.tracker.ReduceLROnPlateau,\n",
       "  'ModelResetter': fastai.callback.rnn.ModelResetter,\n",
       "  'RNNCallback': fastai.callback.rnn.RNNCallback,\n",
       "  'RNNRegularizer': fastai.callback.rnn.RNNRegularizer,\n",
       "  'rnn_cbs': <function fastai.callback.rnn.rnn_cbs(alpha=0.0, beta=0.0)>,\n",
       "  'ShortEpochCallback': fastai.callback.training.ShortEpochCallback,\n",
       "  'GradientAccumulation': fastai.callback.training.GradientAccumulation,\n",
       "  'GradientClip': fastai.callback.training.GradientClip,\n",
       "  'set_bn_eval': <function fastai.callback.training.set_bn_eval(m: torch.nn.modules.module.Module, use_eval=True) -> None>,\n",
       "  'BnFreeze': fastai.callback.training.BnFreeze,\n",
       "  'bn_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "   torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "   torch.nn.modules.batchnorm.BatchNorm3d),\n",
       "  'MCDropoutCallback': fastai.callback.preds.MCDropoutCallback,\n",
       "  'RandTransform': fastai.vision.augment.RandTransform,\n",
       "  'TensorTypes': (fastai.torch_core.TensorImage,\n",
       "   fastai.torch_core.TensorMask,\n",
       "   fastai.vision.core.TensorPoint,\n",
       "   fastai.vision.core.TensorBBox),\n",
       "  'FlipItem': fastai.vision.augment.FlipItem,\n",
       "  'DihedralItem': fastai.vision.augment.DihedralItem,\n",
       "  'PadMode': fastcore.basics.PadMode,\n",
       "  'CropPad': fastai.vision.augment.CropPad,\n",
       "  'RandomCrop': fastai.vision.augment.RandomCrop,\n",
       "  'OldRandomCrop': fastai.vision.augment.OldRandomCrop,\n",
       "  'ResizeMethod': fastcore.basics.ResizeMethod,\n",
       "  'Resize': fastai.vision.augment.Resize,\n",
       "  'RandomResizedCrop': fastai.vision.augment.RandomResizedCrop,\n",
       "  'RatioResize': fastai.vision.augment.RatioResize,\n",
       "  'affine_grid': <function fastai.vision.augment.affine_grid(theta, size, align_corners=None)>,\n",
       "  'AffineCoordTfm': fastai.vision.augment.AffineCoordTfm,\n",
       "  'RandomResizedCropGPU': fastai.vision.augment.RandomResizedCropGPU,\n",
       "  'mask_tensor': <function fastai.vision.augment.mask_tensor(x, p=0.5, neutral=0.0, batch=False)>,\n",
       "  'affine_mat': <function fastai.vision.augment.affine_mat(*ms)>,\n",
       "  'flip_mat': <function fastai.vision.augment.flip_mat(x, p=0.5, draw=None, batch=False)>,\n",
       "  'Flip': fastai.vision.augment.Flip,\n",
       "  'DeterministicDraw': fastai.vision.augment.DeterministicDraw,\n",
       "  'DeterministicFlip': fastai.vision.augment.DeterministicFlip,\n",
       "  'dihedral_mat': <function fastai.vision.augment.dihedral_mat(x, p=0.5, draw=None, batch=False)>,\n",
       "  'Dihedral': fastai.vision.augment.Dihedral,\n",
       "  'DeterministicDihedral': fastai.vision.augment.DeterministicDihedral,\n",
       "  'rotate_mat': <function fastai.vision.augment.rotate_mat(x, max_deg=10, p=0.5, draw=None, batch=False)>,\n",
       "  'Rotate': fastai.vision.augment.Rotate,\n",
       "  'zoom_mat': <function fastai.vision.augment.zoom_mat(x, min_zoom=1.0, max_zoom=1.1, p=0.5, draw=None, draw_x=None, draw_y=None, batch=False)>,\n",
       "  'Zoom': fastai.vision.augment.Zoom,\n",
       "  'find_coeffs': <function fastai.vision.augment.find_coeffs(p1, p2)>,\n",
       "  'apply_perspective': <function fastai.vision.augment.apply_perspective(coords, coeffs)>,\n",
       "  'Warp': fastai.vision.augment.Warp,\n",
       "  'SpaceTfm': fastai.vision.augment.SpaceTfm,\n",
       "  'LightingTfm': fastai.vision.augment.LightingTfm,\n",
       "  'Brightness': fastai.vision.augment.Brightness,\n",
       "  'Contrast': fastai.vision.augment.Contrast,\n",
       "  'grayscale': <function fastai.vision.augment.grayscale(x)>,\n",
       "  'Saturation': fastai.vision.augment.Saturation,\n",
       "  'rgb2hsv': <function fastai.vision.augment.rgb2hsv(img)>,\n",
       "  'hsv2rgb': <function fastai.vision.augment.hsv2rgb(img)>,\n",
       "  'HSVTfm': fastai.vision.augment.HSVTfm,\n",
       "  'Hue': fastai.vision.augment.Hue,\n",
       "  'cutout_gaussian': <function fastai.vision.augment.cutout_gaussian(x, areas)>,\n",
       "  'norm_apply_denorm': <function fastai.vision.augment.norm_apply_denorm(x, f, nrm)>,\n",
       "  'RandomErasing': fastai.vision.augment.RandomErasing,\n",
       "  'setup_aug_tfms': <function fastai.vision.augment.setup_aug_tfms(tfms)>,\n",
       "  'aug_transforms': <function fastai.vision.augment.aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=None, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0)>,\n",
       "  'Image': <module 'PIL.Image' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/PIL/Image.py'>,\n",
       "  'imagenet_stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
       "  'cifar_stats': ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261]),\n",
       "  'mnist_stats': ([0.131], [0.308]),\n",
       "  'n_px': None,\n",
       "  'shape': None,\n",
       "  'aspect': None,\n",
       "  'to_image': <function fastai.vision.core.to_image(x)>,\n",
       "  'load_image': <function fastai.vision.core.load_image(fn, mode=None)>,\n",
       "  'image2tensor': <function fastai.vision.core.image2tensor(img)>,\n",
       "  'PILBase': fastai.vision.core.PILBase,\n",
       "  'PILImage': fastai.vision.core.PILImage,\n",
       "  'PILImageBW': fastai.vision.core.PILImageBW,\n",
       "  'PILMask': fastai.vision.core.PILMask,\n",
       "  'OpenMask': PILBase.create:\n",
       "  encodes: (Path,object) -> create\n",
       "  (str,object) -> create\n",
       "  (Tensor,object) -> create\n",
       "  (ndarray,object) -> create\n",
       "  (bytes,object) -> createdecodes: ,\n",
       "  'AddMaskCodes': fastai.vision.core.AddMaskCodes,\n",
       "  'TensorPoint': fastai.vision.core.TensorPoint,\n",
       "  'TensorPointCreate': TensorPoint.create:\n",
       "  encodes: (object,object) -> createdecodes: ,\n",
       "  'get_annotations': <function fastai.vision.core.get_annotations(fname, prefix=None)>,\n",
       "  'TensorBBox': fastai.vision.core.TensorBBox,\n",
       "  'LabeledBBox': fastai.vision.core.LabeledBBox,\n",
       "  'encodes': <function fastai.vision.core.encodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       "  'PointScaler': fastai.vision.core.PointScaler,\n",
       "  'BBoxLabeler': fastai.vision.core.BBoxLabeler,\n",
       "  'decodes': <function fastai.vision.core.decodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       "  'get_grid': <function fastai.vision.data.get_grid(n, nrows=None, ncols=None, add_vert=0, figsize=None, double=False, title=None, return_fig=False, flatten=True, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       "  'clip_remove_empty': <function fastai.vision.data.clip_remove_empty(bbox, label)>,\n",
       "  'bb_pad': <function fastai.vision.data.bb_pad(samples, pad_idx=0)>,\n",
       "  'ImageBlock': <function fastai.vision.data.ImageBlock(cls=<class 'fastai.vision.core.PILImage'>)>,\n",
       "  'MaskBlock': <function fastai.vision.data.MaskBlock(codes=None)>,\n",
       "  'PointBlock': <fastai.data.block.TransformBlock at 0x7f34b7020410>,\n",
       "  'BBoxBlock': <fastai.data.block.TransformBlock at 0x7f34b7093850>,\n",
       "  'BBoxLblBlock': <function fastai.vision.data.BBoxLblBlock(vocab=None, add_na=True)>,\n",
       "  'ImageDataLoaders': fastai.vision.data.ImageDataLoaders,\n",
       "  'SegmentationDataLoaders': fastai.vision.data.SegmentationDataLoaders,\n",
       "  'init_cnn': <function fastai.vision.models.xresnet.init_cnn(m)>,\n",
       "  'XResNet': fastai.vision.models.xresnet.XResNet,\n",
       "  'xresnet18': <function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>,\n",
       "  'xresnet34': <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>,\n",
       "  'xresnet50': <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>,\n",
       "  'xresnet101': <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>,\n",
       "  'xresnet152': <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>,\n",
       "  'xresnet18_deep': <function fastai.vision.models.xresnet.xresnet18_deep(pretrained=False, **kwargs)>,\n",
       "  'xresnet34_deep': <function fastai.vision.models.xresnet.xresnet34_deep(pretrained=False, **kwargs)>,\n",
       "  'xresnet50_deep': <function fastai.vision.models.xresnet.xresnet50_deep(pretrained=False, **kwargs)>,\n",
       "  'xresnet18_deeper': <function fastai.vision.models.xresnet.xresnet18_deeper(pretrained=False, **kwargs)>,\n",
       "  'xresnet34_deeper': <function fastai.vision.models.xresnet.xresnet34_deeper(pretrained=False, **kwargs)>,\n",
       "  'xresnet50_deeper': <function fastai.vision.models.xresnet.xresnet50_deeper(pretrained=False, **kwargs)>,\n",
       "  'se_kwargs1': {'groups': 1, 'reduction': 16},\n",
       "  'se_kwargs2': {'groups': 32, 'reduction': 16},\n",
       "  'se_kwargs3': {'groups': 32, 'reduction': 0},\n",
       "  'g0': [2, 2, 2, 2],\n",
       "  'g1': [3, 4, 6, 3],\n",
       "  'g2': [3, 4, 23, 3],\n",
       "  'g3': [3, 8, 36, 3],\n",
       "  'xse_resnet18': <function fastai.vision.models.xresnet.xse_resnet18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext18': <function fastai.vision.models.xresnet.xse_resnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xresnext18': <function fastai.vision.models.xresnet.xresnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnet34': <function fastai.vision.models.xresnet.xse_resnet34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext34': <function fastai.vision.models.xresnet.xse_resnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xresnext34': <function fastai.vision.models.xresnet.xresnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnet50': <function fastai.vision.models.xresnet.xse_resnet50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext50': <function fastai.vision.models.xresnet.xse_resnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xresnext50': <function fastai.vision.models.xresnet.xresnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnet101': <function fastai.vision.models.xresnet.xse_resnet101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext101': <function fastai.vision.models.xresnet.xse_resnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xresnext101': <function fastai.vision.models.xresnet.xresnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnet152': <function fastai.vision.models.xresnet.xse_resnet152(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xsenet154': <function fastai.vision.models.xresnet.xsenet154(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext18_deep': <function fastai.vision.models.xresnet.xse_resnext18_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext34_deep': <function fastai.vision.models.xresnet.xse_resnext34_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext50_deep': <function fastai.vision.models.xresnet.xse_resnext50_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext18_deeper': <function fastai.vision.models.xresnet.xse_resnext18_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext34_deeper': <function fastai.vision.models.xresnet.xse_resnext34_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'xse_resnext50_deeper': <function fastai.vision.models.xresnet.xse_resnext50_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       "  'UnetBlock': fastai.vision.models.unet.UnetBlock,\n",
       "  'ResizeToOrig': fastai.vision.models.unet.ResizeToOrig,\n",
       "  'DynamicUnet': fastai.vision.models.unet.DynamicUnet,\n",
       "  'ResNet': torchvision.models.resnet.ResNet,\n",
       "  'resnet18': <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "  'resnet34': <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "  'resnet50': <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "  'resnet101': <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "  'resnet152': <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       "  'SqueezeNet': torchvision.models.squeezenet.SqueezeNet,\n",
       "  'squeezenet1_0': <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       "  'squeezenet1_1': <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       "  'densenet121': <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "  'densenet169': <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "  'densenet201': <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "  'densenet161': <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       "  'vgg11_bn': <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "  'vgg13_bn': <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "  'vgg16_bn': <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "  'vgg19_bn': <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       "  'alexnet': <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>,\n",
       "  'has_pool_type': <function fastai.vision.learner.has_pool_type(m)>,\n",
       "  'create_body': <function fastai.vision.learner.create_body(arch, n_in=3, pretrained=True, cut=None)>,\n",
       "  'create_head': <function fastai.vision.learner.create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "  'default_split': <function fastai.vision.learner.default_split(m)>,\n",
       "  'model_meta': {<function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "    'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "    'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "    'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "    'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "    'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "    'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "    'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "    'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "    'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "    'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "    'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "   <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>: {'cut': -2,\n",
       "    'split': <function fastai.vision.learner._alexnet_split(m: torch.nn.modules.module.Module)>,\n",
       "    'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])}},\n",
       "  'create_cnn_model': <function fastai.vision.learner.create_cnn_model(arch, n_out, pretrained=True, cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "  'cnn_learner': <function fastai.vision.learner.cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       "  'create_unet_model': <function fastai.vision.learner.create_unet_model(arch, n_out, img_size, pretrained=True, cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       "  'unet_learner': <function fastai.vision.learner.unet_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       "  'download_images': <function fastai.vision.utils.download_images(dest, url_file=None, urls=None, max_pics=1000, n_workers=8, timeout=4, preserve_filename=False)>,\n",
       "  'resize_to': <function fastai.vision.utils.resize_to(img, targ_sz, use_min=False)>,\n",
       "  'verify_image': <function fastai.vision.utils.verify_image(fn)>,\n",
       "  'verify_images': <function fastai.vision.utils.verify_images(fns)>,\n",
       "  'resize_image': <function fastai.vision.utils.resize_image(file, dest, max_size=None, n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=False, **kwargs)>,\n",
       "  'resize_images': <function fastai.vision.utils.resize_images(path, max_workers=4, max_size=None, recurse=False, dest=Path('.'), n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=None, **kwargs)>,\n",
       "  'transforms': <module 'torchaudio.transforms' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/transforms.py'>,\n",
       "  'make_dataclass': <function dataclasses.make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)>,\n",
       "  'signature': <function inspect.signature(obj, *, follow_wrapped=True)>,\n",
       "  'save_audio': <function torchaudio.backend.sox_io_backend.save(filepath: str, src: torch.Tensor, sample_rate: int, channels_first: bool = True, compression: Union[float, NoneType] = None, format: Union[str, NoneType] = None, encoding: Union[str, NoneType] = None, bits_per_sample: Union[int, NoneType] = None)>,\n",
       "  'Resample': fastaudio.augment.preprocess.Resample,\n",
       "  'DownmixMono': fastaudio.augment.signal.DownmixMono,\n",
       "  'ResizeSignal': fastaudio.augment.signal.ResizeSignal,\n",
       "  'AudioTensor': fastaudio.core.signal.AudioTensor,\n",
       "  'get_audio_files': <function fastaudio.core.signal.get_audio_files(path, recurse=True, folders=None)>,\n",
       "  'audio_item_tfms': <function fastaudio.core.config.audio_item_tfms(sample_rate=16000, force_mono=True, crop_signal_to=None)>,\n",
       "  'PreprocessAudio': fastaudio.core.config.PreprocessAudio,\n",
       "  'preprocess_audio_folder': <function fastaudio.core.config.preprocess_audio_folder(path, folders=None, output_dir=None, sample_rate=16000, force_mono=True, crop_signal_to=None, **kwargs)>,\n",
       "  'AudioBlock': fastaudio.core.config.AudioBlock,\n",
       "  'config_from_func': <function fastaudio.core.config.config_from_func(func, name, **kwargs)>,\n",
       "  'AudioConfig': fastaudio.core.config.AudioConfig,\n",
       "  'torchaudio': <module 'torchaudio' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/__init__.py'>,\n",
       "  'Audio': IPython.lib.display.Audio,\n",
       "  'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
       "  'waveplot': <function librosa.display.waveplot(y, sr=22050, max_points=50000.0, x_axis='time', offset=0.0, max_sr=1000, ax=None, **kwargs)>,\n",
       "  'path': <module 'posixpath' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/posixpath.py'>,\n",
       "  'audio_extensions': ('.m3u',\n",
       "   '.ram',\n",
       "   '.au',\n",
       "   '.snd',\n",
       "   '.mp3',\n",
       "   '.mp2',\n",
       "   '.aif',\n",
       "   '.aifc',\n",
       "   '.aiff',\n",
       "   '.ra',\n",
       "   '.wav',\n",
       "   '.amr',\n",
       "   '.awb',\n",
       "   '.axa',\n",
       "   '.csd',\n",
       "   '.orc',\n",
       "   '.sco',\n",
       "   '.flac',\n",
       "   '.mid',\n",
       "   '.midi',\n",
       "   '.kar',\n",
       "   '.mpga',\n",
       "   '.mpega',\n",
       "   '.m4a',\n",
       "   '.oga',\n",
       "   '.ogg',\n",
       "   '.opus',\n",
       "   '.spx',\n",
       "   '.sid',\n",
       "   '.gsm',\n",
       "   '.wma',\n",
       "   '.wax',\n",
       "   '.rm',\n",
       "   '.pls',\n",
       "   '.sd2'),\n",
       "  'AudioGetter': <function fastaudio.core.signal.AudioGetter(suf='', recurse=True, folders=None)>,\n",
       "  'tar_extract_at_filename': <function fastaudio.core.signal.tar_extract_at_filename(fname, dest)>,\n",
       "  'show_audio_signal': <function fastaudio.core.signal.show_audio_signal(ai, ctx, ax=None, title='', **kwargs)>,\n",
       "  'OpenAudio': fastaudio.core.signal.OpenAudio,\n",
       "  ...},\n",
       " 'os': <module 'os' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/os.py'>,\n",
       " 'sys': <module 'sys' (built-in)>,\n",
       " '_i': 'locals()',\n",
       " '_ii': \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       " '_iii': \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       " '_i1': \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       " '_i2': 'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       " 'models': <module 'fastai.vision.models' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/fastai/vision/models/__init__.py'>,\n",
       " 'multiprocessing': <module 'multiprocessing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/__init__.py'>,\n",
       " 'platform': <module 'platform' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/platform.py'>,\n",
       " 'np': <module 'numpy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/numpy/__init__.py'>,\n",
       " 'io': <module 'io' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/io.py'>,\n",
       " 'operator': <module 'operator' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/operator.py'>,\n",
       " 're': <module 're' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/re.py'>,\n",
       " 'mimetypes': <module 'mimetypes' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/mimetypes.py'>,\n",
       " 'csv': <module 'csv' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/csv.py'>,\n",
       " 'itertools': <module 'itertools' (built-in)>,\n",
       " 'json': <module 'json' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/json/__init__.py'>,\n",
       " 'shutil': <module 'shutil' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/shutil.py'>,\n",
       " 'glob': <module 'glob' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/glob.py'>,\n",
       " 'pickle': <module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>,\n",
       " 'tarfile': <module 'tarfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tarfile.py'>,\n",
       " 'collections': <module 'collections' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/collections/__init__.py'>,\n",
       " 'hashlib': <module 'hashlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/hashlib.py'>,\n",
       " 'types': <module 'types' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/types.py'>,\n",
       " 'inspect': <module 'inspect' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/inspect.py'>,\n",
       " 'functools': <module 'functools' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/functools.py'>,\n",
       " 'random': <module 'random' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/random.py'>,\n",
       " 'time': <module 'time' (built-in)>,\n",
       " 'math': <module 'math' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so'>,\n",
       " 'bz2': <module 'bz2' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/bz2.py'>,\n",
       " 'typing': <module 'typing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/typing.py'>,\n",
       " 'numbers': <module 'numbers' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/numbers.py'>,\n",
       " 'string': <module 'string' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/string.py'>,\n",
       " 'threading': <module 'threading' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/threading.py'>,\n",
       " 'urllib': <module 'urllib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/urllib/__init__.py'>,\n",
       " 'tempfile': <module 'tempfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tempfile.py'>,\n",
       " 'concurrent': <module 'concurrent' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/concurrent/__init__.py'>,\n",
       " 'matplotlib': <module 'matplotlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/__init__.py'>,\n",
       " 'warnings': <module 'warnings' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/warnings.py'>,\n",
       " 'zipfile': <module 'zipfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/zipfile.py'>,\n",
       " 'as_completed': <function concurrent.futures._base.as_completed(fs, timeout=None)>,\n",
       " 'partial': functools.partial,\n",
       " 'reduce': <function _functools.reduce>,\n",
       " 'starmap': itertools.starmap,\n",
       " 'dropwhile': itertools.dropwhile,\n",
       " 'takewhile': itertools.takewhile,\n",
       " 'zip_longest': itertools.zip_longest,\n",
       " 'copy': <function copy.copy(x)>,\n",
       " 'deepcopy': <function copy.deepcopy(x, memo=None, _nil=[])>,\n",
       " 'Lock': <bound method BaseContext.Lock of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       " 'Process': multiprocessing.context.Process,\n",
       " 'Queue': <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       " 'queues': <module 'multiprocessing.queues' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/queues.py'>,\n",
       " 'datetime': datetime.datetime,\n",
       " 'redirect_stdout': contextlib.redirect_stdout,\n",
       " 'contextmanager': <function contextlib.contextmanager(func)>,\n",
       " 'Iterable': typing.Iterable,\n",
       " 'Iterator': typing.Iterator,\n",
       " 'Generator': typing.Generator,\n",
       " 'Sequence': typing.Sequence,\n",
       " 'Union': typing.Union,\n",
       " 'Optional': typing.Optional,\n",
       " 'SimpleNamespace': types.SimpleNamespace,\n",
       " 'Path': pathlib.Path,\n",
       " 'OrderedDict': collections.OrderedDict,\n",
       " 'defaultdict': collections.defaultdict,\n",
       " 'Counter': collections.Counter,\n",
       " 'namedtuple': <function collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)>,\n",
       " 'Enum': <enum 'Enum'>,\n",
       " 'IntEnum': <enum 'IntEnum'>,\n",
       " 'TextWrapper': textwrap.TextWrapper,\n",
       " 'itemgetter': operator.itemgetter,\n",
       " 'attrgetter': operator.attrgetter,\n",
       " 'methodcaller': operator.methodcaller,\n",
       " 'urlopen': <function fastcore.net.urlopen(url, data=None, headers=None, **kwargs)>,\n",
       " 'requests': <module 'requests' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/requests/__init__.py'>,\n",
       " 'yaml': <module 'yaml' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/yaml/__init__.py'>,\n",
       " 'plt': <module 'matplotlib.pyplot' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/pyplot.py'>,\n",
       " 'pd': <module 'pandas' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/pandas/__init__.py'>,\n",
       " 'scipy': <module 'scipy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/__init__.py'>,\n",
       " 'is_categorical_dtype': <function pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype) -> 'bool'>,\n",
       " 'is_numeric_dtype': <function pandas.core.dtypes.common.is_numeric_dtype(arr_or_dtype) -> 'bool'>,\n",
       " 'array': <function numpy.array>,\n",
       " 'ndarray': numpy.ndarray,\n",
       " 'ndimage': <module 'scipy.ndimage' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/ndimage/__init__.py'>,\n",
       " 'set_trace': <function IPython.core.debugger.set_trace(frame=None)>,\n",
       " 'enum': <module 'enum' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/enum.py'>,\n",
       " 'warn': <function _warnings.warn(message, category=None, stacklevel=1, source=None)>,\n",
       " 'WrapperDescriptorType': wrapper_descriptor,\n",
       " 'MethodWrapperType': method-wrapper,\n",
       " 'MethodDescriptorType': method_descriptor,\n",
       " 'BuiltinFunctionType': builtin_function_or_method,\n",
       " 'BuiltinMethodType': builtin_function_or_method,\n",
       " 'MethodType': method,\n",
       " 'FunctionType': function,\n",
       " 'NoneType': NoneType,\n",
       " 'string_classes': (str, bytes),\n",
       " 'is_iter': <function fastai.imports.is_iter(o)>,\n",
       " 'is_coll': <function fastai.imports.is_coll(o)>,\n",
       " 'all_equal': <function fastai.imports.all_equal(a, b)>,\n",
       " 'noop': <function fastai.imports.noop(x=None, *args, **kwargs)>,\n",
       " 'noops': <function fastai.imports.noops(self, x=None, *args, **kwargs)>,\n",
       " 'any_is_instance': <function fastcore.imports.any_is_instance(t, *args)>,\n",
       " 'isinstance_str': <function fastcore.imports.isinstance_str(x, cls_name)>,\n",
       " 'array_equal': <function fastcore.imports.array_equal(a, b)>,\n",
       " 'df_equal': <function fastcore.imports.df_equal(a, b)>,\n",
       " 'equals': <function fastai.imports.equals(a, b)>,\n",
       " 'ipython_shell': <function fastcore.imports.ipython_shell()>,\n",
       " 'in_ipython': <function fastcore.imports.in_ipython()>,\n",
       " 'in_colab': <function fastcore.imports.in_colab()>,\n",
       " 'in_jupyter': <function fastcore.imports.in_jupyter()>,\n",
       " 'in_notebook': <function fastcore.imports.in_notebook()>,\n",
       " 'IN_IPYTHON': True,\n",
       " 'IN_JUPYTER': True,\n",
       " 'IN_COLAB': False,\n",
       " 'IN_NOTEBOOK': True,\n",
       " 'remove_prefix': <function fastcore.imports.remove_prefix(text, prefix)>,\n",
       " 'remove_suffix': <function fastcore.imports.remove_suffix(text, suffix)>,\n",
       " 'working_directory': <function fastcore.foundation.working_directory(path)>,\n",
       " 'add_docs': <function fastcore.foundation.add_docs(cls, cls_doc=None, **docs)>,\n",
       " 'docs': <function fastcore.foundation.docs(cls)>,\n",
       " 'coll_repr': <function fastcore.foundation.coll_repr(c, max_n=10)>,\n",
       " 'is_bool': <function fastcore.foundation.is_bool(x)>,\n",
       " 'mask2idxs': <function fastcore.foundation.mask2idxs(mask)>,\n",
       " 'cycle': <function fastcore.basics.cycle(o)>,\n",
       " 'zip_cycle': <function fastcore.basics.zip_cycle(x, *args)>,\n",
       " 'is_indexer': <function fastcore.foundation.is_indexer(idx)>,\n",
       " 'CollBase': fastcore.foundation.CollBase,\n",
       " 'L': fastcore.foundation.L,\n",
       " 'save_config_file': <function fastcore.foundation.save_config_file(file, d, **kwargs)>,\n",
       " 'read_config_file': <function fastcore.foundation.read_config_file(file, **kwargs)>,\n",
       " 'Config': fastai.data.external.Config,\n",
       " 'lenient_issubclass': <function fastcore.dispatch.lenient_issubclass(cls, types)>,\n",
       " 'sorted_topologically': <function fastcore.dispatch.sorted_topologically(iterable, *, cmp=<built-in function lt>, reverse=False)>,\n",
       " 'TypeDispatch': fastcore.dispatch.TypeDispatch,\n",
       " 'DispatchReg': fastcore.dispatch.DispatchReg,\n",
       " 'typedispatch': <fastcore.dispatch.DispatchReg at 0x7f34c6df11d0>,\n",
       " 'cast': (object,object) -> cast,\n",
       " 'retain_meta': <function fastcore.dispatch.retain_meta(x, res, as_copy=False)>,\n",
       " 'default_set_meta': <function fastcore.dispatch.default_set_meta(self, x, as_copy=False)>,\n",
       " 'retain_type': <function fastcore.dispatch.retain_type(new, old=None, typ=None, as_copy=False)>,\n",
       " 'retain_types': <function fastcore.dispatch.retain_types(new, old=None, typs=None)>,\n",
       " 'explode_types': <function fastcore.dispatch.explode_types(o)>,\n",
       " 'test_fail': <function fastcore.test.test_fail(f, msg='', contains='', args=None, kwargs=None)>,\n",
       " 'test': <function fastcore.test.test(a, b, cmp, cname=None)>,\n",
       " 'nequals': <function fastcore.test.nequals(a, b)>,\n",
       " 'test_eq': <function fastcore.test.test_eq(a, b)>,\n",
       " 'test_eq_type': <function fastcore.test.test_eq_type(a, b)>,\n",
       " 'test_ne': <function fastcore.test.test_ne(a, b)>,\n",
       " 'is_close': <function fastcore.test.is_close(a, b, eps=1e-05)>,\n",
       " 'test_close': <function fastcore.test.test_close(a, b, eps=1e-05)>,\n",
       " 'test_is': <function fastcore.test.test_is(a, b)>,\n",
       " 'test_shuffled': <function fastcore.test.test_shuffled(a, b)>,\n",
       " 'test_stdout': <function fastcore.test.test_stdout(f, exp, regex=False)>,\n",
       " 'test_warns': <function fastcore.test.test_warns(f, show=False)>,\n",
       " 'TEST_IMAGE': 'images/puppy.jpg',\n",
       " 'TEST_IMAGE_BW': 'images/mnist3.png',\n",
       " 'test_fig_exists': <function fastcore.test.test_fig_exists(ax)>,\n",
       " 'ExceptionExpected': fastcore.test.ExceptionExpected,\n",
       " 'exception': <fastcore.test.ExceptionExpected at 0x7f34c0dcc550>,\n",
       " 'defaults': namespace(cpus=4,\n",
       "           use_cuda=None,\n",
       "           activation=torch.nn.modules.activation.ReLU,\n",
       "           callbacks=[fastai.callback.core.TrainEvalCallback,\n",
       "                      fastai.learner.Recorder,\n",
       "                      fastai.callback.progress.ProgressCallback],\n",
       "           lr=0.001),\n",
       " 'ifnone': <function fastcore.basics.ifnone(a, b)>,\n",
       " 'maybe_attr': <function fastcore.basics.maybe_attr(o, attr)>,\n",
       " 'basic_repr': <function fastcore.basics.basic_repr(flds=None)>,\n",
       " 'is_array': <function fastcore.basics.is_array(x)>,\n",
       " 'listify': <function fastcore.basics.listify(o=None, *rest, use_list=False, match=None)>,\n",
       " 'tuplify': <function fastcore.basics.tuplify(o, use_list=False, match=None)>,\n",
       " 'true': <function fastcore.basics.true(*args, **kwargs)>,\n",
       " 'NullType': fastcore.basics.NullType,\n",
       " 'null': <fastcore.basics.NullType at 0x7f34c0e2dbd0>,\n",
       " 'tonull': <function fastcore.basics.tonull(x)>,\n",
       " 'get_class': <function fastcore.basics.get_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       " 'mk_class': <function fastcore.basics.mk_class(nm, *fld_names, sup=None, doc=None, funcs=None, mod=None, **flds)>,\n",
       " 'wrap_class': <function fastcore.basics.wrap_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       " 'ignore_exceptions': fastcore.basics.ignore_exceptions,\n",
       " 'exec_local': <function fastcore.basics.exec_local(code, var_name)>,\n",
       " 'risinstance': <function fastcore.basics.risinstance(types, obj=None)>,\n",
       " 'Inf': fastcore.basics.Inf,\n",
       " 'in_': <function fastcore.basics.in_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'lt': <function fastcore.basics.lt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'gt': <function fastcore.basics.gt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'le': <function fastcore.basics.le(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'ge': <function fastcore.basics.ge(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'eq': <function fastcore.basics.eq(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'ne': <function fastcore.basics.ne(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'add': <function fastcore.basics.add(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'sub': <function fastcore.basics.sub(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'mul': <function fastcore.basics.mul(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'truediv': <function fastcore.basics.truediv(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'is_': <function fastcore.basics.is_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'is_not': <function fastcore.basics.is_not(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'stop': <function fastcore.basics.stop(e=<class 'StopIteration'>)>,\n",
       " 'gen': <function fastcore.basics.gen(func, seq, cond=<function true at 0x7f34c0e30e60>)>,\n",
       " 'chunked': <function fastcore.basics.chunked(it, chunk_sz=None, drop_last=False, n_chunks=None)>,\n",
       " 'otherwise': <function fastcore.basics.otherwise(x, tst, y)>,\n",
       " 'custom_dir': <function fastcore.basics.custom_dir(c, add)>,\n",
       " 'AttrDict': fastcore.basics.AttrDict,\n",
       " 'type_hints': <function fastcore.basics.type_hints(f)>,\n",
       " 'annotations': <function fastcore.basics.annotations(o)>,\n",
       " 'anno_ret': <function fastcore.basics.anno_ret(func)>,\n",
       " 'argnames': <function fastcore.basics.argnames(f, frame=False)>,\n",
       " 'with_cast': <function fastcore.basics.with_cast(f)>,\n",
       " 'store_attr': <function fastcore.basics.store_attr(names=None, self=None, but='', cast=False, store_args=None, **attrs)>,\n",
       " 'attrdict': <function fastcore.basics.attrdict(o, *ks, default=None)>,\n",
       " 'properties': <function fastcore.basics.properties(cls, *ps)>,\n",
       " 'camel2words': <function fastcore.basics.camel2words(s, space=' ')>,\n",
       " 'camel2snake': <function fastcore.basics.camel2snake(name)>,\n",
       " 'snake2camel': <function fastcore.basics.snake2camel(s)>,\n",
       " 'class2attr': <function fastcore.basics.class2attr(self, cls_name)>,\n",
       " 'getattrs': <function fastcore.basics.getattrs(o, *attrs, default=None)>,\n",
       " 'hasattrs': <function fastcore.basics.hasattrs(o, attrs)>,\n",
       " 'setattrs': <function fastcore.basics.setattrs(dest, flds, src)>,\n",
       " 'try_attrs': <function fastcore.basics.try_attrs(obj, *attrs)>,\n",
       " 'GetAttrBase': fastcore.basics.GetAttrBase,\n",
       " 'GetAttr': fastcore.basics.GetAttr,\n",
       " 'delegate_attr': <function fastcore.basics.delegate_attr(self, k, to)>,\n",
       " 'ShowPrint': fastcore.basics.ShowPrint,\n",
       " 'Int': fastcore.basics.Int,\n",
       " 'Str': fastcore.basics.Str,\n",
       " 'Float': fastcore.basics.Float,\n",
       " 'concat': <function fastai.torch_core.concat(*ls)>,\n",
       " 'strcat': <function fastcore.basics.strcat(its, sep: str = '') -> str>,\n",
       " 'detuplify': <function fastcore.basics.detuplify(x)>,\n",
       " 'replicate': <function fastcore.basics.replicate(item, match)>,\n",
       " 'setify': <function fastcore.basics.setify(o)>,\n",
       " 'merge': <function fastcore.basics.merge(*ds)>,\n",
       " 'range_of': <function fastcore.basics.range_of(a, b=None, step=None)>,\n",
       " 'groupby': <function fastcore.basics.groupby(x, key, val=<function noop at 0x7f34c0dfed40>)>,\n",
       " 'last_index': <function fastcore.basics.last_index(x, o)>,\n",
       " 'filter_dict': <function fastcore.basics.filter_dict(d, func)>,\n",
       " 'filter_keys': <function fastcore.basics.filter_keys(d, func)>,\n",
       " 'filter_values': <function fastcore.basics.filter_values(d, func)>,\n",
       " 'sorted_ex': <function fastcore.basics.sorted_ex(iterable, key=None, reverse=False)>,\n",
       " 'not_': <function fastcore.basics.not_(f)>,\n",
       " 'argwhere': <function fastcore.basics.argwhere(iterable, f, negate=False, **kwargs)>,\n",
       " 'filter_ex': <function fastcore.basics.filter_ex(iterable, f=<function noop at 0x7f34c0dfed40>, negate=False, gen=False, **kwargs)>,\n",
       " 'renumerate': <function fastcore.basics.renumerate(iterable, start=0)>,\n",
       " 'first': <function fastcore.basics.first(x, f=None, negate=False, **kwargs)>,\n",
       " 'nested_attr': <function fastcore.basics.nested_attr(o, attr, default=None)>,\n",
       " 'nested_idx': <function fastcore.basics.nested_idx(coll, *idxs)>,\n",
       " 'val2idx': <function fastcore.basics.val2idx(x)>,\n",
       " 'uniqueify': <function fastcore.basics.uniqueify(x, sort=False, bidir=False, start=None)>,\n",
       " 'num_methods': ['__add__',\n",
       "  '__sub__',\n",
       "  '__mul__',\n",
       "  '__matmul__',\n",
       "  '__truediv__',\n",
       "  '__floordiv__',\n",
       "  '__mod__',\n",
       "  '__divmod__',\n",
       "  '__pow__',\n",
       "  '__lshift__',\n",
       "  '__rshift__',\n",
       "  '__and__',\n",
       "  '__xor__',\n",
       "  '__or__',\n",
       "  '__neg__',\n",
       "  '__pos__',\n",
       "  '__abs__'],\n",
       " 'rnum_methods': ['__radd__',\n",
       "  '__rsub__',\n",
       "  '__rmul__',\n",
       "  '__rmatmul__',\n",
       "  '__rtruediv__',\n",
       "  '__rfloordiv__',\n",
       "  '__rmod__',\n",
       "  '__rdivmod__',\n",
       "  '__rpow__',\n",
       "  '__rlshift__',\n",
       "  '__rrshift__',\n",
       "  '__rand__',\n",
       "  '__rxor__',\n",
       "  '__ror__'],\n",
       " 'inum_methods': ['__iadd__',\n",
       "  '__isub__',\n",
       "  '__imul__',\n",
       "  '__imatmul__',\n",
       "  '__itruediv__',\n",
       "  '__ifloordiv__',\n",
       "  '__imod__',\n",
       "  '__ipow__',\n",
       "  '__ilshift__',\n",
       "  '__irshift__',\n",
       "  '__iand__',\n",
       "  '__ixor__',\n",
       "  '__ior__'],\n",
       " 'fastuple': fastcore.basics.fastuple,\n",
       " 'arg0': <fastcore.basics._Arg at 0x7f34c0dbc410>,\n",
       " 'arg1': <fastcore.basics._Arg at 0x7f34c0dbc450>,\n",
       " 'arg2': <fastcore.basics._Arg at 0x7f34c0dbc490>,\n",
       " 'arg3': <fastcore.basics._Arg at 0x7f34c0dbc4d0>,\n",
       " 'arg4': <fastcore.basics._Arg at 0x7f34c0dbc510>,\n",
       " 'bind': fastcore.basics.bind,\n",
       " 'mapt': <function fastcore.basics.mapt(func, *iterables)>,\n",
       " 'map_ex': <function fastcore.basics.map_ex(iterable, f, *args, gen=False, **kwargs)>,\n",
       " 'compose': <function fastcore.basics.compose(*funcs, order=None)>,\n",
       " 'maps': <function fastcore.basics.maps(*args, retain=<function noop at 0x7f34c0dfed40>)>,\n",
       " 'partialler': <function fastcore.basics.partialler(f, *args, order=None, **kwargs)>,\n",
       " 'instantiate': <function fastcore.basics.instantiate(t)>,\n",
       " 'using_attr': <function fastcore.basics.using_attr(f, attr)>,\n",
       " 'Self': <fastcore.basics._SelfCls at 0x7f34c0dbc5d0>,\n",
       " 'copy_func': <function fastcore.basics.copy_func(f)>,\n",
       " 'patch_to': <function fastcore.basics.patch_to(cls, as_prop=False, cls_method=False)>,\n",
       " 'patch': <function fastcore.basics.patch(f=None, *, as_prop=False, cls_method=False)>,\n",
       " 'patch_property': <function fastcore.basics.patch_property(f)>,\n",
       " 'ImportEnum': <enum 'ImportEnum'>,\n",
       " 'StrEnum': <enum 'StrEnum'>,\n",
       " 'str_enum': <function fastcore.basics.str_enum(name, *vals)>,\n",
       " 'Stateful': fastcore.basics.Stateful,\n",
       " 'PrettyString': fastcore.basics.PrettyString,\n",
       " 'even_mults': <function fastcore.basics.even_mults(start, stop, n)>,\n",
       " 'num_cpus': <function fastcore.basics.num_cpus()>,\n",
       " 'add_props': <function fastcore.basics.add_props(f, g=None, n=2)>,\n",
       " 'typed': <function fastcore.basics.typed(f)>,\n",
       " 'dict2obj': <function fastcore.xtras.dict2obj(d)>,\n",
       " 'obj2dict': <function fastcore.xtras.obj2dict(d)>,\n",
       " 'repr_dict': <function fastcore.xtras.repr_dict(d)>,\n",
       " 'is_listy': <function fastcore.xtras.is_listy(x)>,\n",
       " 'shufflish': <function fastcore.xtras.shufflish(x, pct=0.04)>,\n",
       " 'mapped': <function fastcore.xtras.mapped(f, it)>,\n",
       " 'IterLen': fastcore.xtras.IterLen,\n",
       " 'ReindexCollection': fastcore.xtras.ReindexCollection,\n",
       " 'maybe_open': <function fastcore.xtras.maybe_open(f, mode='r', **kwargs)>,\n",
       " 'image_size': <function fastcore.xtras.image_size(fn)>,\n",
       " 'bunzip': <function fastcore.xtras.bunzip(fn)>,\n",
       " 'join_path_file': <function fastcore.xtras.join_path_file(file, path, ext='')>,\n",
       " 'loads': <function fastcore.xtras.loads(s, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)>,\n",
       " 'loads_multi': <function fastcore.xtras.loads_multi(s: str)>,\n",
       " 'untar_dir': <function fastcore.xtras.untar_dir(file, dest)>,\n",
       " 'repo_details': <function fastcore.xtras.repo_details(url)>,\n",
       " 'run': <function fastcore.xtras.run(cmd, *rest, same_in_win=False, ignore_ex=False, as_bytes=False, stderr=False)>,\n",
       " 'open_file': <function fastcore.xtras.open_file(fn, mode='r', **kwargs)>,\n",
       " 'save_pickle': <function fastcore.xtras.save_pickle(fn, o)>,\n",
       " 'load_pickle': <function fastcore.xtras.load_pickle(fn)>,\n",
       " 'truncstr': <function fastcore.xtras.truncstr(s: str, maxlen: int, suf: str = '…', space='') -> str>,\n",
       " 'spark_chars': '▁▂▃▅▆▇',\n",
       " 'sparkline': <function fastcore.xtras.sparkline(data, mn=None, mx=None, empty_zero=False)>,\n",
       " 'autostart': <function fastcore.xtras.autostart(g)>,\n",
       " 'EventTimer': fastcore.xtras.EventTimer,\n",
       " 'stringfmt_names': <function fastcore.xtras.stringfmt_names(s: str) -> list>,\n",
       " 'PartialFormatter': fastcore.xtras.PartialFormatter,\n",
       " 'partial_format': <function fastcore.xtras.partial_format(s: str, **kwargs)>,\n",
       " 'utc2local': <function fastcore.xtras.utc2local(dt: datetime.datetime) -> datetime.datetime>,\n",
       " 'local2utc': <function fastcore.xtras.local2utc(dt: datetime.datetime) -> datetime.datetime>,\n",
       " 'trace': <function fastcore.xtras.trace(f)>,\n",
       " 'round_multiple': <function fastcore.xtras.round_multiple(x, mult, round_down=False)>,\n",
       " 'modified_env': <function fastcore.xtras.modified_env(*delete, **replace)>,\n",
       " 'ContextManagers': fastcore.xtras.ContextManagers,\n",
       " 'str2bool': <function fastcore.xtras.str2bool(s)>,\n",
       " 'sort_by_run': <function fastcore.xtras.sort_by_run(fs)>,\n",
       " 'threaded': <function fastcore.parallel.threaded(f)>,\n",
       " 'startthread': <function fastcore.parallel.startthread(f)>,\n",
       " 'set_num_threads': <function fastcore.parallel.set_num_threads(nt)>,\n",
       " 'parallelable': <function fastcore.parallel.parallelable(param_name, num_workers, f=None)>,\n",
       " 'ThreadPoolExecutor': fastcore.parallel.ThreadPoolExecutor,\n",
       " 'ProcessPoolExecutor': fastcore.parallel.ProcessPoolExecutor,\n",
       " 'parallel': <function fastcore.parallel.parallel(f, items, *args, n_workers=4, total=None, progress=None, pause=0, threadpool=False, timeout=None, chunksize=1, **kwargs)>,\n",
       " 'add_one': <function fastcore.parallel.add_one(x, a=1)>,\n",
       " 'run_procs': <function fastcore.parallel.run_procs(f, f_done, args)>,\n",
       " 'parallel_gen': <function fastcore.parallel.parallel_gen(cls, items, n_workers=4, **kwargs)>,\n",
       " 'url_default_headers': {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
       "  'Accept-Language': 'en-US,en;q=0.9',\n",
       "  'Cache-Control': 'max-age=0',\n",
       "  'Sec-Fetch-Dest': 'document',\n",
       "  'Sec-Fetch-Mode': 'navigate',\n",
       "  'Sec-Fetch-Site': 'none',\n",
       "  'Sec-Fetch-User': '?1',\n",
       "  'Upgrade-Insecure-Requests': '1',\n",
       "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'},\n",
       " 'urlquote': <function fastcore.net.urlquote(url)>,\n",
       " 'urlwrap': <function fastcore.net.urlwrap(url, data=None, headers=None)>,\n",
       " 'ExceptionsHTTP': {400: fastcore.basics.HTTP400BadRequestError,\n",
       "  401: fastcore.basics.HTTP401UnauthorizedError,\n",
       "  402: fastcore.basics.HTTP402PaymentRequiredError,\n",
       "  403: fastcore.basics.HTTP403ForbiddenError,\n",
       "  404: fastcore.basics.HTTP404NotFoundError,\n",
       "  405: fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "  406: fastcore.basics.HTTP406NotAcceptableError,\n",
       "  407: fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "  408: fastcore.basics.HTTP408RequestTimeoutError,\n",
       "  409: fastcore.basics.HTTP409ConflictError,\n",
       "  410: fastcore.basics.HTTP410GoneError,\n",
       "  411: fastcore.basics.HTTP411LengthRequiredError,\n",
       "  412: fastcore.basics.HTTP412PreconditionFailedError,\n",
       "  413: fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "  414: fastcore.basics.HTTP414URITooLongError,\n",
       "  415: fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "  416: fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "  417: fastcore.basics.HTTP417ExpectationFailedError,\n",
       "  418: fastcore.basics.HTTP418AmAteapotError,\n",
       "  421: fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "  422: fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "  423: fastcore.basics.HTTP423LockedError,\n",
       "  424: fastcore.basics.HTTP424FailedDependencyError,\n",
       "  425: fastcore.basics.HTTP425TooEarlyError,\n",
       "  426: fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "  428: fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "  429: fastcore.basics.HTTP429TooManyRequestsError,\n",
       "  431: fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "  451: fastcore.basics.HTTP451LegalReasonsError},\n",
       " 'HTTP4xxClientError': fastcore.net.HTTP4xxClientError,\n",
       " 'HTTP5xxServerError': fastcore.net.HTTP5xxServerError,\n",
       " 'HTTP400BadRequestError': fastcore.basics.HTTP400BadRequestError,\n",
       " 'HTTP401UnauthorizedError': fastcore.basics.HTTP401UnauthorizedError,\n",
       " 'HTTP402PaymentRequiredError': fastcore.basics.HTTP402PaymentRequiredError,\n",
       " 'HTTP403ForbiddenError': fastcore.basics.HTTP403ForbiddenError,\n",
       " 'HTTP404NotFoundError': fastcore.basics.HTTP404NotFoundError,\n",
       " 'HTTP405MethodNotAllowedError': fastcore.basics.HTTP405MethodNotAllowedError,\n",
       " 'HTTP406NotAcceptableError': fastcore.basics.HTTP406NotAcceptableError,\n",
       " 'HTTP407ProxyAuthRequiredError': fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       " 'HTTP408RequestTimeoutError': fastcore.basics.HTTP408RequestTimeoutError,\n",
       " 'HTTP409ConflictError': fastcore.basics.HTTP409ConflictError,\n",
       " 'HTTP410GoneError': fastcore.basics.HTTP410GoneError,\n",
       " 'HTTP411LengthRequiredError': fastcore.basics.HTTP411LengthRequiredError,\n",
       " 'HTTP412PreconditionFailedError': fastcore.basics.HTTP412PreconditionFailedError,\n",
       " 'HTTP413PayloadTooLargeError': fastcore.basics.HTTP413PayloadTooLargeError,\n",
       " 'HTTP414URITooLongError': fastcore.basics.HTTP414URITooLongError,\n",
       " 'HTTP415UnsupportedMediaTypeError': fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       " 'HTTP416RangeNotSatisfiableError': fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       " 'HTTP417ExpectationFailedError': fastcore.basics.HTTP417ExpectationFailedError,\n",
       " 'HTTP418AmAteapotError': fastcore.basics.HTTP418AmAteapotError,\n",
       " 'HTTP421MisdirectedRequestError': fastcore.basics.HTTP421MisdirectedRequestError,\n",
       " 'HTTP422UnprocessableEntityError': fastcore.basics.HTTP422UnprocessableEntityError,\n",
       " 'HTTP423LockedError': fastcore.basics.HTTP423LockedError,\n",
       " 'HTTP424FailedDependencyError': fastcore.basics.HTTP424FailedDependencyError,\n",
       " 'HTTP425TooEarlyError': fastcore.basics.HTTP425TooEarlyError,\n",
       " 'HTTP426UpgradeRequiredError': fastcore.basics.HTTP426UpgradeRequiredError,\n",
       " 'HTTP428PreconditionRequiredError': fastcore.basics.HTTP428PreconditionRequiredError,\n",
       " 'HTTP429TooManyRequestsError': fastcore.basics.HTTP429TooManyRequestsError,\n",
       " 'HTTP431HeaderFieldsTooLargeError': fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       " 'HTTP451LegalReasonsError': fastcore.basics.HTTP451LegalReasonsError,\n",
       " 'urlread': <function fastcore.net.urlread(url, data=None, headers=None, decode=True, return_json=False, return_headers=False, **kwargs)>,\n",
       " 'urljson': <function fastcore.net.urljson(url, data=None)>,\n",
       " 'urlcheck': <function fastcore.net.urlcheck(url, timeout=10)>,\n",
       " 'urlclean': <function fastcore.net.urlclean(url)>,\n",
       " 'urlsave': <function fastcore.net.urlsave(url, dest=None)>,\n",
       " 'urlvalid': <function fastcore.net.urlvalid(x)>,\n",
       " 'urlrequest': <function fastcore.net.urlrequest(url, verb, headers=None, route=None, query=None, data=None, json_data=True)>,\n",
       " 'urlsend': <function fastcore.net.urlsend(url, verb, headers=None, route=None, query=None, data=None, json_data=True, return_json=True, return_headers=False, debug=None)>,\n",
       " 'do_request': <function fastcore.net.do_request(url, post=False, headers=None, **data)>,\n",
       " 'start_server': <function fastcore.net.start_server(port, host=None, dgram=False, reuse_addr=True, n_queue=None)>,\n",
       " 'start_client': <function fastcore.net.start_client(port, host=None, dgram=False)>,\n",
       " 'Transform': fastcore.transform.Transform,\n",
       " 'InplaceTransform': fastcore.transform.InplaceTransform,\n",
       " 'DisplayedTransform': fastcore.transform.DisplayedTransform,\n",
       " 'ItemTransform': fastcore.transform.ItemTransform,\n",
       " 'get_func': <function fastcore.transform.get_func(t, name, *args, **kwargs)>,\n",
       " 'Func': fastcore.transform.Func,\n",
       " 'Sig': <fastcore.transform._Sig at 0x7f34c0d37590>,\n",
       " 'compose_tfms': <function fastcore.transform.compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs)>,\n",
       " 'mk_transform': <function fastcore.transform.mk_transform(f)>,\n",
       " 'gather_attrs': <function fastcore.transform.gather_attrs(o, k, nm)>,\n",
       " 'gather_attr_names': <function fastcore.transform.gather_attr_names(o, nm)>,\n",
       " 'Pipeline': fastcore.transform.Pipeline,\n",
       " 'test_sig': <function fastcore.meta.test_sig(f, b)>,\n",
       " 'FixSigMeta': fastcore.meta.FixSigMeta,\n",
       " 'PrePostInitMeta': fastcore.meta.PrePostInitMeta,\n",
       " 'AutoInit': fastcore.meta.AutoInit,\n",
       " 'NewChkMeta': fastcore.meta.NewChkMeta,\n",
       " 'BypassNewMeta': fastcore.meta.BypassNewMeta,\n",
       " 'empty2none': <function fastcore.meta.empty2none(p)>,\n",
       " 'anno_dict': <function fastcore.meta.anno_dict(f)>,\n",
       " 'use_kwargs_dict': <function fastcore.meta.use_kwargs_dict(keep=False, **kwargs)>,\n",
       " 'use_kwargs': <function fastcore.meta.use_kwargs(names, keep=False)>,\n",
       " 'delegates': <function fastcore.meta.delegates(to=None, keep=False, but=None)>,\n",
       " 'method': <function fastcore.meta.method(f)>,\n",
       " 'funcs_kwargs': <function fastcore.meta.funcs_kwargs(as_method=False)>,\n",
       " 'store_true': <function fastcore.script.store_true()>,\n",
       " 'store_false': <function fastcore.script.store_false()>,\n",
       " 'bool_arg': <function fastcore.script.bool_arg(v)>,\n",
       " 'clean_type_str': <function fastcore.script.clean_type_str(x: str)>,\n",
       " 'Param': fastcore.script.Param,\n",
       " 'anno_parser': <function fastcore.script.anno_parser(func, prog=None, from_name=False)>,\n",
       " 'args_from_prog': <function fastcore.script.args_from_prog(func, prog)>,\n",
       " 'SCRIPT_INFO': namespace(func=None),\n",
       " 'call_parse': <function fastcore.script.call_parse(func)>,\n",
       " 'progress_bar': fastprogress.fastprogress.NBProgressBar,\n",
       " 'master_bar': fastprogress.fastprogress.NBMasterBar,\n",
       " 'LambdaType': function,\n",
       " 'one_is_instance': <function fastai.imports.one_is_instance(a, b, t)>,\n",
       " 'pv': <function fastai.imports.pv(text, verbose)>,\n",
       " 'torch': <module 'torch' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/__init__.py'>,\n",
       " 'as_tensor': <function _VariableFunctionsClass.as_tensor>,\n",
       " 'Tensor': torch.Tensor,\n",
       " 'ByteTensor': torch.ByteTensor,\n",
       " 'LongTensor': torch.LongTensor,\n",
       " 'FloatTensor': torch.FloatTensor,\n",
       " 'HalfTensor': torch.HalfTensor,\n",
       " 'DoubleTensor': torch.DoubleTensor,\n",
       " 'nn': <module 'torch.nn' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/__init__.py'>,\n",
       " 'F': <module 'torch.nn.functional' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/functional.py'>,\n",
       " 'SequentialSampler': torch.utils.data.sampler.SequentialSampler,\n",
       " 'RandomSampler': torch.utils.data.sampler.RandomSampler,\n",
       " 'Sampler': torch.utils.data.sampler.Sampler,\n",
       " 'BatchSampler': torch.utils.data.sampler.BatchSampler,\n",
       " 'IterableDataset': torch.utils.data.dataset.IterableDataset,\n",
       " 'get_worker_info': <function torch.utils.data._utils.worker.get_worker_info()>,\n",
       " 'default_collate': <function torch.utils.data._utils.collate.default_collate(batch)>,\n",
       " 'default_convert': <function torch.utils.data._utils.collate.default_convert(data)>,\n",
       " 'subplots': <function fastai.torch_core.subplots(nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **kwargs)>,\n",
       " 'show_image': <function fastai.torch_core.show_image(im, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       " 'show_titled_image': <function fastai.torch_core.show_titled_image(o, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       " 'show_images': <function fastai.torch_core.show_images(ims, nrows=1, ncols=None, titles=None, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       " 'ArrayBase': fastai.torch_core.ArrayBase,\n",
       " 'ArrayImageBase': fastai.torch_core.ArrayImageBase,\n",
       " 'ArrayImage': fastai.torch_core.ArrayImage,\n",
       " 'ArrayImageBW': fastai.torch_core.ArrayImageBW,\n",
       " 'ArrayMask': fastai.torch_core.ArrayMask,\n",
       " 'tensor': <function fastai.torch_core.tensor(x, *rest, dtype=None, device=None, requires_grad=False, pin_memory=False)>,\n",
       " 'set_seed': <function fastai.torch_core.set_seed(s, reproducible=False)>,\n",
       " 'get_random_states': <function fastai.torch_core.get_random_states()>,\n",
       " 'set_random_states': <function fastai.torch_core.set_random_states(random_state, numpy_state, torch_state, torch_cuda_state, torch_deterministic, torch_benchmark)>,\n",
       " 'no_random': <function fastai.torch_core.no_random(seed=42, reproducible=True)>,\n",
       " 'unsqueeze': <function fastai.torch_core.unsqueeze(x, dim=-1, n=1)>,\n",
       " 'unsqueeze_': <function fastai.torch_core.unsqueeze_(x, dim=-1, n=1)>,\n",
       " 'apply': <function fastai.torch_core.apply(func, x, *args, **kwargs)>,\n",
       " 'maybe_gather': <function fastai.torch_core.maybe_gather(x, axis=0)>,\n",
       " 'to_detach': <function fastai.torch_core.to_detach(b, cpu=True, gather=True)>,\n",
       " 'to_half': <function fastai.torch_core.to_half(b)>,\n",
       " 'to_float': <function fastai.torch_core.to_float(b)>,\n",
       " 'default_device': <function fastai.torch_core.default_device(use_cuda=-1)>,\n",
       " 'to_device': <function fastai.torch_core.to_device(b, device=None, non_blocking=False)>,\n",
       " 'to_cpu': <function fastai.torch_core.to_cpu(b)>,\n",
       " 'to_np': <function fastai.torch_core.to_np(x)>,\n",
       " 'to_concat': <function fastai.torch_core.to_concat(xs, dim=0)>,\n",
       " 'TensorBase': fastai.torch_core.TensorBase,\n",
       " 'TensorImageBase': fastai.torch_core.TensorImageBase,\n",
       " 'TensorImage': fastai.torch_core.TensorImage,\n",
       " 'TensorImageBW': fastai.torch_core.TensorImageBW,\n",
       " 'TensorMask': fastai.torch_core.TensorMask,\n",
       " 'TensorFlowField': fastai.torch_core.TensorFlowField,\n",
       " 'TensorCategory': fastai.torch_core.TensorCategory,\n",
       " 'TensorMultiCategory': fastai.torch_core.TensorMultiCategory,\n",
       " 'TitledTensorScalar': fastai.torch_core.TitledTensorScalar,\n",
       " 'Chunks': fastai.torch_core.Chunks,\n",
       " 'show_title': <function fastai.torch_core.show_title(o, ax=None, ctx=None, label=None, color='black', **kwargs)>,\n",
       " 'ShowTitle': fastai.torch_core.ShowTitle,\n",
       " 'TitledInt': fastai.torch_core.TitledInt,\n",
       " 'TitledFloat': fastai.torch_core.TitledFloat,\n",
       " 'TitledStr': fastai.torch_core.TitledStr,\n",
       " 'TitledTuple': fastai.torch_core.TitledTuple,\n",
       " 'get_empty_df': <function fastai.torch_core.get_empty_df(n)>,\n",
       " 'display_df': <function fastai.torch_core.display_df(df)>,\n",
       " 'get_first': <function fastai.torch_core.get_first(c)>,\n",
       " 'one_param': <function fastai.torch_core.one_param(m)>,\n",
       " 'item_find': <function fastai.torch_core.item_find(x, idx=0)>,\n",
       " 'find_device': <function fastai.torch_core.find_device(b)>,\n",
       " 'find_bs': <function fastai.torch_core.find_bs(b)>,\n",
       " 'np_func': <function fastai.torch_core.np_func(f)>,\n",
       " 'Module': fastai.torch_core.Module,\n",
       " 'get_model': <function fastai.torch_core.get_model(model)>,\n",
       " 'one_hot': <function fastai.torch_core.one_hot(x, c)>,\n",
       " 'one_hot_decode': <function fastai.torch_core.one_hot_decode(x, vocab=None)>,\n",
       " 'params': <function fastai.torch_core.params(m)>,\n",
       " 'trainable_params': <function fastai.torch_core.trainable_params(m)>,\n",
       " 'norm_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm3d,\n",
       "  torch.nn.modules.instancenorm.InstanceNorm1d,\n",
       "  torch.nn.modules.instancenorm.InstanceNorm2d,\n",
       "  torch.nn.modules.instancenorm.InstanceNorm3d,\n",
       "  torch.nn.modules.normalization.LayerNorm),\n",
       " 'norm_bias_params': <function fastai.torch_core.norm_bias_params(m, with_bias=True)>,\n",
       " 'batch_to_samples': <function fastai.torch_core.batch_to_samples(b, max_n=10)>,\n",
       " 'logit': <function fastai.torch_core.logit(x)>,\n",
       " 'num_distrib': <function fastai.torch_core.num_distrib()>,\n",
       " 'rank_distrib': <function fastai.torch_core.rank_distrib()>,\n",
       " 'distrib_barrier': <function fastai.torch_core.distrib_barrier()>,\n",
       " 'base_doc': <function fastai.torch_core.base_doc(elt)>,\n",
       " 'doc': <function fastai.torch_core.doc(elt)>,\n",
       " 'nested_reorder': <function fastai.torch_core.nested_reorder(t, idxs)>,\n",
       " 'make_cross_image': <function fastai.torch_core.make_cross_image(bw=True)>,\n",
       " 'show_image_batch': <function fastai.torch_core.show_image_batch(b, show=<function show_titled_image at 0x7f34c0cf3170>, items=9, cols=3, figsize=None, **kwargs)>,\n",
       " 'requires_grad': <function fastai.torch_core.requires_grad(m)>,\n",
       " 'init_default': <function fastai.layers.init_default(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       " 'cond_init': <function fastai.torch_core.cond_init(m, func)>,\n",
       " 'apply_leaf': <function fastai.torch_core.apply_leaf(m, f)>,\n",
       " 'apply_init': <function fastai.torch_core.apply_init(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       " 'script_use_ctx': <function fastai.torch_core.script_use_ctx(f)>,\n",
       " 'script_save_ctx': <function fastai.torch_core.script_save_ctx(static, *argidx)>,\n",
       " 'script_fwd': <function fastai.torch_core.script_fwd(*argidx)>,\n",
       " 'script_bwd': <function fastai.torch_core.script_bwd(f)>,\n",
       " 'grad_module': <function fastai.torch_core.grad_module(cls)>,\n",
       " 'flatten_check': <function fastai.torch_core.flatten_check(inp, targ)>,\n",
       " 'module': <function fastai.layers.module(*flds, **defaults)>,\n",
       " 'Identity': fastai.layers.Identity,\n",
       " 'Lambda': fastai.layers.Lambda,\n",
       " 'PartialLambda': fastai.layers.PartialLambda,\n",
       " 'Flatten': fastai.layers.Flatten,\n",
       " 'View': fastai.layers.View,\n",
       " 'ResizeBatch': fastai.layers.ResizeBatch,\n",
       " 'Debugger': fastai.layers.Debugger,\n",
       " 'sigmoid_range': <function fastai.layers.sigmoid_range(x, low, high)>,\n",
       " 'SigmoidRange': fastai.layers.SigmoidRange,\n",
       " 'AdaptiveConcatPool1d': fastai.layers.AdaptiveConcatPool1d,\n",
       " 'AdaptiveConcatPool2d': fastai.layers.AdaptiveConcatPool2d,\n",
       " 'PoolType': fastai.layers.PoolType,\n",
       " 'adaptive_pool': <function fastai.layers.adaptive_pool(pool_type)>,\n",
       " 'PoolFlatten': fastai.layers.PoolFlatten,\n",
       " 'NormType': <enum 'NormType'>,\n",
       " 'BatchNorm': <function fastai.layers.BatchNorm(nf, ndim=2, norm_type=<NormType.Batch: 1>, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)>,\n",
       " 'InstanceNorm': <function fastai.layers.InstanceNorm(nf, ndim=2, norm_type=<NormType.Instance: 5>, affine=True, eps: float = 1e-05, momentum: float = 0.1, track_running_stats: bool = False)>,\n",
       " 'BatchNorm1dFlat': fastai.layers.BatchNorm1dFlat,\n",
       " 'LinBnDrop': fastai.layers.LinBnDrop,\n",
       " 'sigmoid': <function fastai.layers.sigmoid(input, eps=1e-07)>,\n",
       " 'sigmoid_': <function fastai.layers.sigmoid_(input, eps=1e-07)>,\n",
       " 'vleaky_relu': <function fastai.layers.vleaky_relu(input, inplace=True)>,\n",
       " 'init_linear': <function fastai.layers.init_linear(m, act_func=None, init='auto', bias_std=0.01)>,\n",
       " 'ConvLayer': fastai.layers.ConvLayer,\n",
       " 'AdaptiveAvgPool': <function fastai.layers.AdaptiveAvgPool(sz=1, ndim=2)>,\n",
       " 'MaxPool': <function fastai.layers.MaxPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       " 'AvgPool': <function fastai.layers.AvgPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       " 'trunc_normal_': <function fastai.layers.trunc_normal_(x, mean=0.0, std=1.0)>,\n",
       " 'Embedding': fastai.layers.Embedding,\n",
       " 'SelfAttention': fastai.layers.SelfAttention,\n",
       " 'PooledSelfAttention2d': fastai.layers.PooledSelfAttention2d,\n",
       " 'SimpleSelfAttention': fastai.layers.SimpleSelfAttention,\n",
       " 'icnr_init': <function fastai.layers.icnr_init(x, scale=2, init=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       " 'PixelShuffle_ICNR': fastai.layers.PixelShuffle_ICNR,\n",
       " 'sequential': <function fastai.layers.sequential(*args)>,\n",
       " 'SequentialEx': fastai.layers.SequentialEx,\n",
       " 'MergeLayer': fastai.layers.MergeLayer,\n",
       " 'Cat': fastai.layers.Cat,\n",
       " 'SimpleCNN': fastai.layers.SimpleCNN,\n",
       " 'ProdLayer': fastai.layers.ProdLayer,\n",
       " 'inplace_relu': functools.partial(<class 'torch.nn.modules.activation.ReLU'>, inplace=True),\n",
       " 'SEModule': <function fastai.layers.SEModule(ch, reduction, act_cls=<class 'torch.nn.modules.activation.ReLU'>)>,\n",
       " 'ResBlock': fastai.layers.ResBlock,\n",
       " 'SEBlock': <function fastai.layers.SEBlock(expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)>,\n",
       " 'SEResNeXtBlock': <function fastai.layers.SEResNeXtBlock(expansion, ni, nf, groups=32, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       " 'SeparableBlock': <function fastai.layers.SeparableBlock(expansion, ni, nf, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       " 'TimeDistributed': fastai.layers.TimeDistributed,\n",
       " 'swish': <function fastai.layers.swish(x, inplace=False)>,\n",
       " 'Swish': fastai.layers.Swish,\n",
       " 'MishJitAutoFn': fastai.layers.MishJitAutoFn,\n",
       " 'mish': <function fastai.layers.mish(x)>,\n",
       " 'Mish': fastai.layers.Mish,\n",
       " 'ParameterModule': fastai.layers.ParameterModule,\n",
       " 'children_and_parameters': <function fastai.layers.children_and_parameters(m)>,\n",
       " 'has_children': <function fastai.layers.has_children(m)>,\n",
       " 'flatten_model': <function fastai.layers.flatten_model(m)>,\n",
       " 'NoneReduce': fastai.layers.NoneReduce,\n",
       " 'in_channels': <function fastai.layers.in_channels(m)>,\n",
       " 'BaseLoss': fastai.losses.BaseLoss,\n",
       " 'CrossEntropyLossFlat': fastai.losses.CrossEntropyLossFlat,\n",
       " 'FocalLossFlat': fastai.losses.FocalLossFlat,\n",
       " 'BCEWithLogitsLossFlat': fastai.losses.BCEWithLogitsLossFlat,\n",
       " 'BCELossFlat': <function fastai.losses.BCELossFlat(*args, axis=-1, floatify=True, weight=None, reduction='mean')>,\n",
       " 'MSELossFlat': <function fastai.losses.MSELossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       " 'L1LossFlat': <function fastai.losses.L1LossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       " 'LabelSmoothingCrossEntropy': fastai.losses.LabelSmoothingCrossEntropy,\n",
       " 'LabelSmoothingCrossEntropyFlat': fastai.losses.LabelSmoothingCrossEntropyFlat,\n",
       " 'show_batch': (TensorImage,TensorImage) -> show_batch\n",
       " (TensorImage,object) -> show_batch\n",
       " (AudioTensor,object) -> show_batch\n",
       " (AudioSpectrogram,object) -> show_batch\n",
       " (object,object) -> show_batch,\n",
       " 'show_results': (TensorImage,TensorCategory) -> show_results\n",
       " (TensorImage,TensorMask) -> show_results\n",
       " (TensorImage,TensorBBox) -> show_results\n",
       " (TensorImage,TensorPoint) -> show_results\n",
       " (TensorImage,TensorImage) -> show_results\n",
       " (TensorImage,object) -> show_results\n",
       " (object,object) -> show_results,\n",
       " 'TfmdDL': fastai.data.core.TfmdDL,\n",
       " 'DataLoaders': fastai.data.core.DataLoaders,\n",
       " 'FilteredBase': fastai.data.core.FilteredBase,\n",
       " 'TfmdLists': fastai.data.core.TfmdLists,\n",
       " 'decode_at': <function fastai.data.core.decode_at(o, idx)>,\n",
       " 'show_at': <function fastai.data.core.show_at(o, idx, **kwargs)>,\n",
       " 'Datasets': fastai.data.core.Datasets,\n",
       " 'test_set': <function fastai.data.core.test_set(dsets, test_items, rm_tfms=None, with_labels=False)>,\n",
       " 'fa_collate': <function fastai.data.load.fa_collate(t)>,\n",
       " 'fa_convert': <function fastai.data.load.fa_convert(t)>,\n",
       " 'SkipItemException': fastai.data.load.SkipItemException,\n",
       " 'DataLoader': fastai.data.load.DataLoader,\n",
       " 'URLs': fastai.data.external.URLs,\n",
       " 'download_url': <function fastai.data.external.download_url(url, dest, overwrite=False, pbar=None, show_progress=True, chunk_size=1048576, timeout=4, retries=5)>,\n",
       " 'download_data': <function fastai.data.external.download_data(url, fname=None, c_key='archive', force_download=False, timeout=4)>,\n",
       " 'file_extract': <function fastai.data.external.file_extract(fname, dest=None)>,\n",
       " 'newest_folder': <function fastai.data.external.newest_folder(path)>,\n",
       " 'rename_extracted': <function fastai.data.external.rename_extracted(dest)>,\n",
       " 'untar_data': <function fastai.data.external.untar_data(url, fname=None, dest=None, c_key='data', force_download=False, extract_func=<function file_extract at 0x7f34bf3bec20>, timeout=4)>,\n",
       " 'get_files': <function fastai.data.transforms.get_files(path, extensions=None, recurse=True, folders=None, followlinks=True)>,\n",
       " 'FileGetter': <function fastai.data.transforms.FileGetter(suf='', extensions=None, recurse=True, folders=None)>,\n",
       " 'image_extensions': {'.art',\n",
       "  '.bmp',\n",
       "  '.cdr',\n",
       "  '.cdt',\n",
       "  '.cpt',\n",
       "  '.cr2',\n",
       "  '.crw',\n",
       "  '.djv',\n",
       "  '.djvu',\n",
       "  '.erf',\n",
       "  '.gif',\n",
       "  '.ico',\n",
       "  '.ief',\n",
       "  '.jng',\n",
       "  '.jp2',\n",
       "  '.jpe',\n",
       "  '.jpeg',\n",
       "  '.jpf',\n",
       "  '.jpg',\n",
       "  '.jpg2',\n",
       "  '.jpm',\n",
       "  '.jpx',\n",
       "  '.nef',\n",
       "  '.orf',\n",
       "  '.pat',\n",
       "  '.pbm',\n",
       "  '.pcx',\n",
       "  '.pgm',\n",
       "  '.png',\n",
       "  '.pnm',\n",
       "  '.ppm',\n",
       "  '.psd',\n",
       "  '.ras',\n",
       "  '.rgb',\n",
       "  '.svg',\n",
       "  '.svgz',\n",
       "  '.tif',\n",
       "  '.tiff',\n",
       "  '.wbmp',\n",
       "  '.xbm',\n",
       "  '.xpm',\n",
       "  '.xwd'},\n",
       " 'get_image_files': <function fastai.data.transforms.get_image_files(path, recurse=True, folders=None)>,\n",
       " 'ImageGetter': <function fastai.data.transforms.ImageGetter(suf='', recurse=True, folders=None)>,\n",
       " 'get_text_files': <function fastai.data.transforms.get_text_files(path, recurse=True, folders=None)>,\n",
       " 'ItemGetter': fastai.data.transforms.ItemGetter,\n",
       " 'AttrGetter': fastai.data.transforms.AttrGetter,\n",
       " 'RandomSplitter': <function fastai.data.transforms.RandomSplitter(valid_pct=0.2, seed=None)>,\n",
       " 'TrainTestSplitter': <function fastai.data.transforms.TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, train_size=None, shuffle=True)>,\n",
       " 'IndexSplitter': <function fastai.data.transforms.IndexSplitter(valid_idx)>,\n",
       " 'GrandparentSplitter': <function fastai.data.transforms.GrandparentSplitter(train_name='train', valid_name='valid')>,\n",
       " 'FuncSplitter': <function fastai.data.transforms.FuncSplitter(func)>,\n",
       " 'MaskSplitter': <function fastai.data.transforms.MaskSplitter(mask)>,\n",
       " 'FileSplitter': <function fastai.data.transforms.FileSplitter(fname)>,\n",
       " 'ColSplitter': <function fastai.data.transforms.ColSplitter(col='is_valid')>,\n",
       " 'RandomSubsetSplitter': <function fastai.data.transforms.RandomSubsetSplitter(train_sz, valid_sz, seed=None)>,\n",
       " 'parent_label': <function fastai.data.transforms.parent_label(o)>,\n",
       " 'RegexLabeller': fastai.data.transforms.RegexLabeller,\n",
       " 'ColReader': fastai.data.transforms.ColReader,\n",
       " 'CategoryMap': fastai.data.transforms.CategoryMap,\n",
       " 'Categorize': fastai.data.transforms.Categorize,\n",
       " 'Category': fastai.data.transforms.Category,\n",
       " 'MultiCategorize': fastai.data.transforms.MultiCategorize,\n",
       " 'MultiCategory': fastai.data.transforms.MultiCategory,\n",
       " 'OneHotEncode': fastai.data.transforms.OneHotEncode,\n",
       " 'EncodedMultiCategorize': fastai.data.transforms.EncodedMultiCategorize,\n",
       " 'RegressionSetup': fastai.data.transforms.RegressionSetup,\n",
       " 'get_c': <function fastai.data.transforms.get_c(dls)>,\n",
       " 'ToTensor': fastai.data.transforms.ToTensor,\n",
       " 'IntToFloatTensor': fastai.data.transforms.IntToFloatTensor,\n",
       " 'broadcast_vec': <function fastai.data.transforms.broadcast_vec(dim, ndim, *t, cuda=True)>,\n",
       " 'Normalize': fastai.data.transforms.Normalize,\n",
       " 'TransformBlock': fastai.data.block.TransformBlock,\n",
       " 'CategoryBlock': <function fastai.data.block.CategoryBlock(vocab=None, sort=True, add_na=False)>,\n",
       " 'MultiCategoryBlock': <function fastai.data.block.MultiCategoryBlock(encoded=False, vocab=None, add_na=False)>,\n",
       " 'RegressionBlock': <function fastai.data.block.RegressionBlock(n_out=None)>,\n",
       " 'DataBlock': fastai.data.block.DataBlock,\n",
       " 'Optimizer': fastai.optimizer.Optimizer,\n",
       " 'sgd_step': <function fastai.optimizer.sgd_step(p, lr, **kwargs)>,\n",
       " 'weight_decay': <function fastai.optimizer.weight_decay(p, lr, wd, do_wd=True, **kwargs)>,\n",
       " 'l2_reg': <function fastai.optimizer.l2_reg(p, lr, wd, do_wd=True, **kwargs)>,\n",
       " 'average_grad': <function fastai.optimizer.average_grad(p, mom, dampening=False, grad_avg=None, **kwargs)>,\n",
       " 'average_sqr_grad': <function fastai.optimizer.average_sqr_grad(p, sqr_mom, dampening=True, sqr_avg=None, **kwargs)>,\n",
       " 'momentum_step': <function fastai.optimizer.momentum_step(p, lr, grad_avg, **kwargs)>,\n",
       " 'SGD': <function fastai.optimizer.SGD(params, lr, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       " 'rms_prop_step': <function fastai.optimizer.rms_prop_step(p, lr, sqr_avg, eps, grad_avg=None, **kwargs)>,\n",
       " 'RMSProp': <function fastai.optimizer.RMSProp(params, lr, sqr_mom=0.99, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       " 'step_stat': <function fastai.optimizer.step_stat(p, step=0, **kwargs)>,\n",
       " 'debias': <function fastai.optimizer.debias(mom, damp, step)>,\n",
       " 'adam_step': <function fastai.optimizer.adam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       " 'Adam': <function fastai.optimizer.Adam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.01, decouple_wd=True)>,\n",
       " 'radam_step': <function fastai.optimizer.radam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, beta, **kwargs)>,\n",
       " 'RAdam': <function fastai.optimizer.RAdam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, beta=0.0, decouple_wd=True)>,\n",
       " 'qhadam_step': <function fastai.optimizer.qhadam_step(p, lr, mom, sqr_mom, sqr_avg, nu_1, nu_2, step, grad_avg, eps, **kwargs)>,\n",
       " 'QHAdam': <function fastai.optimizer.QHAdam(params, lr, mom=0.999, sqr_mom=0.999, nu_1=0.7, nu_2=1.0, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       " 'larc_layer_lr': <function fastai.optimizer.larc_layer_lr(p, lr, trust_coeff, wd, eps, clip=True, **kwargs)>,\n",
       " 'larc_step': <function fastai.optimizer.larc_step(p, local_lr, grad_avg=None, **kwargs)>,\n",
       " 'Larc': <function fastai.optimizer.Larc(params, lr, mom=0.9, clip=True, trust_coeff=0.02, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       " 'lamb_step': <function fastai.optimizer.lamb_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       " 'Lamb': <function fastai.optimizer.Lamb(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, decouple_wd=True)>,\n",
       " 'Lookahead': fastai.optimizer.Lookahead,\n",
       " 'ranger': <function fastai.optimizer.ranger(p, lr, mom=0.95, wd=0.01, eps=1e-06, sqr_mom=0.99, beta=0.0, decouple_wd=True)>,\n",
       " 'detuplify_pg': <function fastai.optimizer.detuplify_pg(d)>,\n",
       " 'set_item_pg': <function fastai.optimizer.set_item_pg(pg, k, v)>,\n",
       " 'pytorch_hp_map': {'momentum': 'mom',\n",
       "  'weight_decay': 'wd',\n",
       "  'alpha': 'sqr_mom',\n",
       "  'betas__0': 'mom',\n",
       "  'betas__1': 'sqr_mom'},\n",
       " 'OptimWrapper': fastai.optimizer.OptimWrapper,\n",
       " 'CancelStepException': fastcore.basics.CancelStepException,\n",
       " 'CancelFitException': fastcore.basics.CancelFitException,\n",
       " 'CancelEpochException': fastcore.basics.CancelEpochException,\n",
       " 'CancelTrainException': fastcore.basics.CancelTrainException,\n",
       " 'CancelValidException': fastcore.basics.CancelValidException,\n",
       " 'CancelBatchException': fastcore.basics.CancelBatchException,\n",
       " 'event': fastcore.basics.event,\n",
       " 'Callback': fastai.callback.core.Callback,\n",
       " 'TrainEvalCallback': fastai.callback.core.TrainEvalCallback,\n",
       " 'GatherPredsCallback': fastai.callback.core.GatherPredsCallback,\n",
       " 'FetchPredsCallback': fastai.callback.core.FetchPredsCallback,\n",
       " 'replacing_yield': <function fastai.learner.replacing_yield(o, attr, val)>,\n",
       " 'mk_metric': <function fastai.learner.mk_metric(m)>,\n",
       " 'save_model': <function fastai.learner.save_model(file, model, opt, with_opt=True, pickle_protocol=2)>,\n",
       " 'load_model': <function fastai.learner.load_model(file, model, opt, with_opt=True, device=None, strict=True)>,\n",
       " 'Learner': fastai.learner.Learner,\n",
       " 'before_batch_cb': <function fastai.learner.before_batch_cb(f)>,\n",
       " 'load_learner': <function fastai.learner.load_learner(fname, cpu=True, pickle_module=<module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>)>,\n",
       " 'to_detach_from_dl': <function fastai.learner.to_detach_from_dl(learn: (<class 'fastai.learner.Learner'>, <class 'NoneType'>), b: object, cpu: bool = True, gather: bool = True)>,\n",
       " 'Metric': fastai.learner.Metric,\n",
       " 'AvgMetric': fastai.learner.AvgMetric,\n",
       " 'AvgLoss': fastai.learner.AvgLoss,\n",
       " 'AvgSmoothLoss': fastai.learner.AvgSmoothLoss,\n",
       " 'ValueMetric': fastai.learner.ValueMetric,\n",
       " 'Recorder': fastai.learner.Recorder,\n",
       " 'AccumMetric': fastai.metrics.AccumMetric,\n",
       " 'skm_to_fastai': <function fastai.metrics.skm_to_fastai(func, is_class=True, thresh=None, axis=-1, activation=None, **kwargs)>,\n",
       " 'optim_metric': <function fastai.metrics.optim_metric(f, argname, bounds, tol=0.01, do_neg=True, get_x=False)>,\n",
       " 'accuracy': <function fastai.metrics.accuracy(inp, targ, axis=-1)>,\n",
       " 'error_rate': <function fastai.metrics.error_rate(inp, targ, axis=-1)>,\n",
       " 'top_k_accuracy': <function fastai.metrics.top_k_accuracy(inp, targ, k=5, axis=-1)>,\n",
       " 'APScoreBinary': <function fastai.metrics.APScoreBinary(axis=-1, average='macro', pos_label=1, sample_weight=None)>,\n",
       " 'BalancedAccuracy': <function fastai.metrics.BalancedAccuracy(axis=-1, sample_weight=None, adjusted=False)>,\n",
       " 'BrierScore': <function fastai.metrics.BrierScore(axis=-1, sample_weight=None, pos_label=None)>,\n",
       " 'CohenKappa': <function fastai.metrics.CohenKappa(axis=-1, labels=None, weights=None, sample_weight=None)>,\n",
       " 'F1Score': <function fastai.metrics.F1Score(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'FBeta': <function fastai.metrics.FBeta(beta, axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'HammingLoss': <function fastai.metrics.HammingLoss(axis=-1, sample_weight=None)>,\n",
       " 'Jaccard': <function fastai.metrics.Jaccard(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'Precision': <function fastai.metrics.Precision(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'Recall': <function fastai.metrics.Recall(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'RocAuc': <function fastai.metrics.RocAuc(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='ovr')>,\n",
       " 'RocAucBinary': <function fastai.metrics.RocAucBinary(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='raise')>,\n",
       " 'MatthewsCorrCoef': <function fastai.metrics.MatthewsCorrCoef(sample_weight=None, **kwargs)>,\n",
       " 'Perplexity': fastai.metrics.Perplexity,\n",
       " 'perplexity': <fastai.metrics.Perplexity at 0x7f34b7101810>,\n",
       " 'accuracy_multi': <function fastai.metrics.accuracy_multi(inp, targ, thresh=0.5, sigmoid=True)>,\n",
       " 'APScoreMulti': <function fastai.metrics.APScoreMulti(sigmoid=True, average='macro', pos_label=1, sample_weight=None)>,\n",
       " 'BrierScoreMulti': <function fastai.metrics.BrierScoreMulti(thresh=0.5, sigmoid=True, sample_weight=None, pos_label=None)>,\n",
       " 'F1ScoreMulti': <function fastai.metrics.F1ScoreMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'FBetaMulti': <function fastai.metrics.FBetaMulti(beta, thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'HammingLossMulti': <function fastai.metrics.HammingLossMulti(thresh=0.5, sigmoid=True, labels=None, sample_weight=None)>,\n",
       " 'JaccardMulti': <function fastai.metrics.JaccardMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'MatthewsCorrCoefMulti': <function fastai.metrics.MatthewsCorrCoefMulti(thresh=0.5, sigmoid=True, sample_weight=None)>,\n",
       " 'PrecisionMulti': <function fastai.metrics.PrecisionMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'RecallMulti': <function fastai.metrics.RecallMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'RocAucMulti': <function fastai.metrics.RocAucMulti(sigmoid=True, average='macro', sample_weight=None, max_fpr=None)>,\n",
       " 'mse': <function fastai.metrics.mse(inp, targ)>,\n",
       " 'rmse': <fastai.metrics.AccumMetric at 0x7f34b7101850>,\n",
       " 'mae': <function fastai.metrics.mae(inp, targ)>,\n",
       " 'msle': <function fastai.metrics.msle(inp, targ)>,\n",
       " 'exp_rmspe': <fastai.metrics.AccumMetric at 0x7f34b71018d0>,\n",
       " 'ExplainedVariance': <function fastai.metrics.ExplainedVariance(sample_weight=None)>,\n",
       " 'R2Score': <function fastai.metrics.R2Score(sample_weight=None)>,\n",
       " 'PearsonCorrCoef': <function fastai.metrics.PearsonCorrCoef(dim_argmax=None, activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       " 'SpearmanCorrCoef': <function fastai.metrics.SpearmanCorrCoef(dim_argmax=None, axis=0, nan_policy='propagate', activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       " 'foreground_acc': <function fastai.metrics.foreground_acc(inp, targ, bkg_idx=0, axis=1)>,\n",
       " 'Dice': fastai.metrics.Dice,\n",
       " 'DiceMulti': fastai.metrics.DiceMulti,\n",
       " 'JaccardCoeff': fastai.metrics.JaccardCoeff,\n",
       " 'CorpusBLEUMetric': fastai.metrics.CorpusBLEUMetric,\n",
       " 'LossMetric': fastai.metrics.LossMetric,\n",
       " 'LossMetrics': <function fastai.metrics.LossMetrics(attrs, nms=None)>,\n",
       " 'plot_top_losses': (TensorImage,TensorMultiCategory) -> plot_top_losses\n",
       " (TensorImage,TensorCategory) -> plot_top_losses\n",
       " (TensorImage,TensorMask) -> plot_top_losses\n",
       " (object,object) -> plot_top_losses,\n",
       " 'Interpretation': fastai.interpret.Interpretation,\n",
       " 'ClassificationInterpretation': fastai.interpret.ClassificationInterpretation,\n",
       " 'SegmentationInterpretation': fastai.interpret.SegmentationInterpretation,\n",
       " 'CollectDataCallback': fastai.callback.data.CollectDataCallback,\n",
       " 'WeightedDL': fastai.callback.data.WeightedDL,\n",
       " 'PartialDL': fastai.callback.data.PartialDL,\n",
       " 'MixedPrecision': fastai.callback.fp16.MixedPrecision,\n",
       " 'FP16TestCallback': fastai.callback.fp16.FP16TestCallback,\n",
       " 'get_master': <function fastai.callback.fp16.get_master(opt, flat_master=False)>,\n",
       " 'to_master_grads': <function fastai.callback.fp16.to_master_grads(model_pgs, master_pgs, flat_master=False)>,\n",
       " 'to_model_params': <function fastai.callback.fp16.to_model_params(model_pgs, master_pgs, flat_master=False) -> None>,\n",
       " 'test_overflow': <function fastai.callback.fp16.test_overflow(x)>,\n",
       " 'grad_overflow': <function fastai.callback.fp16.grad_overflow(pgs)>,\n",
       " 'copy_clone': <function fastai.callback.fp16.copy_clone(d)>,\n",
       " 'ModelToHalf': fastai.callback.fp16.ModelToHalf,\n",
       " 'NonNativeMixedPrecision': fastai.callback.fp16.NonNativeMixedPrecision,\n",
       " 'Hook': fastai.callback.hook.Hook,\n",
       " 'hook_output': <function fastai.callback.hook.hook_output(module, detach=True, cpu=False, grad=False)>,\n",
       " 'Hooks': fastai.callback.hook.Hooks,\n",
       " 'hook_outputs': <function fastai.callback.hook.hook_outputs(modules, detach=True, cpu=False, grad=False)>,\n",
       " 'dummy_eval': <function fastai.callback.hook.dummy_eval(m, size=(64, 64))>,\n",
       " 'model_sizes': <function fastai.callback.hook.model_sizes(m, size=(64, 64))>,\n",
       " 'num_features_model': <function fastai.callback.hook.num_features_model(m)>,\n",
       " 'has_params': <function fastai.callback.hook.has_params(m)>,\n",
       " 'HookCallback': fastai.callback.hook.HookCallback,\n",
       " 'total_params': <function fastai.callback.hook.total_params(m)>,\n",
       " 'layer_info': <function fastai.callback.hook.layer_info(learn, *xb)>,\n",
       " 'module_summary': <function fastai.callback.hook.module_summary(learn, *xb)>,\n",
       " 'ActivationStats': fastai.callback.hook.ActivationStats,\n",
       " 'reduce_loss': <function fastai.callback.mixup.reduce_loss(loss, reduction='mean')>,\n",
       " 'MixHandler': fastai.callback.mixup.MixHandler,\n",
       " 'MixUp': fastai.callback.mixup.MixUp,\n",
       " 'CutMix': fastai.callback.mixup.CutMix,\n",
       " 'ProgressCallback': fastai.callback.progress.ProgressCallback,\n",
       " 'ShowGraphCallback': fastai.callback.progress.ShowGraphCallback,\n",
       " 'CSVLogger': fastai.callback.progress.CSVLogger,\n",
       " 'annealer': <function fastai.callback.schedule.annealer(f)>,\n",
       " 'sched_lin': <function fastai.callback.schedule.sched_lin(start, end, pos)>,\n",
       " 'sched_cos': <function fastai.callback.schedule.sched_cos(start, end, pos)>,\n",
       " 'sched_no': <function fastai.callback.schedule.sched_no(start, end, pos)>,\n",
       " 'sched_exp': <function fastai.callback.schedule.sched_exp(start, end, pos)>,\n",
       " 'SchedLin': <function fastai.callback.schedule.SchedLin(start, end)>,\n",
       " 'SchedCos': <function fastai.callback.schedule.SchedCos(start, end)>,\n",
       " 'SchedNo': <function fastai.callback.schedule.SchedNo(start, end)>,\n",
       " 'SchedExp': <function fastai.callback.schedule.SchedExp(start, end)>,\n",
       " 'SchedPoly': <function fastai.callback.schedule.SchedPoly(start, end, power)>,\n",
       " 'combine_scheds': <function fastai.callback.schedule.combine_scheds(pcts, scheds)>,\n",
       " 'combined_cos': <function fastai.callback.schedule.combined_cos(pct, start, middle, end)>,\n",
       " 'ParamScheduler': fastai.callback.schedule.ParamScheduler,\n",
       " 'LRFinder': fastai.callback.schedule.LRFinder,\n",
       " 'SuggestedLRs': fastai.callback.schedule.SuggestedLRs,\n",
       " 'TerminateOnNaNCallback': fastai.callback.tracker.TerminateOnNaNCallback,\n",
       " 'TrackerCallback': fastai.callback.tracker.TrackerCallback,\n",
       " 'EarlyStoppingCallback': fastai.callback.tracker.EarlyStoppingCallback,\n",
       " 'SaveModelCallback': fastai.callback.tracker.SaveModelCallback,\n",
       " 'ReduceLROnPlateau': fastai.callback.tracker.ReduceLROnPlateau,\n",
       " 'ModelResetter': fastai.callback.rnn.ModelResetter,\n",
       " 'RNNCallback': fastai.callback.rnn.RNNCallback,\n",
       " 'RNNRegularizer': fastai.callback.rnn.RNNRegularizer,\n",
       " 'rnn_cbs': <function fastai.callback.rnn.rnn_cbs(alpha=0.0, beta=0.0)>,\n",
       " 'ShortEpochCallback': fastai.callback.training.ShortEpochCallback,\n",
       " 'GradientAccumulation': fastai.callback.training.GradientAccumulation,\n",
       " 'GradientClip': fastai.callback.training.GradientClip,\n",
       " 'set_bn_eval': <function fastai.callback.training.set_bn_eval(m: torch.nn.modules.module.Module, use_eval=True) -> None>,\n",
       " 'BnFreeze': fastai.callback.training.BnFreeze,\n",
       " 'bn_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm3d),\n",
       " 'MCDropoutCallback': fastai.callback.preds.MCDropoutCallback,\n",
       " 'RandTransform': fastai.vision.augment.RandTransform,\n",
       " 'TensorTypes': (fastai.torch_core.TensorImage,\n",
       "  fastai.torch_core.TensorMask,\n",
       "  fastai.vision.core.TensorPoint,\n",
       "  fastai.vision.core.TensorBBox),\n",
       " 'FlipItem': fastai.vision.augment.FlipItem,\n",
       " 'DihedralItem': fastai.vision.augment.DihedralItem,\n",
       " 'PadMode': fastcore.basics.PadMode,\n",
       " 'CropPad': fastai.vision.augment.CropPad,\n",
       " 'RandomCrop': fastai.vision.augment.RandomCrop,\n",
       " 'OldRandomCrop': fastai.vision.augment.OldRandomCrop,\n",
       " 'ResizeMethod': fastcore.basics.ResizeMethod,\n",
       " 'Resize': fastai.vision.augment.Resize,\n",
       " 'RandomResizedCrop': fastai.vision.augment.RandomResizedCrop,\n",
       " 'RatioResize': fastai.vision.augment.RatioResize,\n",
       " 'affine_grid': <function fastai.vision.augment.affine_grid(theta, size, align_corners=None)>,\n",
       " 'AffineCoordTfm': fastai.vision.augment.AffineCoordTfm,\n",
       " 'RandomResizedCropGPU': fastai.vision.augment.RandomResizedCropGPU,\n",
       " 'mask_tensor': <function fastai.vision.augment.mask_tensor(x, p=0.5, neutral=0.0, batch=False)>,\n",
       " 'affine_mat': <function fastai.vision.augment.affine_mat(*ms)>,\n",
       " 'flip_mat': <function fastai.vision.augment.flip_mat(x, p=0.5, draw=None, batch=False)>,\n",
       " 'Flip': fastai.vision.augment.Flip,\n",
       " 'DeterministicDraw': fastai.vision.augment.DeterministicDraw,\n",
       " 'DeterministicFlip': fastai.vision.augment.DeterministicFlip,\n",
       " 'dihedral_mat': <function fastai.vision.augment.dihedral_mat(x, p=0.5, draw=None, batch=False)>,\n",
       " 'Dihedral': fastai.vision.augment.Dihedral,\n",
       " 'DeterministicDihedral': fastai.vision.augment.DeterministicDihedral,\n",
       " 'rotate_mat': <function fastai.vision.augment.rotate_mat(x, max_deg=10, p=0.5, draw=None, batch=False)>,\n",
       " 'Rotate': fastai.vision.augment.Rotate,\n",
       " 'zoom_mat': <function fastai.vision.augment.zoom_mat(x, min_zoom=1.0, max_zoom=1.1, p=0.5, draw=None, draw_x=None, draw_y=None, batch=False)>,\n",
       " 'Zoom': fastai.vision.augment.Zoom,\n",
       " 'find_coeffs': <function fastai.vision.augment.find_coeffs(p1, p2)>,\n",
       " 'apply_perspective': <function fastai.vision.augment.apply_perspective(coords, coeffs)>,\n",
       " 'Warp': fastai.vision.augment.Warp,\n",
       " 'SpaceTfm': fastai.vision.augment.SpaceTfm,\n",
       " 'LightingTfm': fastai.vision.augment.LightingTfm,\n",
       " 'Brightness': fastai.vision.augment.Brightness,\n",
       " 'Contrast': fastai.vision.augment.Contrast,\n",
       " 'grayscale': <function fastai.vision.augment.grayscale(x)>,\n",
       " 'Saturation': fastai.vision.augment.Saturation,\n",
       " 'rgb2hsv': <function fastai.vision.augment.rgb2hsv(img)>,\n",
       " 'hsv2rgb': <function fastai.vision.augment.hsv2rgb(img)>,\n",
       " 'HSVTfm': fastai.vision.augment.HSVTfm,\n",
       " 'Hue': fastai.vision.augment.Hue,\n",
       " 'cutout_gaussian': <function fastai.vision.augment.cutout_gaussian(x, areas)>,\n",
       " 'norm_apply_denorm': <function fastai.vision.augment.norm_apply_denorm(x, f, nrm)>,\n",
       " 'RandomErasing': fastai.vision.augment.RandomErasing,\n",
       " 'setup_aug_tfms': <function fastai.vision.augment.setup_aug_tfms(tfms)>,\n",
       " 'aug_transforms': <function fastai.vision.augment.aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=None, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0)>,\n",
       " 'Image': <module 'PIL.Image' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/PIL/Image.py'>,\n",
       " 'imagenet_stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
       " 'cifar_stats': ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261]),\n",
       " 'mnist_stats': ([0.131], [0.308]),\n",
       " 'n_px': None,\n",
       " 'shape': None,\n",
       " 'aspect': None,\n",
       " 'to_image': <function fastai.vision.core.to_image(x)>,\n",
       " 'load_image': <function fastai.vision.core.load_image(fn, mode=None)>,\n",
       " 'image2tensor': <function fastai.vision.core.image2tensor(img)>,\n",
       " 'PILBase': fastai.vision.core.PILBase,\n",
       " 'PILImage': fastai.vision.core.PILImage,\n",
       " 'PILImageBW': fastai.vision.core.PILImageBW,\n",
       " 'PILMask': fastai.vision.core.PILMask,\n",
       " 'OpenMask': PILBase.create:\n",
       " encodes: (Path,object) -> create\n",
       " (str,object) -> create\n",
       " (Tensor,object) -> create\n",
       " (ndarray,object) -> create\n",
       " (bytes,object) -> createdecodes: ,\n",
       " 'AddMaskCodes': fastai.vision.core.AddMaskCodes,\n",
       " 'TensorPoint': fastai.vision.core.TensorPoint,\n",
       " 'TensorPointCreate': TensorPoint.create:\n",
       " encodes: (object,object) -> createdecodes: ,\n",
       " 'get_annotations': <function fastai.vision.core.get_annotations(fname, prefix=None)>,\n",
       " 'TensorBBox': fastai.vision.core.TensorBBox,\n",
       " 'LabeledBBox': fastai.vision.core.LabeledBBox,\n",
       " 'encodes': <function fastai.vision.core.encodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       " 'PointScaler': fastai.vision.core.PointScaler,\n",
       " 'BBoxLabeler': fastai.vision.core.BBoxLabeler,\n",
       " 'decodes': <function fastai.vision.core.decodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       " 'get_grid': <function fastai.vision.data.get_grid(n, nrows=None, ncols=None, add_vert=0, figsize=None, double=False, title=None, return_fig=False, flatten=True, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       " 'clip_remove_empty': <function fastai.vision.data.clip_remove_empty(bbox, label)>,\n",
       " 'bb_pad': <function fastai.vision.data.bb_pad(samples, pad_idx=0)>,\n",
       " 'ImageBlock': <function fastai.vision.data.ImageBlock(cls=<class 'fastai.vision.core.PILImage'>)>,\n",
       " 'MaskBlock': <function fastai.vision.data.MaskBlock(codes=None)>,\n",
       " 'PointBlock': <fastai.data.block.TransformBlock at 0x7f34b7020410>,\n",
       " 'BBoxBlock': <fastai.data.block.TransformBlock at 0x7f34b7093850>,\n",
       " 'BBoxLblBlock': <function fastai.vision.data.BBoxLblBlock(vocab=None, add_na=True)>,\n",
       " 'ImageDataLoaders': fastai.vision.data.ImageDataLoaders,\n",
       " 'SegmentationDataLoaders': fastai.vision.data.SegmentationDataLoaders,\n",
       " 'init_cnn': <function fastai.vision.models.xresnet.init_cnn(m)>,\n",
       " 'XResNet': fastai.vision.models.xresnet.XResNet,\n",
       " 'xresnet18': <function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>,\n",
       " 'xresnet34': <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>,\n",
       " 'xresnet50': <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>,\n",
       " 'xresnet101': <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>,\n",
       " 'xresnet152': <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>,\n",
       " 'xresnet18_deep': <function fastai.vision.models.xresnet.xresnet18_deep(pretrained=False, **kwargs)>,\n",
       " 'xresnet34_deep': <function fastai.vision.models.xresnet.xresnet34_deep(pretrained=False, **kwargs)>,\n",
       " 'xresnet50_deep': <function fastai.vision.models.xresnet.xresnet50_deep(pretrained=False, **kwargs)>,\n",
       " 'xresnet18_deeper': <function fastai.vision.models.xresnet.xresnet18_deeper(pretrained=False, **kwargs)>,\n",
       " 'xresnet34_deeper': <function fastai.vision.models.xresnet.xresnet34_deeper(pretrained=False, **kwargs)>,\n",
       " 'xresnet50_deeper': <function fastai.vision.models.xresnet.xresnet50_deeper(pretrained=False, **kwargs)>,\n",
       " 'se_kwargs1': {'groups': 1, 'reduction': 16},\n",
       " 'se_kwargs2': {'groups': 32, 'reduction': 16},\n",
       " 'se_kwargs3': {'groups': 32, 'reduction': 0},\n",
       " 'g0': [2, 2, 2, 2],\n",
       " 'g1': [3, 4, 6, 3],\n",
       " 'g2': [3, 4, 23, 3],\n",
       " 'g3': [3, 8, 36, 3],\n",
       " 'xse_resnet18': <function fastai.vision.models.xresnet.xse_resnet18(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext18': <function fastai.vision.models.xresnet.xse_resnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext18': <function fastai.vision.models.xresnet.xresnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet34': <function fastai.vision.models.xresnet.xse_resnet34(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext34': <function fastai.vision.models.xresnet.xse_resnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext34': <function fastai.vision.models.xresnet.xresnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet50': <function fastai.vision.models.xresnet.xse_resnet50(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext50': <function fastai.vision.models.xresnet.xse_resnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext50': <function fastai.vision.models.xresnet.xresnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet101': <function fastai.vision.models.xresnet.xse_resnet101(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext101': <function fastai.vision.models.xresnet.xse_resnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext101': <function fastai.vision.models.xresnet.xresnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet152': <function fastai.vision.models.xresnet.xse_resnet152(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xsenet154': <function fastai.vision.models.xresnet.xsenet154(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext18_deep': <function fastai.vision.models.xresnet.xse_resnext18_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext34_deep': <function fastai.vision.models.xresnet.xse_resnext34_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext50_deep': <function fastai.vision.models.xresnet.xse_resnext50_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext18_deeper': <function fastai.vision.models.xresnet.xse_resnext18_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext34_deeper': <function fastai.vision.models.xresnet.xse_resnext34_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext50_deeper': <function fastai.vision.models.xresnet.xse_resnext50_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'UnetBlock': fastai.vision.models.unet.UnetBlock,\n",
       " 'ResizeToOrig': fastai.vision.models.unet.ResizeToOrig,\n",
       " 'DynamicUnet': fastai.vision.models.unet.DynamicUnet,\n",
       " 'ResNet': torchvision.models.resnet.ResNet,\n",
       " 'resnet18': <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet34': <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet50': <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet101': <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet152': <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'SqueezeNet': torchvision.models.squeezenet.SqueezeNet,\n",
       " 'squeezenet1_0': <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       " 'squeezenet1_1': <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       " 'densenet121': <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet169': <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet201': <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet161': <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'vgg11_bn': <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg13_bn': <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg16_bn': <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg19_bn': <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'alexnet': <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>,\n",
       " 'has_pool_type': <function fastai.vision.learner.has_pool_type(m)>,\n",
       " 'create_body': <function fastai.vision.learner.create_body(arch, n_in=3, pretrained=True, cut=None)>,\n",
       " 'create_head': <function fastai.vision.learner.create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       " 'default_split': <function fastai.vision.learner.default_split(m)>,\n",
       " 'model_meta': {<function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._alexnet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])}},\n",
       " 'create_cnn_model': <function fastai.vision.learner.create_cnn_model(arch, n_out, pretrained=True, cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       " 'cnn_learner': <function fastai.vision.learner.cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       " 'create_unet_model': <function fastai.vision.learner.create_unet_model(arch, n_out, img_size, pretrained=True, cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       " 'unet_learner': <function fastai.vision.learner.unet_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       " 'download_images': <function fastai.vision.utils.download_images(dest, url_file=None, urls=None, max_pics=1000, n_workers=8, timeout=4, preserve_filename=False)>,\n",
       " 'resize_to': <function fastai.vision.utils.resize_to(img, targ_sz, use_min=False)>,\n",
       " 'verify_image': <function fastai.vision.utils.verify_image(fn)>,\n",
       " 'verify_images': <function fastai.vision.utils.verify_images(fns)>,\n",
       " 'resize_image': <function fastai.vision.utils.resize_image(file, dest, max_size=None, n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=False, **kwargs)>,\n",
       " 'resize_images': <function fastai.vision.utils.resize_images(path, max_workers=4, max_size=None, recurse=False, dest=Path('.'), n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=None, **kwargs)>,\n",
       " 'transforms': <module 'torchaudio.transforms' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/transforms.py'>,\n",
       " 'make_dataclass': <function dataclasses.make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)>,\n",
       " 'signature': <function inspect.signature(obj, *, follow_wrapped=True)>,\n",
       " 'save_audio': <function torchaudio.backend.sox_io_backend.save(filepath: str, src: torch.Tensor, sample_rate: int, channels_first: bool = True, compression: Union[float, NoneType] = None, format: Union[str, NoneType] = None, encoding: Union[str, NoneType] = None, bits_per_sample: Union[int, NoneType] = None)>,\n",
       " 'Resample': fastaudio.augment.preprocess.Resample,\n",
       " 'DownmixMono': fastaudio.augment.signal.DownmixMono,\n",
       " 'ResizeSignal': fastaudio.augment.signal.ResizeSignal,\n",
       " 'AudioTensor': fastaudio.core.signal.AudioTensor,\n",
       " 'get_audio_files': <function fastaudio.core.signal.get_audio_files(path, recurse=True, folders=None)>,\n",
       " 'audio_item_tfms': <function fastaudio.core.config.audio_item_tfms(sample_rate=16000, force_mono=True, crop_signal_to=None)>,\n",
       " 'PreprocessAudio': fastaudio.core.config.PreprocessAudio,\n",
       " 'preprocess_audio_folder': <function fastaudio.core.config.preprocess_audio_folder(path, folders=None, output_dir=None, sample_rate=16000, force_mono=True, crop_signal_to=None, **kwargs)>,\n",
       " 'AudioBlock': fastaudio.core.config.AudioBlock,\n",
       " 'config_from_func': <function fastaudio.core.config.config_from_func(func, name, **kwargs)>,\n",
       " 'AudioConfig': fastaudio.core.config.AudioConfig,\n",
       " 'torchaudio': <module 'torchaudio' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/__init__.py'>,\n",
       " 'Audio': IPython.lib.display.Audio,\n",
       " 'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
       " 'waveplot': <function librosa.display.waveplot(y, sr=22050, max_points=50000.0, x_axis='time', offset=0.0, max_sr=1000, ax=None, **kwargs)>,\n",
       " 'path': <module 'posixpath' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/posixpath.py'>,\n",
       " 'audio_extensions': ('.m3u',\n",
       "  '.ram',\n",
       "  '.au',\n",
       "  '.snd',\n",
       "  '.mp3',\n",
       "  '.mp2',\n",
       "  '.aif',\n",
       "  '.aifc',\n",
       "  '.aiff',\n",
       "  '.ra',\n",
       "  '.wav',\n",
       "  '.amr',\n",
       "  '.awb',\n",
       "  '.axa',\n",
       "  '.csd',\n",
       "  '.orc',\n",
       "  '.sco',\n",
       "  '.flac',\n",
       "  '.mid',\n",
       "  '.midi',\n",
       "  '.kar',\n",
       "  '.mpga',\n",
       "  '.mpega',\n",
       "  '.m4a',\n",
       "  '.oga',\n",
       "  '.ogg',\n",
       "  '.opus',\n",
       "  '.spx',\n",
       "  '.sid',\n",
       "  '.gsm',\n",
       "  '.wma',\n",
       "  '.wax',\n",
       "  '.rm',\n",
       "  '.pls',\n",
       "  '.sd2'),\n",
       " 'AudioGetter': <function fastaudio.core.signal.AudioGetter(suf='', recurse=True, folders=None)>,\n",
       " 'tar_extract_at_filename': <function fastaudio.core.signal.tar_extract_at_filename(fname, dest)>,\n",
       " 'show_audio_signal': <function fastaudio.core.signal.show_audio_signal(ai, ctx, ax=None, title='', **kwargs)>,\n",
       " 'OpenAudio': fastaudio.core.signal.OpenAudio,\n",
       " 'asdict': <function dataclasses.asdict(obj, *, dict_factory=<class 'dict'>)>,\n",
       " 'is_dataclass': <function dataclasses.is_dataclass(obj)>,\n",
       " 'specshow': <function librosa.display.specshow(data, x_coords=None, y_coords=None, x_axis=None, y_axis=None, sr=22050, hop_length=512, fmin=None, fmax=None, tuning=0.0, bins_per_octave=12, key='C:maj', Sa=None, mela=None, thaat=None, ax=None, **kwargs)>,\n",
       " 'AudioSpectrogram': fastaudio.core.spectrogram.AudioSpectrogram,\n",
       " 'show_spectrogram': <function fastaudio.core.spectrogram.show_spectrogram(sg, title='', ax=None, ctx=None, **kwargs)>,\n",
       " 'AudioToSpec': fastaudio.core.spectrogram.AudioToSpec,\n",
       " 'SpectrogramTransformer': <function fastaudio.core.spectrogram.SpectrogramTransformer(mel=True, to_db=True)>,\n",
       " 'fill_pipeline': <function fastaudio.core.spectrogram.fill_pipeline(transform_list, sg_type, **kwargs)>,\n",
       " 'warn_unused': <function fastaudio.core.spectrogram.warn_unused(all_kwargs, used_kwargs)>,\n",
       " 'get_usable_kwargs': <function fastaudio.core.spectrogram.get_usable_kwargs(func, kwargs, exclude=None)>,\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v for k,v in locals().copy().items() if k[:2] != '__'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "  'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "  \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"p = Path('data/pitch_accent')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "  'import fastai\\nfastai.__version__',\n",
       "  'AudioConfig.Voice',\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "  'my_dict = object()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "  'd.__setattr__(b=b)',\n",
       "  'd.__setattr__(b,b)',\n",
       "  \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "  \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "  'locals()'],\n",
       " '_oh': {8:                                         path pattern  kana  morae  drop  \\\n",
       "  0       accentAudio/ある.yomi000142BB_0596.mp3      頭高    アル      2     1   \n",
       "  1       accentAudio/思う.yomi0006C617_043A.mp3      中高   オモウ      3     2   \n",
       "  2       accentAudio/など.yomi000240B7_0028.mp3      頭高    ナド      2     1   \n",
       "  3        accentAudio/私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0   \n",
       "  4       accentAudio/見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1   \n",
       "  ...                                      ...     ...   ...    ...   ...   \n",
       "  163962      OjadMedia/立て-377_10_1_female.mp3      頭高    たて      2     1   \n",
       "  163963       OjadMedia/立てる-377_11_1_male.mp3      中高   たてる      3     2   \n",
       "  163964     OjadMedia/立てる-377_11_1_female.mp3      中高   たてる      3     2   \n",
       "  163965       OjadMedia/立とう-377_12_1_male.mp3      中高   たとう      3     2   \n",
       "  163966     OjadMedia/立とう-377_12_1_female.mp3      中高   たとう      3     2   \n",
       "  \n",
       "                 type  \n",
       "  0               nhk  \n",
       "  1               nhk  \n",
       "  2               nhk  \n",
       "  3               nhk  \n",
       "  4               nhk  \n",
       "  ...             ...  \n",
       "  163962  ojad female  \n",
       "  163963    ojad male  \n",
       "  163964  ojad female  \n",
       "  163965    ojad male  \n",
       "  163966  ojad female  \n",
       "  \n",
       "  [163967 rows x 6 columns],\n",
       "  10:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  12:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  13:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  16:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  18:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  19:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  20:                                                      path pattern      kana  \\\n",
       "  0         ある-66_1_1_male.mp3dict1ある.yomi000142BB_0596.mp3    頭高頭高      あるアル   \n",
       "  1       ある-66_1_1_female.mp3dict1思う.yomi0006C617_043A.mp3    頭高中高     あるオモウ   \n",
       "  2       あります-66_2_1_male.mp3dict1など.yomi000240B7_0028.mp3    中高頭高    ありますナド   \n",
       "  3      あります-66_2_1_female.mp3dict1私.yomi00092F63_0072.mp3    中高平板  ありますワタくシ   \n",
       "  4        あって-66_3_1_male.mp3dict1見る.yomi000A41BD_001E.mp3    頭高頭高     あってミル   \n",
       "  ...                                                   ...     ...       ...   \n",
       "  84477                                                 NaN     NaN       NaN   \n",
       "  84478                                                 NaN     NaN       NaN   \n",
       "  84479                                                 NaN     NaN       NaN   \n",
       "  84480                                                 NaN     NaN       NaN   \n",
       "  84481                                                 NaN     NaN       NaN   \n",
       "  \n",
       "         morae  drop               type  \n",
       "  0        4.0   2.0    dict2 maledict1  \n",
       "  1        5.0   3.0  dict2 femaledict1  \n",
       "  2        6.0   4.0    dict2 maledict1  \n",
       "  3        8.0   3.0  dict2 femaledict1  \n",
       "  4        5.0   2.0    dict2 maledict1  \n",
       "  ...      ...   ...                ...  \n",
       "  84477    NaN   NaN                NaN  \n",
       "  84478    NaN   NaN                NaN  \n",
       "  84479    NaN   NaN                NaN  \n",
       "  84480    NaN   NaN                NaN  \n",
       "  84481    NaN   NaN                NaN  \n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  23:                                 path pattern  kana  morae  drop          type\n",
       "  0      dict1ある.yomi000142BB_0596.mp3      頭高    アル      2     1         dict1\n",
       "  1      dict1思う.yomi0006C617_043A.mp3      中高   オモウ      3     2         dict1\n",
       "  2      dict1など.yomi000240B7_0028.mp3      頭高    ナド      2     1         dict1\n",
       "  3       dict1私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0         dict1\n",
       "  4      dict1見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1         dict1\n",
       "  ...                              ...     ...   ...    ...   ...           ...\n",
       "  84477         立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478          立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479        立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480          立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481        立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [163966 rows x 6 columns],\n",
       "  24: '2.3.1',\n",
       "  25: types.Voice,\n",
       "  37: {'k': 3.0}},\n",
       " '_dh': ['/home/mizoru/ML/japanese-ml'],\n",
       " 'In': ['',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       "  \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'), Path('data'))\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tar_extract_at_filename')\",\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'tarfile.open')\",\n",
       "  'tarfile.open(Path(\\'dataset/pitch_accent.tar.gz\\'), \"r:gz\").extractall(\\'data\\')',\n",
       "  \"pd.read_csv('data/pitch_accent/all_labeles.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv', index=False)\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict1_labels.csv')\",\n",
       "  \"pd.read_csv('data/pitch_accent/dict2_labels.csv')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"p = Path('data/pitch_accent')\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\nlabels2 + labels1\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.join(labels1, labels2)\",\n",
       "  \"labels1 = pd.read_csv(p/'dict1_labels.csv')\\nlabels1.path = 'dict1' + labels1.path\\nlabels2 = pd.read_csv(p/'dict2_labels.csv')\\nlabels2 = labels2[labels2.path != '見上げさせる-1567_8_2_male.mp3']\\npd.concat([labels1, labels2])\",\n",
       "  'import fastai\\nfastai.__version__',\n",
       "  'AudioConfig.Voice',\n",
       "  \"get_ipython().run_line_magic('pinfo2', 'AudioConfig.Voice')\",\n",
       "  'my_dict = object()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  'class NewClass(object): pass\\nmydict = NewClass()',\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nfor i in [a,b,k]:\\n    my_dict.i = i\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k:k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k for k in [a,b,k])\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\ndict(k=k)\",\n",
       "  \"a, b, k = 10, 'i', 3.0\\nd = dict(k=k)\",\n",
       "  'd.__setattr__(b=b)',\n",
       "  'd.__setattr__(b,b)',\n",
       "  \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       "  \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       "  'locals()'],\n",
       " 'Out': {8:                                         path pattern  kana  morae  drop  \\\n",
       "  0       accentAudio/ある.yomi000142BB_0596.mp3      頭高    アル      2     1   \n",
       "  1       accentAudio/思う.yomi0006C617_043A.mp3      中高   オモウ      3     2   \n",
       "  2       accentAudio/など.yomi000240B7_0028.mp3      頭高    ナド      2     1   \n",
       "  3        accentAudio/私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0   \n",
       "  4       accentAudio/見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1   \n",
       "  ...                                      ...     ...   ...    ...   ...   \n",
       "  163962      OjadMedia/立て-377_10_1_female.mp3      頭高    たて      2     1   \n",
       "  163963       OjadMedia/立てる-377_11_1_male.mp3      中高   たてる      3     2   \n",
       "  163964     OjadMedia/立てる-377_11_1_female.mp3      中高   たてる      3     2   \n",
       "  163965       OjadMedia/立とう-377_12_1_male.mp3      中高   たとう      3     2   \n",
       "  163966     OjadMedia/立とう-377_12_1_female.mp3      中高   たとう      3     2   \n",
       "  \n",
       "                 type  \n",
       "  0               nhk  \n",
       "  1               nhk  \n",
       "  2               nhk  \n",
       "  3               nhk  \n",
       "  4               nhk  \n",
       "  ...             ...  \n",
       "  163962  ojad female  \n",
       "  163963    ojad male  \n",
       "  163964  ojad female  \n",
       "  163965    ojad male  \n",
       "  163966  ojad female  \n",
       "  \n",
       "  [163967 rows x 6 columns],\n",
       "  10:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  12:                                       path pattern        kana  morae  drop  \\\n",
       "  0                 ある.yomi000142BB_0596.mp3      頭高          アル      2     1   \n",
       "  1                 思う.yomi0006C617_043A.mp3      中高         オモウ      3     2   \n",
       "  2                 など.yomi000240B7_0028.mp3      頭高          ナド      2     1   \n",
       "  3                  私.yomi00092F63_0072.mp3      平板        ワタくシ      4     0   \n",
       "  4                 見る.yomi000A41BD_001E.mp3      頭高          ミル      2     1   \n",
       "  ...                                    ...     ...         ...    ...   ...   \n",
       "  79480      捨てがな_捨て仮名.yomi00072538_06BE.mp3      平板       すテカ゚ナ      5     0   \n",
       "  79481  くも膜下出血_蜘蛛膜下出血.yomi0001AAD1_0622.mp3      中高  クモマッカしュッケツ      9     6   \n",
       "  79482             捜す.yomi00072507_0088.mp3      平板        サカ゚ス      4     0   \n",
       "  79483            捜し物.yomi000724FD_0424.mp3      平板      サカ゚シモノ      6     0   \n",
       "  79484      あこや貝_阿古屋貝.yomi00013767_0114.mp3      中高      アコヤカ゚イ      6     3   \n",
       "  \n",
       "          type  \n",
       "  0      dict1  \n",
       "  1      dict1  \n",
       "  2      dict1  \n",
       "  3      dict1  \n",
       "  4      dict1  \n",
       "  ...      ...  \n",
       "  79480  dict1  \n",
       "  79481  dict1  \n",
       "  79482  dict1  \n",
       "  79483  dict1  \n",
       "  79484  dict1  \n",
       "  \n",
       "  [79485 rows x 6 columns],\n",
       "  13:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  16:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  18:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  19:                           path pattern  kana  morae  drop          type\n",
       "  0           ある-66_1_1_male.mp3      頭高    ある      2     1    dict2 male\n",
       "  1         ある-66_1_1_female.mp3      頭高    ある      2     1  dict2 female\n",
       "  2         あります-66_2_1_male.mp3      中高  あります      4     3    dict2 male\n",
       "  3       あります-66_2_1_female.mp3      中高  あります      4     3  dict2 female\n",
       "  4          あって-66_3_1_male.mp3      頭高   あって      3     1    dict2 male\n",
       "  ...                        ...     ...   ...    ...   ...           ...\n",
       "  84477   立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478    立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479  立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480    立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481  立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [84481 rows x 6 columns],\n",
       "  20:                                                      path pattern      kana  \\\n",
       "  0         ある-66_1_1_male.mp3dict1ある.yomi000142BB_0596.mp3    頭高頭高      あるアル   \n",
       "  1       ある-66_1_1_female.mp3dict1思う.yomi0006C617_043A.mp3    頭高中高     あるオモウ   \n",
       "  2       あります-66_2_1_male.mp3dict1など.yomi000240B7_0028.mp3    中高頭高    ありますナド   \n",
       "  3      あります-66_2_1_female.mp3dict1私.yomi00092F63_0072.mp3    中高平板  ありますワタくシ   \n",
       "  4        あって-66_3_1_male.mp3dict1見る.yomi000A41BD_001E.mp3    頭高頭高     あってミル   \n",
       "  ...                                                   ...     ...       ...   \n",
       "  84477                                                 NaN     NaN       NaN   \n",
       "  84478                                                 NaN     NaN       NaN   \n",
       "  84479                                                 NaN     NaN       NaN   \n",
       "  84480                                                 NaN     NaN       NaN   \n",
       "  84481                                                 NaN     NaN       NaN   \n",
       "  \n",
       "         morae  drop               type  \n",
       "  0        4.0   2.0    dict2 maledict1  \n",
       "  1        5.0   3.0  dict2 femaledict1  \n",
       "  2        6.0   4.0    dict2 maledict1  \n",
       "  3        8.0   3.0  dict2 femaledict1  \n",
       "  4        5.0   2.0    dict2 maledict1  \n",
       "  ...      ...   ...                ...  \n",
       "  84477    NaN   NaN                NaN  \n",
       "  84478    NaN   NaN                NaN  \n",
       "  84479    NaN   NaN                NaN  \n",
       "  84480    NaN   NaN                NaN  \n",
       "  84481    NaN   NaN                NaN  \n",
       "  \n",
       "  [84482 rows x 6 columns],\n",
       "  23:                                 path pattern  kana  morae  drop          type\n",
       "  0      dict1ある.yomi000142BB_0596.mp3      頭高    アル      2     1         dict1\n",
       "  1      dict1思う.yomi0006C617_043A.mp3      中高   オモウ      3     2         dict1\n",
       "  2      dict1など.yomi000240B7_0028.mp3      頭高    ナド      2     1         dict1\n",
       "  3       dict1私.yomi00092F63_0072.mp3      平板  ワタくシ      4     0         dict1\n",
       "  4      dict1見る.yomi000A41BD_001E.mp3      頭高    ミル      2     1         dict1\n",
       "  ...                              ...     ...   ...    ...   ...           ...\n",
       "  84477         立て-377_10_1_female.mp3      頭高    たて      2     1  dict2 female\n",
       "  84478          立てる-377_11_1_male.mp3      中高   たてる      3     2    dict2 male\n",
       "  84479        立てる-377_11_1_female.mp3      中高   たてる      3     2  dict2 female\n",
       "  84480          立とう-377_12_1_male.mp3      中高   たとう      3     2    dict2 male\n",
       "  84481        立とう-377_12_1_female.mp3      中高   たとう      3     2  dict2 female\n",
       "  \n",
       "  [163966 rows x 6 columns],\n",
       "  24: '2.3.1',\n",
       "  25: types.Voice,\n",
       "  37: {'k': 3.0}},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f354f4bc590>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f354f435990>,\n",
       " '_': {'k': 3.0},\n",
       " '__': types.Voice,\n",
       " '___': '2.3.1',\n",
       " 'os': <module 'os' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/os.py'>,\n",
       " 'sys': <module 'sys' (built-in)>,\n",
       " '__vsc_ipynb_file__': '/home/mizoru/ML/japanese-ml/get_data.ipynb',\n",
       " '_i': \"{k:v for k,v in locals().copy() if k[:2] != '__'}\",\n",
       " '_ii': \"{k:v for k,v in locals().copy().iteritems() if k[:2] != '__'}\",\n",
       " '_iii': 'd.__setattr__(b,b)',\n",
       " '_i1': \"tar_extract_at_filename(Path('dataset/pitch_accent.tar.gz'))\",\n",
       " '_i2': 'import os\\nfrom fastai.vision.all import *\\nfrom fastaudio.core.all import *\\nfrom fastaudio.augment.all import *\\nfrom fastcore.xtras import untar_dir\\n# import tarfile',\n",
       " 'models': <module 'fastai.vision.models' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/fastai/vision/models/__init__.py'>,\n",
       " 'multiprocessing': <module 'multiprocessing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/__init__.py'>,\n",
       " 'platform': <module 'platform' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/platform.py'>,\n",
       " 'np': <module 'numpy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/numpy/__init__.py'>,\n",
       " 'io': <module 'io' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/io.py'>,\n",
       " 'operator': <module 'operator' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/operator.py'>,\n",
       " 're': <module 're' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/re.py'>,\n",
       " 'mimetypes': <module 'mimetypes' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/mimetypes.py'>,\n",
       " 'csv': <module 'csv' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/csv.py'>,\n",
       " 'itertools': <module 'itertools' (built-in)>,\n",
       " 'json': <module 'json' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/json/__init__.py'>,\n",
       " 'shutil': <module 'shutil' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/shutil.py'>,\n",
       " 'glob': <module 'glob' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/glob.py'>,\n",
       " 'pickle': <module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>,\n",
       " 'tarfile': <module 'tarfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tarfile.py'>,\n",
       " 'collections': <module 'collections' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/collections/__init__.py'>,\n",
       " 'hashlib': <module 'hashlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/hashlib.py'>,\n",
       " 'types': <module 'types' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/types.py'>,\n",
       " 'inspect': <module 'inspect' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/inspect.py'>,\n",
       " 'functools': <module 'functools' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/functools.py'>,\n",
       " 'random': <module 'random' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/random.py'>,\n",
       " 'time': <module 'time' (built-in)>,\n",
       " 'math': <module 'math' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so'>,\n",
       " 'bz2': <module 'bz2' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/bz2.py'>,\n",
       " 'typing': <module 'typing' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/typing.py'>,\n",
       " 'numbers': <module 'numbers' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/numbers.py'>,\n",
       " 'string': <module 'string' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/string.py'>,\n",
       " 'threading': <module 'threading' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/threading.py'>,\n",
       " 'urllib': <module 'urllib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/urllib/__init__.py'>,\n",
       " 'tempfile': <module 'tempfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/tempfile.py'>,\n",
       " 'concurrent': <module 'concurrent' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/concurrent/__init__.py'>,\n",
       " 'matplotlib': <module 'matplotlib' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/__init__.py'>,\n",
       " 'warnings': <module 'warnings' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/warnings.py'>,\n",
       " 'zipfile': <module 'zipfile' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/zipfile.py'>,\n",
       " 'as_completed': <function concurrent.futures._base.as_completed(fs, timeout=None)>,\n",
       " 'partial': functools.partial,\n",
       " 'reduce': <function _functools.reduce>,\n",
       " 'starmap': itertools.starmap,\n",
       " 'dropwhile': itertools.dropwhile,\n",
       " 'takewhile': itertools.takewhile,\n",
       " 'zip_longest': itertools.zip_longest,\n",
       " 'copy': <function copy.copy(x)>,\n",
       " 'deepcopy': <function copy.deepcopy(x, memo=None, _nil=[])>,\n",
       " 'Lock': <bound method BaseContext.Lock of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       " 'Process': multiprocessing.context.Process,\n",
       " 'Queue': <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7f34c91df8d0>>,\n",
       " 'queues': <module 'multiprocessing.queues' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/multiprocessing/queues.py'>,\n",
       " 'datetime': datetime.datetime,\n",
       " 'redirect_stdout': contextlib.redirect_stdout,\n",
       " 'contextmanager': <function contextlib.contextmanager(func)>,\n",
       " 'Iterable': typing.Iterable,\n",
       " 'Iterator': typing.Iterator,\n",
       " 'Generator': typing.Generator,\n",
       " 'Sequence': typing.Sequence,\n",
       " 'Union': typing.Union,\n",
       " 'Optional': typing.Optional,\n",
       " 'SimpleNamespace': types.SimpleNamespace,\n",
       " 'Path': pathlib.Path,\n",
       " 'OrderedDict': collections.OrderedDict,\n",
       " 'defaultdict': collections.defaultdict,\n",
       " 'Counter': collections.Counter,\n",
       " 'namedtuple': <function collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)>,\n",
       " 'Enum': <enum 'Enum'>,\n",
       " 'IntEnum': <enum 'IntEnum'>,\n",
       " 'TextWrapper': textwrap.TextWrapper,\n",
       " 'itemgetter': operator.itemgetter,\n",
       " 'attrgetter': operator.attrgetter,\n",
       " 'methodcaller': operator.methodcaller,\n",
       " 'urlopen': <function fastcore.net.urlopen(url, data=None, headers=None, **kwargs)>,\n",
       " 'requests': <module 'requests' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/requests/__init__.py'>,\n",
       " 'yaml': <module 'yaml' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/yaml/__init__.py'>,\n",
       " 'plt': <module 'matplotlib.pyplot' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/matplotlib/pyplot.py'>,\n",
       " 'pd': <module 'pandas' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/pandas/__init__.py'>,\n",
       " 'scipy': <module 'scipy' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/__init__.py'>,\n",
       " 'is_categorical_dtype': <function pandas.core.dtypes.common.is_categorical_dtype(arr_or_dtype) -> 'bool'>,\n",
       " 'is_numeric_dtype': <function pandas.core.dtypes.common.is_numeric_dtype(arr_or_dtype) -> 'bool'>,\n",
       " 'array': <function numpy.array>,\n",
       " 'ndarray': numpy.ndarray,\n",
       " 'ndimage': <module 'scipy.ndimage' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/scipy/ndimage/__init__.py'>,\n",
       " 'set_trace': <function IPython.core.debugger.set_trace(frame=None)>,\n",
       " 'enum': <module 'enum' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/enum.py'>,\n",
       " 'warn': <function _warnings.warn(message, category=None, stacklevel=1, source=None)>,\n",
       " 'WrapperDescriptorType': wrapper_descriptor,\n",
       " 'MethodWrapperType': method-wrapper,\n",
       " 'MethodDescriptorType': method_descriptor,\n",
       " 'BuiltinFunctionType': builtin_function_or_method,\n",
       " 'BuiltinMethodType': builtin_function_or_method,\n",
       " 'MethodType': method,\n",
       " 'FunctionType': function,\n",
       " 'NoneType': NoneType,\n",
       " 'string_classes': (str, bytes),\n",
       " 'is_iter': <function fastai.imports.is_iter(o)>,\n",
       " 'is_coll': <function fastai.imports.is_coll(o)>,\n",
       " 'all_equal': <function fastai.imports.all_equal(a, b)>,\n",
       " 'noop': <function fastai.imports.noop(x=None, *args, **kwargs)>,\n",
       " 'noops': <function fastai.imports.noops(self, x=None, *args, **kwargs)>,\n",
       " 'any_is_instance': <function fastcore.imports.any_is_instance(t, *args)>,\n",
       " 'isinstance_str': <function fastcore.imports.isinstance_str(x, cls_name)>,\n",
       " 'array_equal': <function fastcore.imports.array_equal(a, b)>,\n",
       " 'df_equal': <function fastcore.imports.df_equal(a, b)>,\n",
       " 'equals': <function fastai.imports.equals(a, b)>,\n",
       " 'ipython_shell': <function fastcore.imports.ipython_shell()>,\n",
       " 'in_ipython': <function fastcore.imports.in_ipython()>,\n",
       " 'in_colab': <function fastcore.imports.in_colab()>,\n",
       " 'in_jupyter': <function fastcore.imports.in_jupyter()>,\n",
       " 'in_notebook': <function fastcore.imports.in_notebook()>,\n",
       " 'IN_IPYTHON': True,\n",
       " 'IN_JUPYTER': True,\n",
       " 'IN_COLAB': False,\n",
       " 'IN_NOTEBOOK': True,\n",
       " 'remove_prefix': <function fastcore.imports.remove_prefix(text, prefix)>,\n",
       " 'remove_suffix': <function fastcore.imports.remove_suffix(text, suffix)>,\n",
       " 'working_directory': <function fastcore.foundation.working_directory(path)>,\n",
       " 'add_docs': <function fastcore.foundation.add_docs(cls, cls_doc=None, **docs)>,\n",
       " 'docs': <function fastcore.foundation.docs(cls)>,\n",
       " 'coll_repr': <function fastcore.foundation.coll_repr(c, max_n=10)>,\n",
       " 'is_bool': <function fastcore.foundation.is_bool(x)>,\n",
       " 'mask2idxs': <function fastcore.foundation.mask2idxs(mask)>,\n",
       " 'cycle': <function fastcore.basics.cycle(o)>,\n",
       " 'zip_cycle': <function fastcore.basics.zip_cycle(x, *args)>,\n",
       " 'is_indexer': <function fastcore.foundation.is_indexer(idx)>,\n",
       " 'CollBase': fastcore.foundation.CollBase,\n",
       " 'L': fastcore.foundation.L,\n",
       " 'save_config_file': <function fastcore.foundation.save_config_file(file, d, **kwargs)>,\n",
       " 'read_config_file': <function fastcore.foundation.read_config_file(file, **kwargs)>,\n",
       " 'Config': fastai.data.external.Config,\n",
       " 'lenient_issubclass': <function fastcore.dispatch.lenient_issubclass(cls, types)>,\n",
       " 'sorted_topologically': <function fastcore.dispatch.sorted_topologically(iterable, *, cmp=<built-in function lt>, reverse=False)>,\n",
       " 'TypeDispatch': fastcore.dispatch.TypeDispatch,\n",
       " 'DispatchReg': fastcore.dispatch.DispatchReg,\n",
       " 'typedispatch': <fastcore.dispatch.DispatchReg at 0x7f34c6df11d0>,\n",
       " 'cast': (object,object) -> cast,\n",
       " 'retain_meta': <function fastcore.dispatch.retain_meta(x, res, as_copy=False)>,\n",
       " 'default_set_meta': <function fastcore.dispatch.default_set_meta(self, x, as_copy=False)>,\n",
       " 'retain_type': <function fastcore.dispatch.retain_type(new, old=None, typ=None, as_copy=False)>,\n",
       " 'retain_types': <function fastcore.dispatch.retain_types(new, old=None, typs=None)>,\n",
       " 'explode_types': <function fastcore.dispatch.explode_types(o)>,\n",
       " 'test_fail': <function fastcore.test.test_fail(f, msg='', contains='', args=None, kwargs=None)>,\n",
       " 'test': <function fastcore.test.test(a, b, cmp, cname=None)>,\n",
       " 'nequals': <function fastcore.test.nequals(a, b)>,\n",
       " 'test_eq': <function fastcore.test.test_eq(a, b)>,\n",
       " 'test_eq_type': <function fastcore.test.test_eq_type(a, b)>,\n",
       " 'test_ne': <function fastcore.test.test_ne(a, b)>,\n",
       " 'is_close': <function fastcore.test.is_close(a, b, eps=1e-05)>,\n",
       " 'test_close': <function fastcore.test.test_close(a, b, eps=1e-05)>,\n",
       " 'test_is': <function fastcore.test.test_is(a, b)>,\n",
       " 'test_shuffled': <function fastcore.test.test_shuffled(a, b)>,\n",
       " 'test_stdout': <function fastcore.test.test_stdout(f, exp, regex=False)>,\n",
       " 'test_warns': <function fastcore.test.test_warns(f, show=False)>,\n",
       " 'TEST_IMAGE': 'images/puppy.jpg',\n",
       " 'TEST_IMAGE_BW': 'images/mnist3.png',\n",
       " 'test_fig_exists': <function fastcore.test.test_fig_exists(ax)>,\n",
       " 'ExceptionExpected': fastcore.test.ExceptionExpected,\n",
       " 'exception': <fastcore.test.ExceptionExpected at 0x7f34c0dcc550>,\n",
       " 'defaults': namespace(cpus=4,\n",
       "           use_cuda=None,\n",
       "           activation=torch.nn.modules.activation.ReLU,\n",
       "           callbacks=[fastai.callback.core.TrainEvalCallback,\n",
       "                      fastai.learner.Recorder,\n",
       "                      fastai.callback.progress.ProgressCallback],\n",
       "           lr=0.001),\n",
       " 'ifnone': <function fastcore.basics.ifnone(a, b)>,\n",
       " 'maybe_attr': <function fastcore.basics.maybe_attr(o, attr)>,\n",
       " 'basic_repr': <function fastcore.basics.basic_repr(flds=None)>,\n",
       " 'is_array': <function fastcore.basics.is_array(x)>,\n",
       " 'listify': <function fastcore.basics.listify(o=None, *rest, use_list=False, match=None)>,\n",
       " 'tuplify': <function fastcore.basics.tuplify(o, use_list=False, match=None)>,\n",
       " 'true': <function fastcore.basics.true(*args, **kwargs)>,\n",
       " 'NullType': fastcore.basics.NullType,\n",
       " 'null': <fastcore.basics.NullType at 0x7f34c0e2dbd0>,\n",
       " 'tonull': <function fastcore.basics.tonull(x)>,\n",
       " 'get_class': <function fastcore.basics.get_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       " 'mk_class': <function fastcore.basics.mk_class(nm, *fld_names, sup=None, doc=None, funcs=None, mod=None, **flds)>,\n",
       " 'wrap_class': <function fastcore.basics.wrap_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds)>,\n",
       " 'ignore_exceptions': fastcore.basics.ignore_exceptions,\n",
       " 'exec_local': <function fastcore.basics.exec_local(code, var_name)>,\n",
       " 'risinstance': <function fastcore.basics.risinstance(types, obj=None)>,\n",
       " 'Inf': fastcore.basics.Inf,\n",
       " 'in_': <function fastcore.basics.in_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'lt': <function fastcore.basics.lt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'gt': <function fastcore.basics.gt(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'le': <function fastcore.basics.le(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'ge': <function fastcore.basics.ge(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'eq': <function fastcore.basics.eq(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'ne': <function fastcore.basics.ne(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'add': <function fastcore.basics.add(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'sub': <function fastcore.basics.sub(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'mul': <function fastcore.basics.mul(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'truediv': <function fastcore.basics.truediv(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'is_': <function fastcore.basics.is_(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'is_not': <function fastcore.basics.is_not(a, b=<object object at 0x7f34c27172e0>)>,\n",
       " 'stop': <function fastcore.basics.stop(e=<class 'StopIteration'>)>,\n",
       " 'gen': <function fastcore.basics.gen(func, seq, cond=<function true at 0x7f34c0e30e60>)>,\n",
       " 'chunked': <function fastcore.basics.chunked(it, chunk_sz=None, drop_last=False, n_chunks=None)>,\n",
       " 'otherwise': <function fastcore.basics.otherwise(x, tst, y)>,\n",
       " 'custom_dir': <function fastcore.basics.custom_dir(c, add)>,\n",
       " 'AttrDict': fastcore.basics.AttrDict,\n",
       " 'type_hints': <function fastcore.basics.type_hints(f)>,\n",
       " 'annotations': <function fastcore.basics.annotations(o)>,\n",
       " 'anno_ret': <function fastcore.basics.anno_ret(func)>,\n",
       " 'argnames': <function fastcore.basics.argnames(f, frame=False)>,\n",
       " 'with_cast': <function fastcore.basics.with_cast(f)>,\n",
       " 'store_attr': <function fastcore.basics.store_attr(names=None, self=None, but='', cast=False, store_args=None, **attrs)>,\n",
       " 'attrdict': <function fastcore.basics.attrdict(o, *ks, default=None)>,\n",
       " 'properties': <function fastcore.basics.properties(cls, *ps)>,\n",
       " 'camel2words': <function fastcore.basics.camel2words(s, space=' ')>,\n",
       " 'camel2snake': <function fastcore.basics.camel2snake(name)>,\n",
       " 'snake2camel': <function fastcore.basics.snake2camel(s)>,\n",
       " 'class2attr': <function fastcore.basics.class2attr(self, cls_name)>,\n",
       " 'getattrs': <function fastcore.basics.getattrs(o, *attrs, default=None)>,\n",
       " 'hasattrs': <function fastcore.basics.hasattrs(o, attrs)>,\n",
       " 'setattrs': <function fastcore.basics.setattrs(dest, flds, src)>,\n",
       " 'try_attrs': <function fastcore.basics.try_attrs(obj, *attrs)>,\n",
       " 'GetAttrBase': fastcore.basics.GetAttrBase,\n",
       " 'GetAttr': fastcore.basics.GetAttr,\n",
       " 'delegate_attr': <function fastcore.basics.delegate_attr(self, k, to)>,\n",
       " 'ShowPrint': fastcore.basics.ShowPrint,\n",
       " 'Int': fastcore.basics.Int,\n",
       " 'Str': fastcore.basics.Str,\n",
       " 'Float': fastcore.basics.Float,\n",
       " 'concat': <function fastai.torch_core.concat(*ls)>,\n",
       " 'strcat': <function fastcore.basics.strcat(its, sep: str = '') -> str>,\n",
       " 'detuplify': <function fastcore.basics.detuplify(x)>,\n",
       " 'replicate': <function fastcore.basics.replicate(item, match)>,\n",
       " 'setify': <function fastcore.basics.setify(o)>,\n",
       " 'merge': <function fastcore.basics.merge(*ds)>,\n",
       " 'range_of': <function fastcore.basics.range_of(a, b=None, step=None)>,\n",
       " 'groupby': <function fastcore.basics.groupby(x, key, val=<function noop at 0x7f34c0dfed40>)>,\n",
       " 'last_index': <function fastcore.basics.last_index(x, o)>,\n",
       " 'filter_dict': <function fastcore.basics.filter_dict(d, func)>,\n",
       " 'filter_keys': <function fastcore.basics.filter_keys(d, func)>,\n",
       " 'filter_values': <function fastcore.basics.filter_values(d, func)>,\n",
       " 'sorted_ex': <function fastcore.basics.sorted_ex(iterable, key=None, reverse=False)>,\n",
       " 'not_': <function fastcore.basics.not_(f)>,\n",
       " 'argwhere': <function fastcore.basics.argwhere(iterable, f, negate=False, **kwargs)>,\n",
       " 'filter_ex': <function fastcore.basics.filter_ex(iterable, f=<function noop at 0x7f34c0dfed40>, negate=False, gen=False, **kwargs)>,\n",
       " 'renumerate': <function fastcore.basics.renumerate(iterable, start=0)>,\n",
       " 'first': <function fastcore.basics.first(x, f=None, negate=False, **kwargs)>,\n",
       " 'nested_attr': <function fastcore.basics.nested_attr(o, attr, default=None)>,\n",
       " 'nested_idx': <function fastcore.basics.nested_idx(coll, *idxs)>,\n",
       " 'val2idx': <function fastcore.basics.val2idx(x)>,\n",
       " 'uniqueify': <function fastcore.basics.uniqueify(x, sort=False, bidir=False, start=None)>,\n",
       " 'num_methods': ['__add__',\n",
       "  '__sub__',\n",
       "  '__mul__',\n",
       "  '__matmul__',\n",
       "  '__truediv__',\n",
       "  '__floordiv__',\n",
       "  '__mod__',\n",
       "  '__divmod__',\n",
       "  '__pow__',\n",
       "  '__lshift__',\n",
       "  '__rshift__',\n",
       "  '__and__',\n",
       "  '__xor__',\n",
       "  '__or__',\n",
       "  '__neg__',\n",
       "  '__pos__',\n",
       "  '__abs__'],\n",
       " 'rnum_methods': ['__radd__',\n",
       "  '__rsub__',\n",
       "  '__rmul__',\n",
       "  '__rmatmul__',\n",
       "  '__rtruediv__',\n",
       "  '__rfloordiv__',\n",
       "  '__rmod__',\n",
       "  '__rdivmod__',\n",
       "  '__rpow__',\n",
       "  '__rlshift__',\n",
       "  '__rrshift__',\n",
       "  '__rand__',\n",
       "  '__rxor__',\n",
       "  '__ror__'],\n",
       " 'inum_methods': ['__iadd__',\n",
       "  '__isub__',\n",
       "  '__imul__',\n",
       "  '__imatmul__',\n",
       "  '__itruediv__',\n",
       "  '__ifloordiv__',\n",
       "  '__imod__',\n",
       "  '__ipow__',\n",
       "  '__ilshift__',\n",
       "  '__irshift__',\n",
       "  '__iand__',\n",
       "  '__ixor__',\n",
       "  '__ior__'],\n",
       " 'fastuple': fastcore.basics.fastuple,\n",
       " 'arg0': <fastcore.basics._Arg at 0x7f34c0dbc410>,\n",
       " 'arg1': <fastcore.basics._Arg at 0x7f34c0dbc450>,\n",
       " 'arg2': <fastcore.basics._Arg at 0x7f34c0dbc490>,\n",
       " 'arg3': <fastcore.basics._Arg at 0x7f34c0dbc4d0>,\n",
       " 'arg4': <fastcore.basics._Arg at 0x7f34c0dbc510>,\n",
       " 'bind': fastcore.basics.bind,\n",
       " 'mapt': <function fastcore.basics.mapt(func, *iterables)>,\n",
       " 'map_ex': <function fastcore.basics.map_ex(iterable, f, *args, gen=False, **kwargs)>,\n",
       " 'compose': <function fastcore.basics.compose(*funcs, order=None)>,\n",
       " 'maps': <function fastcore.basics.maps(*args, retain=<function noop at 0x7f34c0dfed40>)>,\n",
       " 'partialler': <function fastcore.basics.partialler(f, *args, order=None, **kwargs)>,\n",
       " 'instantiate': <function fastcore.basics.instantiate(t)>,\n",
       " 'using_attr': <function fastcore.basics.using_attr(f, attr)>,\n",
       " 'Self': <fastcore.basics._SelfCls at 0x7f34c0dbc5d0>,\n",
       " 'copy_func': <function fastcore.basics.copy_func(f)>,\n",
       " 'patch_to': <function fastcore.basics.patch_to(cls, as_prop=False, cls_method=False)>,\n",
       " 'patch': <function fastcore.basics.patch(f=None, *, as_prop=False, cls_method=False)>,\n",
       " 'patch_property': <function fastcore.basics.patch_property(f)>,\n",
       " 'ImportEnum': <enum 'ImportEnum'>,\n",
       " 'StrEnum': <enum 'StrEnum'>,\n",
       " 'str_enum': <function fastcore.basics.str_enum(name, *vals)>,\n",
       " 'Stateful': fastcore.basics.Stateful,\n",
       " 'PrettyString': fastcore.basics.PrettyString,\n",
       " 'even_mults': <function fastcore.basics.even_mults(start, stop, n)>,\n",
       " 'num_cpus': <function fastcore.basics.num_cpus()>,\n",
       " 'add_props': <function fastcore.basics.add_props(f, g=None, n=2)>,\n",
       " 'typed': <function fastcore.basics.typed(f)>,\n",
       " 'dict2obj': <function fastcore.xtras.dict2obj(d)>,\n",
       " 'obj2dict': <function fastcore.xtras.obj2dict(d)>,\n",
       " 'repr_dict': <function fastcore.xtras.repr_dict(d)>,\n",
       " 'is_listy': <function fastcore.xtras.is_listy(x)>,\n",
       " 'shufflish': <function fastcore.xtras.shufflish(x, pct=0.04)>,\n",
       " 'mapped': <function fastcore.xtras.mapped(f, it)>,\n",
       " 'IterLen': fastcore.xtras.IterLen,\n",
       " 'ReindexCollection': fastcore.xtras.ReindexCollection,\n",
       " 'maybe_open': <function fastcore.xtras.maybe_open(f, mode='r', **kwargs)>,\n",
       " 'image_size': <function fastcore.xtras.image_size(fn)>,\n",
       " 'bunzip': <function fastcore.xtras.bunzip(fn)>,\n",
       " 'join_path_file': <function fastcore.xtras.join_path_file(file, path, ext='')>,\n",
       " 'loads': <function fastcore.xtras.loads(s, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)>,\n",
       " 'loads_multi': <function fastcore.xtras.loads_multi(s: str)>,\n",
       " 'untar_dir': <function fastcore.xtras.untar_dir(file, dest)>,\n",
       " 'repo_details': <function fastcore.xtras.repo_details(url)>,\n",
       " 'run': <function fastcore.xtras.run(cmd, *rest, same_in_win=False, ignore_ex=False, as_bytes=False, stderr=False)>,\n",
       " 'open_file': <function fastcore.xtras.open_file(fn, mode='r', **kwargs)>,\n",
       " 'save_pickle': <function fastcore.xtras.save_pickle(fn, o)>,\n",
       " 'load_pickle': <function fastcore.xtras.load_pickle(fn)>,\n",
       " 'truncstr': <function fastcore.xtras.truncstr(s: str, maxlen: int, suf: str = '…', space='') -> str>,\n",
       " 'spark_chars': '▁▂▃▅▆▇',\n",
       " 'sparkline': <function fastcore.xtras.sparkline(data, mn=None, mx=None, empty_zero=False)>,\n",
       " 'autostart': <function fastcore.xtras.autostart(g)>,\n",
       " 'EventTimer': fastcore.xtras.EventTimer,\n",
       " 'stringfmt_names': <function fastcore.xtras.stringfmt_names(s: str) -> list>,\n",
       " 'PartialFormatter': fastcore.xtras.PartialFormatter,\n",
       " 'partial_format': <function fastcore.xtras.partial_format(s: str, **kwargs)>,\n",
       " 'utc2local': <function fastcore.xtras.utc2local(dt: datetime.datetime) -> datetime.datetime>,\n",
       " 'local2utc': <function fastcore.xtras.local2utc(dt: datetime.datetime) -> datetime.datetime>,\n",
       " 'trace': <function fastcore.xtras.trace(f)>,\n",
       " 'round_multiple': <function fastcore.xtras.round_multiple(x, mult, round_down=False)>,\n",
       " 'modified_env': <function fastcore.xtras.modified_env(*delete, **replace)>,\n",
       " 'ContextManagers': fastcore.xtras.ContextManagers,\n",
       " 'str2bool': <function fastcore.xtras.str2bool(s)>,\n",
       " 'sort_by_run': <function fastcore.xtras.sort_by_run(fs)>,\n",
       " 'threaded': <function fastcore.parallel.threaded(f)>,\n",
       " 'startthread': <function fastcore.parallel.startthread(f)>,\n",
       " 'set_num_threads': <function fastcore.parallel.set_num_threads(nt)>,\n",
       " 'parallelable': <function fastcore.parallel.parallelable(param_name, num_workers, f=None)>,\n",
       " 'ThreadPoolExecutor': fastcore.parallel.ThreadPoolExecutor,\n",
       " 'ProcessPoolExecutor': fastcore.parallel.ProcessPoolExecutor,\n",
       " 'parallel': <function fastcore.parallel.parallel(f, items, *args, n_workers=4, total=None, progress=None, pause=0, threadpool=False, timeout=None, chunksize=1, **kwargs)>,\n",
       " 'add_one': <function fastcore.parallel.add_one(x, a=1)>,\n",
       " 'run_procs': <function fastcore.parallel.run_procs(f, f_done, args)>,\n",
       " 'parallel_gen': <function fastcore.parallel.parallel_gen(cls, items, n_workers=4, **kwargs)>,\n",
       " 'url_default_headers': {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
       "  'Accept-Language': 'en-US,en;q=0.9',\n",
       "  'Cache-Control': 'max-age=0',\n",
       "  'Sec-Fetch-Dest': 'document',\n",
       "  'Sec-Fetch-Mode': 'navigate',\n",
       "  'Sec-Fetch-Site': 'none',\n",
       "  'Sec-Fetch-User': '?1',\n",
       "  'Upgrade-Insecure-Requests': '1',\n",
       "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'},\n",
       " 'urlquote': <function fastcore.net.urlquote(url)>,\n",
       " 'urlwrap': <function fastcore.net.urlwrap(url, data=None, headers=None)>,\n",
       " 'ExceptionsHTTP': {400: fastcore.basics.HTTP400BadRequestError,\n",
       "  401: fastcore.basics.HTTP401UnauthorizedError,\n",
       "  402: fastcore.basics.HTTP402PaymentRequiredError,\n",
       "  403: fastcore.basics.HTTP403ForbiddenError,\n",
       "  404: fastcore.basics.HTTP404NotFoundError,\n",
       "  405: fastcore.basics.HTTP405MethodNotAllowedError,\n",
       "  406: fastcore.basics.HTTP406NotAcceptableError,\n",
       "  407: fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       "  408: fastcore.basics.HTTP408RequestTimeoutError,\n",
       "  409: fastcore.basics.HTTP409ConflictError,\n",
       "  410: fastcore.basics.HTTP410GoneError,\n",
       "  411: fastcore.basics.HTTP411LengthRequiredError,\n",
       "  412: fastcore.basics.HTTP412PreconditionFailedError,\n",
       "  413: fastcore.basics.HTTP413PayloadTooLargeError,\n",
       "  414: fastcore.basics.HTTP414URITooLongError,\n",
       "  415: fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       "  416: fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       "  417: fastcore.basics.HTTP417ExpectationFailedError,\n",
       "  418: fastcore.basics.HTTP418AmAteapotError,\n",
       "  421: fastcore.basics.HTTP421MisdirectedRequestError,\n",
       "  422: fastcore.basics.HTTP422UnprocessableEntityError,\n",
       "  423: fastcore.basics.HTTP423LockedError,\n",
       "  424: fastcore.basics.HTTP424FailedDependencyError,\n",
       "  425: fastcore.basics.HTTP425TooEarlyError,\n",
       "  426: fastcore.basics.HTTP426UpgradeRequiredError,\n",
       "  428: fastcore.basics.HTTP428PreconditionRequiredError,\n",
       "  429: fastcore.basics.HTTP429TooManyRequestsError,\n",
       "  431: fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       "  451: fastcore.basics.HTTP451LegalReasonsError},\n",
       " 'HTTP4xxClientError': fastcore.net.HTTP4xxClientError,\n",
       " 'HTTP5xxServerError': fastcore.net.HTTP5xxServerError,\n",
       " 'HTTP400BadRequestError': fastcore.basics.HTTP400BadRequestError,\n",
       " 'HTTP401UnauthorizedError': fastcore.basics.HTTP401UnauthorizedError,\n",
       " 'HTTP402PaymentRequiredError': fastcore.basics.HTTP402PaymentRequiredError,\n",
       " 'HTTP403ForbiddenError': fastcore.basics.HTTP403ForbiddenError,\n",
       " 'HTTP404NotFoundError': fastcore.basics.HTTP404NotFoundError,\n",
       " 'HTTP405MethodNotAllowedError': fastcore.basics.HTTP405MethodNotAllowedError,\n",
       " 'HTTP406NotAcceptableError': fastcore.basics.HTTP406NotAcceptableError,\n",
       " 'HTTP407ProxyAuthRequiredError': fastcore.basics.HTTP407ProxyAuthRequiredError,\n",
       " 'HTTP408RequestTimeoutError': fastcore.basics.HTTP408RequestTimeoutError,\n",
       " 'HTTP409ConflictError': fastcore.basics.HTTP409ConflictError,\n",
       " 'HTTP410GoneError': fastcore.basics.HTTP410GoneError,\n",
       " 'HTTP411LengthRequiredError': fastcore.basics.HTTP411LengthRequiredError,\n",
       " 'HTTP412PreconditionFailedError': fastcore.basics.HTTP412PreconditionFailedError,\n",
       " 'HTTP413PayloadTooLargeError': fastcore.basics.HTTP413PayloadTooLargeError,\n",
       " 'HTTP414URITooLongError': fastcore.basics.HTTP414URITooLongError,\n",
       " 'HTTP415UnsupportedMediaTypeError': fastcore.basics.HTTP415UnsupportedMediaTypeError,\n",
       " 'HTTP416RangeNotSatisfiableError': fastcore.basics.HTTP416RangeNotSatisfiableError,\n",
       " 'HTTP417ExpectationFailedError': fastcore.basics.HTTP417ExpectationFailedError,\n",
       " 'HTTP418AmAteapotError': fastcore.basics.HTTP418AmAteapotError,\n",
       " 'HTTP421MisdirectedRequestError': fastcore.basics.HTTP421MisdirectedRequestError,\n",
       " 'HTTP422UnprocessableEntityError': fastcore.basics.HTTP422UnprocessableEntityError,\n",
       " 'HTTP423LockedError': fastcore.basics.HTTP423LockedError,\n",
       " 'HTTP424FailedDependencyError': fastcore.basics.HTTP424FailedDependencyError,\n",
       " 'HTTP425TooEarlyError': fastcore.basics.HTTP425TooEarlyError,\n",
       " 'HTTP426UpgradeRequiredError': fastcore.basics.HTTP426UpgradeRequiredError,\n",
       " 'HTTP428PreconditionRequiredError': fastcore.basics.HTTP428PreconditionRequiredError,\n",
       " 'HTTP429TooManyRequestsError': fastcore.basics.HTTP429TooManyRequestsError,\n",
       " 'HTTP431HeaderFieldsTooLargeError': fastcore.basics.HTTP431HeaderFieldsTooLargeError,\n",
       " 'HTTP451LegalReasonsError': fastcore.basics.HTTP451LegalReasonsError,\n",
       " 'urlread': <function fastcore.net.urlread(url, data=None, headers=None, decode=True, return_json=False, return_headers=False, **kwargs)>,\n",
       " 'urljson': <function fastcore.net.urljson(url, data=None)>,\n",
       " 'urlcheck': <function fastcore.net.urlcheck(url, timeout=10)>,\n",
       " 'urlclean': <function fastcore.net.urlclean(url)>,\n",
       " 'urlsave': <function fastcore.net.urlsave(url, dest=None)>,\n",
       " 'urlvalid': <function fastcore.net.urlvalid(x)>,\n",
       " 'urlrequest': <function fastcore.net.urlrequest(url, verb, headers=None, route=None, query=None, data=None, json_data=True)>,\n",
       " 'urlsend': <function fastcore.net.urlsend(url, verb, headers=None, route=None, query=None, data=None, json_data=True, return_json=True, return_headers=False, debug=None)>,\n",
       " 'do_request': <function fastcore.net.do_request(url, post=False, headers=None, **data)>,\n",
       " 'start_server': <function fastcore.net.start_server(port, host=None, dgram=False, reuse_addr=True, n_queue=None)>,\n",
       " 'start_client': <function fastcore.net.start_client(port, host=None, dgram=False)>,\n",
       " 'Transform': fastcore.transform.Transform,\n",
       " 'InplaceTransform': fastcore.transform.InplaceTransform,\n",
       " 'DisplayedTransform': fastcore.transform.DisplayedTransform,\n",
       " 'ItemTransform': fastcore.transform.ItemTransform,\n",
       " 'get_func': <function fastcore.transform.get_func(t, name, *args, **kwargs)>,\n",
       " 'Func': fastcore.transform.Func,\n",
       " 'Sig': <fastcore.transform._Sig at 0x7f34c0d37590>,\n",
       " 'compose_tfms': <function fastcore.transform.compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs)>,\n",
       " 'mk_transform': <function fastcore.transform.mk_transform(f)>,\n",
       " 'gather_attrs': <function fastcore.transform.gather_attrs(o, k, nm)>,\n",
       " 'gather_attr_names': <function fastcore.transform.gather_attr_names(o, nm)>,\n",
       " 'Pipeline': fastcore.transform.Pipeline,\n",
       " 'test_sig': <function fastcore.meta.test_sig(f, b)>,\n",
       " 'FixSigMeta': fastcore.meta.FixSigMeta,\n",
       " 'PrePostInitMeta': fastcore.meta.PrePostInitMeta,\n",
       " 'AutoInit': fastcore.meta.AutoInit,\n",
       " 'NewChkMeta': fastcore.meta.NewChkMeta,\n",
       " 'BypassNewMeta': fastcore.meta.BypassNewMeta,\n",
       " 'empty2none': <function fastcore.meta.empty2none(p)>,\n",
       " 'anno_dict': <function fastcore.meta.anno_dict(f)>,\n",
       " 'use_kwargs_dict': <function fastcore.meta.use_kwargs_dict(keep=False, **kwargs)>,\n",
       " 'use_kwargs': <function fastcore.meta.use_kwargs(names, keep=False)>,\n",
       " 'delegates': <function fastcore.meta.delegates(to=None, keep=False, but=None)>,\n",
       " 'method': <function fastcore.meta.method(f)>,\n",
       " 'funcs_kwargs': <function fastcore.meta.funcs_kwargs(as_method=False)>,\n",
       " 'store_true': <function fastcore.script.store_true()>,\n",
       " 'store_false': <function fastcore.script.store_false()>,\n",
       " 'bool_arg': <function fastcore.script.bool_arg(v)>,\n",
       " 'clean_type_str': <function fastcore.script.clean_type_str(x: str)>,\n",
       " 'Param': fastcore.script.Param,\n",
       " 'anno_parser': <function fastcore.script.anno_parser(func, prog=None, from_name=False)>,\n",
       " 'args_from_prog': <function fastcore.script.args_from_prog(func, prog)>,\n",
       " 'SCRIPT_INFO': namespace(func=None),\n",
       " 'call_parse': <function fastcore.script.call_parse(func)>,\n",
       " 'progress_bar': fastprogress.fastprogress.NBProgressBar,\n",
       " 'master_bar': fastprogress.fastprogress.NBMasterBar,\n",
       " 'LambdaType': function,\n",
       " 'one_is_instance': <function fastai.imports.one_is_instance(a, b, t)>,\n",
       " 'pv': <function fastai.imports.pv(text, verbose)>,\n",
       " 'torch': <module 'torch' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/__init__.py'>,\n",
       " 'as_tensor': <function _VariableFunctionsClass.as_tensor>,\n",
       " 'Tensor': torch.Tensor,\n",
       " 'ByteTensor': torch.ByteTensor,\n",
       " 'LongTensor': torch.LongTensor,\n",
       " 'FloatTensor': torch.FloatTensor,\n",
       " 'HalfTensor': torch.HalfTensor,\n",
       " 'DoubleTensor': torch.DoubleTensor,\n",
       " 'nn': <module 'torch.nn' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/__init__.py'>,\n",
       " 'F': <module 'torch.nn.functional' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torch/nn/functional.py'>,\n",
       " 'SequentialSampler': torch.utils.data.sampler.SequentialSampler,\n",
       " 'RandomSampler': torch.utils.data.sampler.RandomSampler,\n",
       " 'Sampler': torch.utils.data.sampler.Sampler,\n",
       " 'BatchSampler': torch.utils.data.sampler.BatchSampler,\n",
       " 'IterableDataset': torch.utils.data.dataset.IterableDataset,\n",
       " 'get_worker_info': <function torch.utils.data._utils.worker.get_worker_info()>,\n",
       " 'default_collate': <function torch.utils.data._utils.collate.default_collate(batch)>,\n",
       " 'default_convert': <function torch.utils.data._utils.collate.default_convert(data)>,\n",
       " 'subplots': <function fastai.torch_core.subplots(nrows=1, ncols=1, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **kwargs)>,\n",
       " 'show_image': <function fastai.torch_core.show_image(im, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       " 'show_titled_image': <function fastai.torch_core.show_titled_image(o, ax=None, figsize=None, title=None, ctx=None, cmap=None, norm=None, *, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None, **kwargs)>,\n",
       " 'show_images': <function fastai.torch_core.show_images(ims, nrows=1, ncols=None, titles=None, figsize=None, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       " 'ArrayBase': fastai.torch_core.ArrayBase,\n",
       " 'ArrayImageBase': fastai.torch_core.ArrayImageBase,\n",
       " 'ArrayImage': fastai.torch_core.ArrayImage,\n",
       " 'ArrayImageBW': fastai.torch_core.ArrayImageBW,\n",
       " 'ArrayMask': fastai.torch_core.ArrayMask,\n",
       " 'tensor': <function fastai.torch_core.tensor(x, *rest, dtype=None, device=None, requires_grad=False, pin_memory=False)>,\n",
       " 'set_seed': <function fastai.torch_core.set_seed(s, reproducible=False)>,\n",
       " 'get_random_states': <function fastai.torch_core.get_random_states()>,\n",
       " 'set_random_states': <function fastai.torch_core.set_random_states(random_state, numpy_state, torch_state, torch_cuda_state, torch_deterministic, torch_benchmark)>,\n",
       " 'no_random': <function fastai.torch_core.no_random(seed=42, reproducible=True)>,\n",
       " 'unsqueeze': <function fastai.torch_core.unsqueeze(x, dim=-1, n=1)>,\n",
       " 'unsqueeze_': <function fastai.torch_core.unsqueeze_(x, dim=-1, n=1)>,\n",
       " 'apply': <function fastai.torch_core.apply(func, x, *args, **kwargs)>,\n",
       " 'maybe_gather': <function fastai.torch_core.maybe_gather(x, axis=0)>,\n",
       " 'to_detach': <function fastai.torch_core.to_detach(b, cpu=True, gather=True)>,\n",
       " 'to_half': <function fastai.torch_core.to_half(b)>,\n",
       " 'to_float': <function fastai.torch_core.to_float(b)>,\n",
       " 'default_device': <function fastai.torch_core.default_device(use_cuda=-1)>,\n",
       " 'to_device': <function fastai.torch_core.to_device(b, device=None, non_blocking=False)>,\n",
       " 'to_cpu': <function fastai.torch_core.to_cpu(b)>,\n",
       " 'to_np': <function fastai.torch_core.to_np(x)>,\n",
       " 'to_concat': <function fastai.torch_core.to_concat(xs, dim=0)>,\n",
       " 'TensorBase': fastai.torch_core.TensorBase,\n",
       " 'TensorImageBase': fastai.torch_core.TensorImageBase,\n",
       " 'TensorImage': fastai.torch_core.TensorImage,\n",
       " 'TensorImageBW': fastai.torch_core.TensorImageBW,\n",
       " 'TensorMask': fastai.torch_core.TensorMask,\n",
       " 'TensorFlowField': fastai.torch_core.TensorFlowField,\n",
       " 'TensorCategory': fastai.torch_core.TensorCategory,\n",
       " 'TensorMultiCategory': fastai.torch_core.TensorMultiCategory,\n",
       " 'TitledTensorScalar': fastai.torch_core.TitledTensorScalar,\n",
       " 'Chunks': fastai.torch_core.Chunks,\n",
       " 'show_title': <function fastai.torch_core.show_title(o, ax=None, ctx=None, label=None, color='black', **kwargs)>,\n",
       " 'ShowTitle': fastai.torch_core.ShowTitle,\n",
       " 'TitledInt': fastai.torch_core.TitledInt,\n",
       " 'TitledFloat': fastai.torch_core.TitledFloat,\n",
       " 'TitledStr': fastai.torch_core.TitledStr,\n",
       " 'TitledTuple': fastai.torch_core.TitledTuple,\n",
       " 'get_empty_df': <function fastai.torch_core.get_empty_df(n)>,\n",
       " 'display_df': <function fastai.torch_core.display_df(df)>,\n",
       " 'get_first': <function fastai.torch_core.get_first(c)>,\n",
       " 'one_param': <function fastai.torch_core.one_param(m)>,\n",
       " 'item_find': <function fastai.torch_core.item_find(x, idx=0)>,\n",
       " 'find_device': <function fastai.torch_core.find_device(b)>,\n",
       " 'find_bs': <function fastai.torch_core.find_bs(b)>,\n",
       " 'np_func': <function fastai.torch_core.np_func(f)>,\n",
       " 'Module': fastai.torch_core.Module,\n",
       " 'get_model': <function fastai.torch_core.get_model(model)>,\n",
       " 'one_hot': <function fastai.torch_core.one_hot(x, c)>,\n",
       " 'one_hot_decode': <function fastai.torch_core.one_hot_decode(x, vocab=None)>,\n",
       " 'params': <function fastai.torch_core.params(m)>,\n",
       " 'trainable_params': <function fastai.torch_core.trainable_params(m)>,\n",
       " 'norm_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm3d,\n",
       "  torch.nn.modules.instancenorm.InstanceNorm1d,\n",
       "  torch.nn.modules.instancenorm.InstanceNorm2d,\n",
       "  torch.nn.modules.instancenorm.InstanceNorm3d,\n",
       "  torch.nn.modules.normalization.LayerNorm),\n",
       " 'norm_bias_params': <function fastai.torch_core.norm_bias_params(m, with_bias=True)>,\n",
       " 'batch_to_samples': <function fastai.torch_core.batch_to_samples(b, max_n=10)>,\n",
       " 'logit': <function fastai.torch_core.logit(x)>,\n",
       " 'num_distrib': <function fastai.torch_core.num_distrib()>,\n",
       " 'rank_distrib': <function fastai.torch_core.rank_distrib()>,\n",
       " 'distrib_barrier': <function fastai.torch_core.distrib_barrier()>,\n",
       " 'base_doc': <function fastai.torch_core.base_doc(elt)>,\n",
       " 'doc': <function fastai.torch_core.doc(elt)>,\n",
       " 'nested_reorder': <function fastai.torch_core.nested_reorder(t, idxs)>,\n",
       " 'make_cross_image': <function fastai.torch_core.make_cross_image(bw=True)>,\n",
       " 'show_image_batch': <function fastai.torch_core.show_image_batch(b, show=<function show_titled_image at 0x7f34c0cf3170>, items=9, cols=3, figsize=None, **kwargs)>,\n",
       " 'requires_grad': <function fastai.torch_core.requires_grad(m)>,\n",
       " 'init_default': <function fastai.layers.init_default(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       " 'cond_init': <function fastai.torch_core.cond_init(m, func)>,\n",
       " 'apply_leaf': <function fastai.torch_core.apply_leaf(m, f)>,\n",
       " 'apply_init': <function fastai.torch_core.apply_init(m, func=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       " 'script_use_ctx': <function fastai.torch_core.script_use_ctx(f)>,\n",
       " 'script_save_ctx': <function fastai.torch_core.script_save_ctx(static, *argidx)>,\n",
       " 'script_fwd': <function fastai.torch_core.script_fwd(*argidx)>,\n",
       " 'script_bwd': <function fastai.torch_core.script_bwd(f)>,\n",
       " 'grad_module': <function fastai.torch_core.grad_module(cls)>,\n",
       " 'flatten_check': <function fastai.torch_core.flatten_check(inp, targ)>,\n",
       " 'module': <function fastai.layers.module(*flds, **defaults)>,\n",
       " 'Identity': fastai.layers.Identity,\n",
       " 'Lambda': fastai.layers.Lambda,\n",
       " 'PartialLambda': fastai.layers.PartialLambda,\n",
       " 'Flatten': fastai.layers.Flatten,\n",
       " 'View': fastai.layers.View,\n",
       " 'ResizeBatch': fastai.layers.ResizeBatch,\n",
       " 'Debugger': fastai.layers.Debugger,\n",
       " 'sigmoid_range': <function fastai.layers.sigmoid_range(x, low, high)>,\n",
       " 'SigmoidRange': fastai.layers.SigmoidRange,\n",
       " 'AdaptiveConcatPool1d': fastai.layers.AdaptiveConcatPool1d,\n",
       " 'AdaptiveConcatPool2d': fastai.layers.AdaptiveConcatPool2d,\n",
       " 'PoolType': fastai.layers.PoolType,\n",
       " 'adaptive_pool': <function fastai.layers.adaptive_pool(pool_type)>,\n",
       " 'PoolFlatten': fastai.layers.PoolFlatten,\n",
       " 'NormType': <enum 'NormType'>,\n",
       " 'BatchNorm': <function fastai.layers.BatchNorm(nf, ndim=2, norm_type=<NormType.Batch: 1>, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)>,\n",
       " 'InstanceNorm': <function fastai.layers.InstanceNorm(nf, ndim=2, norm_type=<NormType.Instance: 5>, affine=True, eps: float = 1e-05, momentum: float = 0.1, track_running_stats: bool = False)>,\n",
       " 'BatchNorm1dFlat': fastai.layers.BatchNorm1dFlat,\n",
       " 'LinBnDrop': fastai.layers.LinBnDrop,\n",
       " 'sigmoid': <function fastai.layers.sigmoid(input, eps=1e-07)>,\n",
       " 'sigmoid_': <function fastai.layers.sigmoid_(input, eps=1e-07)>,\n",
       " 'vleaky_relu': <function fastai.layers.vleaky_relu(input, inplace=True)>,\n",
       " 'init_linear': <function fastai.layers.init_linear(m, act_func=None, init='auto', bias_std=0.01)>,\n",
       " 'ConvLayer': fastai.layers.ConvLayer,\n",
       " 'AdaptiveAvgPool': <function fastai.layers.AdaptiveAvgPool(sz=1, ndim=2)>,\n",
       " 'MaxPool': <function fastai.layers.MaxPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       " 'AvgPool': <function fastai.layers.AvgPool(ks=2, stride=None, padding=0, ndim=2, ceil_mode=False)>,\n",
       " 'trunc_normal_': <function fastai.layers.trunc_normal_(x, mean=0.0, std=1.0)>,\n",
       " 'Embedding': fastai.layers.Embedding,\n",
       " 'SelfAttention': fastai.layers.SelfAttention,\n",
       " 'PooledSelfAttention2d': fastai.layers.PooledSelfAttention2d,\n",
       " 'SimpleSelfAttention': fastai.layers.SimpleSelfAttention,\n",
       " 'icnr_init': <function fastai.layers.icnr_init(x, scale=2, init=<function kaiming_normal_ at 0x7f34c94c9710>)>,\n",
       " 'PixelShuffle_ICNR': fastai.layers.PixelShuffle_ICNR,\n",
       " 'sequential': <function fastai.layers.sequential(*args)>,\n",
       " 'SequentialEx': fastai.layers.SequentialEx,\n",
       " 'MergeLayer': fastai.layers.MergeLayer,\n",
       " 'Cat': fastai.layers.Cat,\n",
       " 'SimpleCNN': fastai.layers.SimpleCNN,\n",
       " 'ProdLayer': fastai.layers.ProdLayer,\n",
       " 'inplace_relu': functools.partial(<class 'torch.nn.modules.activation.ReLU'>, inplace=True),\n",
       " 'SEModule': <function fastai.layers.SEModule(ch, reduction, act_cls=<class 'torch.nn.modules.activation.ReLU'>)>,\n",
       " 'ResBlock': fastai.layers.ResBlock,\n",
       " 'SEBlock': <function fastai.layers.SEBlock(expansion, ni, nf, groups=1, reduction=16, stride=1, **kwargs)>,\n",
       " 'SEResNeXtBlock': <function fastai.layers.SEResNeXtBlock(expansion, ni, nf, groups=32, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       " 'SeparableBlock': <function fastai.layers.SeparableBlock(expansion, ni, nf, reduction=16, stride=1, base_width=4, **kwargs)>,\n",
       " 'TimeDistributed': fastai.layers.TimeDistributed,\n",
       " 'swish': <function fastai.layers.swish(x, inplace=False)>,\n",
       " 'Swish': fastai.layers.Swish,\n",
       " 'MishJitAutoFn': fastai.layers.MishJitAutoFn,\n",
       " 'mish': <function fastai.layers.mish(x)>,\n",
       " 'Mish': fastai.layers.Mish,\n",
       " 'ParameterModule': fastai.layers.ParameterModule,\n",
       " 'children_and_parameters': <function fastai.layers.children_and_parameters(m)>,\n",
       " 'has_children': <function fastai.layers.has_children(m)>,\n",
       " 'flatten_model': <function fastai.layers.flatten_model(m)>,\n",
       " 'NoneReduce': fastai.layers.NoneReduce,\n",
       " 'in_channels': <function fastai.layers.in_channels(m)>,\n",
       " 'BaseLoss': fastai.losses.BaseLoss,\n",
       " 'CrossEntropyLossFlat': fastai.losses.CrossEntropyLossFlat,\n",
       " 'FocalLossFlat': fastai.losses.FocalLossFlat,\n",
       " 'BCEWithLogitsLossFlat': fastai.losses.BCEWithLogitsLossFlat,\n",
       " 'BCELossFlat': <function fastai.losses.BCELossFlat(*args, axis=-1, floatify=True, weight=None, reduction='mean')>,\n",
       " 'MSELossFlat': <function fastai.losses.MSELossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       " 'L1LossFlat': <function fastai.losses.L1LossFlat(*args, axis=-1, floatify=True, reduction='mean')>,\n",
       " 'LabelSmoothingCrossEntropy': fastai.losses.LabelSmoothingCrossEntropy,\n",
       " 'LabelSmoothingCrossEntropyFlat': fastai.losses.LabelSmoothingCrossEntropyFlat,\n",
       " 'show_batch': (TensorImage,TensorImage) -> show_batch\n",
       " (TensorImage,object) -> show_batch\n",
       " (AudioTensor,object) -> show_batch\n",
       " (AudioSpectrogram,object) -> show_batch\n",
       " (object,object) -> show_batch,\n",
       " 'show_results': (TensorImage,TensorCategory) -> show_results\n",
       " (TensorImage,TensorMask) -> show_results\n",
       " (TensorImage,TensorBBox) -> show_results\n",
       " (TensorImage,TensorPoint) -> show_results\n",
       " (TensorImage,TensorImage) -> show_results\n",
       " (TensorImage,object) -> show_results\n",
       " (object,object) -> show_results,\n",
       " 'TfmdDL': fastai.data.core.TfmdDL,\n",
       " 'DataLoaders': fastai.data.core.DataLoaders,\n",
       " 'FilteredBase': fastai.data.core.FilteredBase,\n",
       " 'TfmdLists': fastai.data.core.TfmdLists,\n",
       " 'decode_at': <function fastai.data.core.decode_at(o, idx)>,\n",
       " 'show_at': <function fastai.data.core.show_at(o, idx, **kwargs)>,\n",
       " 'Datasets': fastai.data.core.Datasets,\n",
       " 'test_set': <function fastai.data.core.test_set(dsets, test_items, rm_tfms=None, with_labels=False)>,\n",
       " 'fa_collate': <function fastai.data.load.fa_collate(t)>,\n",
       " 'fa_convert': <function fastai.data.load.fa_convert(t)>,\n",
       " 'SkipItemException': fastai.data.load.SkipItemException,\n",
       " 'DataLoader': fastai.data.load.DataLoader,\n",
       " 'URLs': fastai.data.external.URLs,\n",
       " 'download_url': <function fastai.data.external.download_url(url, dest, overwrite=False, pbar=None, show_progress=True, chunk_size=1048576, timeout=4, retries=5)>,\n",
       " 'download_data': <function fastai.data.external.download_data(url, fname=None, c_key='archive', force_download=False, timeout=4)>,\n",
       " 'file_extract': <function fastai.data.external.file_extract(fname, dest=None)>,\n",
       " 'newest_folder': <function fastai.data.external.newest_folder(path)>,\n",
       " 'rename_extracted': <function fastai.data.external.rename_extracted(dest)>,\n",
       " 'untar_data': <function fastai.data.external.untar_data(url, fname=None, dest=None, c_key='data', force_download=False, extract_func=<function file_extract at 0x7f34bf3bec20>, timeout=4)>,\n",
       " 'get_files': <function fastai.data.transforms.get_files(path, extensions=None, recurse=True, folders=None, followlinks=True)>,\n",
       " 'FileGetter': <function fastai.data.transforms.FileGetter(suf='', extensions=None, recurse=True, folders=None)>,\n",
       " 'image_extensions': {'.art',\n",
       "  '.bmp',\n",
       "  '.cdr',\n",
       "  '.cdt',\n",
       "  '.cpt',\n",
       "  '.cr2',\n",
       "  '.crw',\n",
       "  '.djv',\n",
       "  '.djvu',\n",
       "  '.erf',\n",
       "  '.gif',\n",
       "  '.ico',\n",
       "  '.ief',\n",
       "  '.jng',\n",
       "  '.jp2',\n",
       "  '.jpe',\n",
       "  '.jpeg',\n",
       "  '.jpf',\n",
       "  '.jpg',\n",
       "  '.jpg2',\n",
       "  '.jpm',\n",
       "  '.jpx',\n",
       "  '.nef',\n",
       "  '.orf',\n",
       "  '.pat',\n",
       "  '.pbm',\n",
       "  '.pcx',\n",
       "  '.pgm',\n",
       "  '.png',\n",
       "  '.pnm',\n",
       "  '.ppm',\n",
       "  '.psd',\n",
       "  '.ras',\n",
       "  '.rgb',\n",
       "  '.svg',\n",
       "  '.svgz',\n",
       "  '.tif',\n",
       "  '.tiff',\n",
       "  '.wbmp',\n",
       "  '.xbm',\n",
       "  '.xpm',\n",
       "  '.xwd'},\n",
       " 'get_image_files': <function fastai.data.transforms.get_image_files(path, recurse=True, folders=None)>,\n",
       " 'ImageGetter': <function fastai.data.transforms.ImageGetter(suf='', recurse=True, folders=None)>,\n",
       " 'get_text_files': <function fastai.data.transforms.get_text_files(path, recurse=True, folders=None)>,\n",
       " 'ItemGetter': fastai.data.transforms.ItemGetter,\n",
       " 'AttrGetter': fastai.data.transforms.AttrGetter,\n",
       " 'RandomSplitter': <function fastai.data.transforms.RandomSplitter(valid_pct=0.2, seed=None)>,\n",
       " 'TrainTestSplitter': <function fastai.data.transforms.TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, train_size=None, shuffle=True)>,\n",
       " 'IndexSplitter': <function fastai.data.transforms.IndexSplitter(valid_idx)>,\n",
       " 'GrandparentSplitter': <function fastai.data.transforms.GrandparentSplitter(train_name='train', valid_name='valid')>,\n",
       " 'FuncSplitter': <function fastai.data.transforms.FuncSplitter(func)>,\n",
       " 'MaskSplitter': <function fastai.data.transforms.MaskSplitter(mask)>,\n",
       " 'FileSplitter': <function fastai.data.transforms.FileSplitter(fname)>,\n",
       " 'ColSplitter': <function fastai.data.transforms.ColSplitter(col='is_valid')>,\n",
       " 'RandomSubsetSplitter': <function fastai.data.transforms.RandomSubsetSplitter(train_sz, valid_sz, seed=None)>,\n",
       " 'parent_label': <function fastai.data.transforms.parent_label(o)>,\n",
       " 'RegexLabeller': fastai.data.transforms.RegexLabeller,\n",
       " 'ColReader': fastai.data.transforms.ColReader,\n",
       " 'CategoryMap': fastai.data.transforms.CategoryMap,\n",
       " 'Categorize': fastai.data.transforms.Categorize,\n",
       " 'Category': fastai.data.transforms.Category,\n",
       " 'MultiCategorize': fastai.data.transforms.MultiCategorize,\n",
       " 'MultiCategory': fastai.data.transforms.MultiCategory,\n",
       " 'OneHotEncode': fastai.data.transforms.OneHotEncode,\n",
       " 'EncodedMultiCategorize': fastai.data.transforms.EncodedMultiCategorize,\n",
       " 'RegressionSetup': fastai.data.transforms.RegressionSetup,\n",
       " 'get_c': <function fastai.data.transforms.get_c(dls)>,\n",
       " 'ToTensor': fastai.data.transforms.ToTensor,\n",
       " 'IntToFloatTensor': fastai.data.transforms.IntToFloatTensor,\n",
       " 'broadcast_vec': <function fastai.data.transforms.broadcast_vec(dim, ndim, *t, cuda=True)>,\n",
       " 'Normalize': fastai.data.transforms.Normalize,\n",
       " 'TransformBlock': fastai.data.block.TransformBlock,\n",
       " 'CategoryBlock': <function fastai.data.block.CategoryBlock(vocab=None, sort=True, add_na=False)>,\n",
       " 'MultiCategoryBlock': <function fastai.data.block.MultiCategoryBlock(encoded=False, vocab=None, add_na=False)>,\n",
       " 'RegressionBlock': <function fastai.data.block.RegressionBlock(n_out=None)>,\n",
       " 'DataBlock': fastai.data.block.DataBlock,\n",
       " 'Optimizer': fastai.optimizer.Optimizer,\n",
       " 'sgd_step': <function fastai.optimizer.sgd_step(p, lr, **kwargs)>,\n",
       " 'weight_decay': <function fastai.optimizer.weight_decay(p, lr, wd, do_wd=True, **kwargs)>,\n",
       " 'l2_reg': <function fastai.optimizer.l2_reg(p, lr, wd, do_wd=True, **kwargs)>,\n",
       " 'average_grad': <function fastai.optimizer.average_grad(p, mom, dampening=False, grad_avg=None, **kwargs)>,\n",
       " 'average_sqr_grad': <function fastai.optimizer.average_sqr_grad(p, sqr_mom, dampening=True, sqr_avg=None, **kwargs)>,\n",
       " 'momentum_step': <function fastai.optimizer.momentum_step(p, lr, grad_avg, **kwargs)>,\n",
       " 'SGD': <function fastai.optimizer.SGD(params, lr, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       " 'rms_prop_step': <function fastai.optimizer.rms_prop_step(p, lr, sqr_avg, eps, grad_avg=None, **kwargs)>,\n",
       " 'RMSProp': <function fastai.optimizer.RMSProp(params, lr, sqr_mom=0.99, mom=0.0, wd=0.0, decouple_wd=True)>,\n",
       " 'step_stat': <function fastai.optimizer.step_stat(p, step=0, **kwargs)>,\n",
       " 'debias': <function fastai.optimizer.debias(mom, damp, step)>,\n",
       " 'adam_step': <function fastai.optimizer.adam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       " 'Adam': <function fastai.optimizer.Adam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.01, decouple_wd=True)>,\n",
       " 'radam_step': <function fastai.optimizer.radam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, beta, **kwargs)>,\n",
       " 'RAdam': <function fastai.optimizer.RAdam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, beta=0.0, decouple_wd=True)>,\n",
       " 'qhadam_step': <function fastai.optimizer.qhadam_step(p, lr, mom, sqr_mom, sqr_avg, nu_1, nu_2, step, grad_avg, eps, **kwargs)>,\n",
       " 'QHAdam': <function fastai.optimizer.QHAdam(params, lr, mom=0.999, sqr_mom=0.999, nu_1=0.7, nu_2=1.0, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       " 'larc_layer_lr': <function fastai.optimizer.larc_layer_lr(p, lr, trust_coeff, wd, eps, clip=True, **kwargs)>,\n",
       " 'larc_step': <function fastai.optimizer.larc_step(p, local_lr, grad_avg=None, **kwargs)>,\n",
       " 'Larc': <function fastai.optimizer.Larc(params, lr, mom=0.9, clip=True, trust_coeff=0.02, eps=1e-08, wd=0.0, decouple_wd=True)>,\n",
       " 'lamb_step': <function fastai.optimizer.lamb_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs)>,\n",
       " 'Lamb': <function fastai.optimizer.Lamb(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-05, wd=0.0, decouple_wd=True)>,\n",
       " 'Lookahead': fastai.optimizer.Lookahead,\n",
       " 'ranger': <function fastai.optimizer.ranger(p, lr, mom=0.95, wd=0.01, eps=1e-06, sqr_mom=0.99, beta=0.0, decouple_wd=True)>,\n",
       " 'detuplify_pg': <function fastai.optimizer.detuplify_pg(d)>,\n",
       " 'set_item_pg': <function fastai.optimizer.set_item_pg(pg, k, v)>,\n",
       " 'pytorch_hp_map': {'momentum': 'mom',\n",
       "  'weight_decay': 'wd',\n",
       "  'alpha': 'sqr_mom',\n",
       "  'betas__0': 'mom',\n",
       "  'betas__1': 'sqr_mom'},\n",
       " 'OptimWrapper': fastai.optimizer.OptimWrapper,\n",
       " 'CancelStepException': fastcore.basics.CancelStepException,\n",
       " 'CancelFitException': fastcore.basics.CancelFitException,\n",
       " 'CancelEpochException': fastcore.basics.CancelEpochException,\n",
       " 'CancelTrainException': fastcore.basics.CancelTrainException,\n",
       " 'CancelValidException': fastcore.basics.CancelValidException,\n",
       " 'CancelBatchException': fastcore.basics.CancelBatchException,\n",
       " 'event': fastcore.basics.event,\n",
       " 'Callback': fastai.callback.core.Callback,\n",
       " 'TrainEvalCallback': fastai.callback.core.TrainEvalCallback,\n",
       " 'GatherPredsCallback': fastai.callback.core.GatherPredsCallback,\n",
       " 'FetchPredsCallback': fastai.callback.core.FetchPredsCallback,\n",
       " 'replacing_yield': <function fastai.learner.replacing_yield(o, attr, val)>,\n",
       " 'mk_metric': <function fastai.learner.mk_metric(m)>,\n",
       " 'save_model': <function fastai.learner.save_model(file, model, opt, with_opt=True, pickle_protocol=2)>,\n",
       " 'load_model': <function fastai.learner.load_model(file, model, opt, with_opt=True, device=None, strict=True)>,\n",
       " 'Learner': fastai.learner.Learner,\n",
       " 'before_batch_cb': <function fastai.learner.before_batch_cb(f)>,\n",
       " 'load_learner': <function fastai.learner.load_learner(fname, cpu=True, pickle_module=<module 'pickle' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/pickle.py'>)>,\n",
       " 'to_detach_from_dl': <function fastai.learner.to_detach_from_dl(learn: (<class 'fastai.learner.Learner'>, <class 'NoneType'>), b: object, cpu: bool = True, gather: bool = True)>,\n",
       " 'Metric': fastai.learner.Metric,\n",
       " 'AvgMetric': fastai.learner.AvgMetric,\n",
       " 'AvgLoss': fastai.learner.AvgLoss,\n",
       " 'AvgSmoothLoss': fastai.learner.AvgSmoothLoss,\n",
       " 'ValueMetric': fastai.learner.ValueMetric,\n",
       " 'Recorder': fastai.learner.Recorder,\n",
       " 'AccumMetric': fastai.metrics.AccumMetric,\n",
       " 'skm_to_fastai': <function fastai.metrics.skm_to_fastai(func, is_class=True, thresh=None, axis=-1, activation=None, **kwargs)>,\n",
       " 'optim_metric': <function fastai.metrics.optim_metric(f, argname, bounds, tol=0.01, do_neg=True, get_x=False)>,\n",
       " 'accuracy': <function fastai.metrics.accuracy(inp, targ, axis=-1)>,\n",
       " 'error_rate': <function fastai.metrics.error_rate(inp, targ, axis=-1)>,\n",
       " 'top_k_accuracy': <function fastai.metrics.top_k_accuracy(inp, targ, k=5, axis=-1)>,\n",
       " 'APScoreBinary': <function fastai.metrics.APScoreBinary(axis=-1, average='macro', pos_label=1, sample_weight=None)>,\n",
       " 'BalancedAccuracy': <function fastai.metrics.BalancedAccuracy(axis=-1, sample_weight=None, adjusted=False)>,\n",
       " 'BrierScore': <function fastai.metrics.BrierScore(axis=-1, sample_weight=None, pos_label=None)>,\n",
       " 'CohenKappa': <function fastai.metrics.CohenKappa(axis=-1, labels=None, weights=None, sample_weight=None)>,\n",
       " 'F1Score': <function fastai.metrics.F1Score(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'FBeta': <function fastai.metrics.FBeta(beta, axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'HammingLoss': <function fastai.metrics.HammingLoss(axis=-1, sample_weight=None)>,\n",
       " 'Jaccard': <function fastai.metrics.Jaccard(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'Precision': <function fastai.metrics.Precision(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'Recall': <function fastai.metrics.Recall(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None)>,\n",
       " 'RocAuc': <function fastai.metrics.RocAuc(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='ovr')>,\n",
       " 'RocAucBinary': <function fastai.metrics.RocAucBinary(axis=-1, average='macro', sample_weight=None, max_fpr=None, multi_class='raise')>,\n",
       " 'MatthewsCorrCoef': <function fastai.metrics.MatthewsCorrCoef(sample_weight=None, **kwargs)>,\n",
       " 'Perplexity': fastai.metrics.Perplexity,\n",
       " 'perplexity': <fastai.metrics.Perplexity at 0x7f34b7101810>,\n",
       " 'accuracy_multi': <function fastai.metrics.accuracy_multi(inp, targ, thresh=0.5, sigmoid=True)>,\n",
       " 'APScoreMulti': <function fastai.metrics.APScoreMulti(sigmoid=True, average='macro', pos_label=1, sample_weight=None)>,\n",
       " 'BrierScoreMulti': <function fastai.metrics.BrierScoreMulti(thresh=0.5, sigmoid=True, sample_weight=None, pos_label=None)>,\n",
       " 'F1ScoreMulti': <function fastai.metrics.F1ScoreMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'FBetaMulti': <function fastai.metrics.FBetaMulti(beta, thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'HammingLossMulti': <function fastai.metrics.HammingLossMulti(thresh=0.5, sigmoid=True, labels=None, sample_weight=None)>,\n",
       " 'JaccardMulti': <function fastai.metrics.JaccardMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'MatthewsCorrCoefMulti': <function fastai.metrics.MatthewsCorrCoefMulti(thresh=0.5, sigmoid=True, sample_weight=None)>,\n",
       " 'PrecisionMulti': <function fastai.metrics.PrecisionMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'RecallMulti': <function fastai.metrics.RecallMulti(thresh=0.5, sigmoid=True, labels=None, pos_label=1, average='macro', sample_weight=None)>,\n",
       " 'RocAucMulti': <function fastai.metrics.RocAucMulti(sigmoid=True, average='macro', sample_weight=None, max_fpr=None)>,\n",
       " 'mse': <function fastai.metrics.mse(inp, targ)>,\n",
       " 'rmse': <fastai.metrics.AccumMetric at 0x7f34b7101850>,\n",
       " 'mae': <function fastai.metrics.mae(inp, targ)>,\n",
       " 'msle': <function fastai.metrics.msle(inp, targ)>,\n",
       " 'exp_rmspe': <fastai.metrics.AccumMetric at 0x7f34b71018d0>,\n",
       " 'ExplainedVariance': <function fastai.metrics.ExplainedVariance(sample_weight=None)>,\n",
       " 'R2Score': <function fastai.metrics.R2Score(sample_weight=None)>,\n",
       " 'PearsonCorrCoef': <function fastai.metrics.PearsonCorrCoef(dim_argmax=None, activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       " 'SpearmanCorrCoef': <function fastai.metrics.SpearmanCorrCoef(dim_argmax=None, axis=0, nan_policy='propagate', activation='no', thresh=None, to_np=False, invert_arg=False, flatten=True)>,\n",
       " 'foreground_acc': <function fastai.metrics.foreground_acc(inp, targ, bkg_idx=0, axis=1)>,\n",
       " 'Dice': fastai.metrics.Dice,\n",
       " 'DiceMulti': fastai.metrics.DiceMulti,\n",
       " 'JaccardCoeff': fastai.metrics.JaccardCoeff,\n",
       " 'CorpusBLEUMetric': fastai.metrics.CorpusBLEUMetric,\n",
       " 'LossMetric': fastai.metrics.LossMetric,\n",
       " 'LossMetrics': <function fastai.metrics.LossMetrics(attrs, nms=None)>,\n",
       " 'plot_top_losses': (TensorImage,TensorMultiCategory) -> plot_top_losses\n",
       " (TensorImage,TensorCategory) -> plot_top_losses\n",
       " (TensorImage,TensorMask) -> plot_top_losses\n",
       " (object,object) -> plot_top_losses,\n",
       " 'Interpretation': fastai.interpret.Interpretation,\n",
       " 'ClassificationInterpretation': fastai.interpret.ClassificationInterpretation,\n",
       " 'SegmentationInterpretation': fastai.interpret.SegmentationInterpretation,\n",
       " 'CollectDataCallback': fastai.callback.data.CollectDataCallback,\n",
       " 'WeightedDL': fastai.callback.data.WeightedDL,\n",
       " 'PartialDL': fastai.callback.data.PartialDL,\n",
       " 'MixedPrecision': fastai.callback.fp16.MixedPrecision,\n",
       " 'FP16TestCallback': fastai.callback.fp16.FP16TestCallback,\n",
       " 'get_master': <function fastai.callback.fp16.get_master(opt, flat_master=False)>,\n",
       " 'to_master_grads': <function fastai.callback.fp16.to_master_grads(model_pgs, master_pgs, flat_master=False)>,\n",
       " 'to_model_params': <function fastai.callback.fp16.to_model_params(model_pgs, master_pgs, flat_master=False) -> None>,\n",
       " 'test_overflow': <function fastai.callback.fp16.test_overflow(x)>,\n",
       " 'grad_overflow': <function fastai.callback.fp16.grad_overflow(pgs)>,\n",
       " 'copy_clone': <function fastai.callback.fp16.copy_clone(d)>,\n",
       " 'ModelToHalf': fastai.callback.fp16.ModelToHalf,\n",
       " 'NonNativeMixedPrecision': fastai.callback.fp16.NonNativeMixedPrecision,\n",
       " 'Hook': fastai.callback.hook.Hook,\n",
       " 'hook_output': <function fastai.callback.hook.hook_output(module, detach=True, cpu=False, grad=False)>,\n",
       " 'Hooks': fastai.callback.hook.Hooks,\n",
       " 'hook_outputs': <function fastai.callback.hook.hook_outputs(modules, detach=True, cpu=False, grad=False)>,\n",
       " 'dummy_eval': <function fastai.callback.hook.dummy_eval(m, size=(64, 64))>,\n",
       " 'model_sizes': <function fastai.callback.hook.model_sizes(m, size=(64, 64))>,\n",
       " 'num_features_model': <function fastai.callback.hook.num_features_model(m)>,\n",
       " 'has_params': <function fastai.callback.hook.has_params(m)>,\n",
       " 'HookCallback': fastai.callback.hook.HookCallback,\n",
       " 'total_params': <function fastai.callback.hook.total_params(m)>,\n",
       " 'layer_info': <function fastai.callback.hook.layer_info(learn, *xb)>,\n",
       " 'module_summary': <function fastai.callback.hook.module_summary(learn, *xb)>,\n",
       " 'ActivationStats': fastai.callback.hook.ActivationStats,\n",
       " 'reduce_loss': <function fastai.callback.mixup.reduce_loss(loss, reduction='mean')>,\n",
       " 'MixHandler': fastai.callback.mixup.MixHandler,\n",
       " 'MixUp': fastai.callback.mixup.MixUp,\n",
       " 'CutMix': fastai.callback.mixup.CutMix,\n",
       " 'ProgressCallback': fastai.callback.progress.ProgressCallback,\n",
       " 'ShowGraphCallback': fastai.callback.progress.ShowGraphCallback,\n",
       " 'CSVLogger': fastai.callback.progress.CSVLogger,\n",
       " 'annealer': <function fastai.callback.schedule.annealer(f)>,\n",
       " 'sched_lin': <function fastai.callback.schedule.sched_lin(start, end, pos)>,\n",
       " 'sched_cos': <function fastai.callback.schedule.sched_cos(start, end, pos)>,\n",
       " 'sched_no': <function fastai.callback.schedule.sched_no(start, end, pos)>,\n",
       " 'sched_exp': <function fastai.callback.schedule.sched_exp(start, end, pos)>,\n",
       " 'SchedLin': <function fastai.callback.schedule.SchedLin(start, end)>,\n",
       " 'SchedCos': <function fastai.callback.schedule.SchedCos(start, end)>,\n",
       " 'SchedNo': <function fastai.callback.schedule.SchedNo(start, end)>,\n",
       " 'SchedExp': <function fastai.callback.schedule.SchedExp(start, end)>,\n",
       " 'SchedPoly': <function fastai.callback.schedule.SchedPoly(start, end, power)>,\n",
       " 'combine_scheds': <function fastai.callback.schedule.combine_scheds(pcts, scheds)>,\n",
       " 'combined_cos': <function fastai.callback.schedule.combined_cos(pct, start, middle, end)>,\n",
       " 'ParamScheduler': fastai.callback.schedule.ParamScheduler,\n",
       " 'LRFinder': fastai.callback.schedule.LRFinder,\n",
       " 'SuggestedLRs': fastai.callback.schedule.SuggestedLRs,\n",
       " 'TerminateOnNaNCallback': fastai.callback.tracker.TerminateOnNaNCallback,\n",
       " 'TrackerCallback': fastai.callback.tracker.TrackerCallback,\n",
       " 'EarlyStoppingCallback': fastai.callback.tracker.EarlyStoppingCallback,\n",
       " 'SaveModelCallback': fastai.callback.tracker.SaveModelCallback,\n",
       " 'ReduceLROnPlateau': fastai.callback.tracker.ReduceLROnPlateau,\n",
       " 'ModelResetter': fastai.callback.rnn.ModelResetter,\n",
       " 'RNNCallback': fastai.callback.rnn.RNNCallback,\n",
       " 'RNNRegularizer': fastai.callback.rnn.RNNRegularizer,\n",
       " 'rnn_cbs': <function fastai.callback.rnn.rnn_cbs(alpha=0.0, beta=0.0)>,\n",
       " 'ShortEpochCallback': fastai.callback.training.ShortEpochCallback,\n",
       " 'GradientAccumulation': fastai.callback.training.GradientAccumulation,\n",
       " 'GradientClip': fastai.callback.training.GradientClip,\n",
       " 'set_bn_eval': <function fastai.callback.training.set_bn_eval(m: torch.nn.modules.module.Module, use_eval=True) -> None>,\n",
       " 'BnFreeze': fastai.callback.training.BnFreeze,\n",
       " 'bn_types': (torch.nn.modules.batchnorm.BatchNorm1d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm2d,\n",
       "  torch.nn.modules.batchnorm.BatchNorm3d),\n",
       " 'MCDropoutCallback': fastai.callback.preds.MCDropoutCallback,\n",
       " 'RandTransform': fastai.vision.augment.RandTransform,\n",
       " 'TensorTypes': (fastai.torch_core.TensorImage,\n",
       "  fastai.torch_core.TensorMask,\n",
       "  fastai.vision.core.TensorPoint,\n",
       "  fastai.vision.core.TensorBBox),\n",
       " 'FlipItem': fastai.vision.augment.FlipItem,\n",
       " 'DihedralItem': fastai.vision.augment.DihedralItem,\n",
       " 'PadMode': fastcore.basics.PadMode,\n",
       " 'CropPad': fastai.vision.augment.CropPad,\n",
       " 'RandomCrop': fastai.vision.augment.RandomCrop,\n",
       " 'OldRandomCrop': fastai.vision.augment.OldRandomCrop,\n",
       " 'ResizeMethod': fastcore.basics.ResizeMethod,\n",
       " 'Resize': fastai.vision.augment.Resize,\n",
       " 'RandomResizedCrop': fastai.vision.augment.RandomResizedCrop,\n",
       " 'RatioResize': fastai.vision.augment.RatioResize,\n",
       " 'affine_grid': <function fastai.vision.augment.affine_grid(theta, size, align_corners=None)>,\n",
       " 'AffineCoordTfm': fastai.vision.augment.AffineCoordTfm,\n",
       " 'RandomResizedCropGPU': fastai.vision.augment.RandomResizedCropGPU,\n",
       " 'mask_tensor': <function fastai.vision.augment.mask_tensor(x, p=0.5, neutral=0.0, batch=False)>,\n",
       " 'affine_mat': <function fastai.vision.augment.affine_mat(*ms)>,\n",
       " 'flip_mat': <function fastai.vision.augment.flip_mat(x, p=0.5, draw=None, batch=False)>,\n",
       " 'Flip': fastai.vision.augment.Flip,\n",
       " 'DeterministicDraw': fastai.vision.augment.DeterministicDraw,\n",
       " 'DeterministicFlip': fastai.vision.augment.DeterministicFlip,\n",
       " 'dihedral_mat': <function fastai.vision.augment.dihedral_mat(x, p=0.5, draw=None, batch=False)>,\n",
       " 'Dihedral': fastai.vision.augment.Dihedral,\n",
       " 'DeterministicDihedral': fastai.vision.augment.DeterministicDihedral,\n",
       " 'rotate_mat': <function fastai.vision.augment.rotate_mat(x, max_deg=10, p=0.5, draw=None, batch=False)>,\n",
       " 'Rotate': fastai.vision.augment.Rotate,\n",
       " 'zoom_mat': <function fastai.vision.augment.zoom_mat(x, min_zoom=1.0, max_zoom=1.1, p=0.5, draw=None, draw_x=None, draw_y=None, batch=False)>,\n",
       " 'Zoom': fastai.vision.augment.Zoom,\n",
       " 'find_coeffs': <function fastai.vision.augment.find_coeffs(p1, p2)>,\n",
       " 'apply_perspective': <function fastai.vision.augment.apply_perspective(coords, coeffs)>,\n",
       " 'Warp': fastai.vision.augment.Warp,\n",
       " 'SpaceTfm': fastai.vision.augment.SpaceTfm,\n",
       " 'LightingTfm': fastai.vision.augment.LightingTfm,\n",
       " 'Brightness': fastai.vision.augment.Brightness,\n",
       " 'Contrast': fastai.vision.augment.Contrast,\n",
       " 'grayscale': <function fastai.vision.augment.grayscale(x)>,\n",
       " 'Saturation': fastai.vision.augment.Saturation,\n",
       " 'rgb2hsv': <function fastai.vision.augment.rgb2hsv(img)>,\n",
       " 'hsv2rgb': <function fastai.vision.augment.hsv2rgb(img)>,\n",
       " 'HSVTfm': fastai.vision.augment.HSVTfm,\n",
       " 'Hue': fastai.vision.augment.Hue,\n",
       " 'cutout_gaussian': <function fastai.vision.augment.cutout_gaussian(x, areas)>,\n",
       " 'norm_apply_denorm': <function fastai.vision.augment.norm_apply_denorm(x, f, nrm)>,\n",
       " 'RandomErasing': fastai.vision.augment.RandomErasing,\n",
       " 'setup_aug_tfms': <function fastai.vision.augment.setup_aug_tfms(tfms)>,\n",
       " 'aug_transforms': <function fastai.vision.augment.aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=None, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0)>,\n",
       " 'Image': <module 'PIL.Image' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/PIL/Image.py'>,\n",
       " 'imagenet_stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
       " 'cifar_stats': ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261]),\n",
       " 'mnist_stats': ([0.131], [0.308]),\n",
       " 'n_px': None,\n",
       " 'shape': None,\n",
       " 'aspect': None,\n",
       " 'to_image': <function fastai.vision.core.to_image(x)>,\n",
       " 'load_image': <function fastai.vision.core.load_image(fn, mode=None)>,\n",
       " 'image2tensor': <function fastai.vision.core.image2tensor(img)>,\n",
       " 'PILBase': fastai.vision.core.PILBase,\n",
       " 'PILImage': fastai.vision.core.PILImage,\n",
       " 'PILImageBW': fastai.vision.core.PILImageBW,\n",
       " 'PILMask': fastai.vision.core.PILMask,\n",
       " 'OpenMask': PILBase.create:\n",
       " encodes: (Path,object) -> create\n",
       " (str,object) -> create\n",
       " (Tensor,object) -> create\n",
       " (ndarray,object) -> create\n",
       " (bytes,object) -> createdecodes: ,\n",
       " 'AddMaskCodes': fastai.vision.core.AddMaskCodes,\n",
       " 'TensorPoint': fastai.vision.core.TensorPoint,\n",
       " 'TensorPointCreate': TensorPoint.create:\n",
       " encodes: (object,object) -> createdecodes: ,\n",
       " 'get_annotations': <function fastai.vision.core.get_annotations(fname, prefix=None)>,\n",
       " 'TensorBBox': fastai.vision.core.TensorBBox,\n",
       " 'LabeledBBox': fastai.vision.core.LabeledBBox,\n",
       " 'encodes': <function fastai.vision.core.encodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       " 'PointScaler': fastai.vision.core.PointScaler,\n",
       " 'BBoxLabeler': fastai.vision.core.BBoxLabeler,\n",
       " 'decodes': <function fastai.vision.core.decodes(self, x: fastai.vision.core.TensorBBox)>,\n",
       " 'get_grid': <function fastai.vision.data.get_grid(n, nrows=None, ncols=None, add_vert=0, figsize=None, double=False, title=None, return_fig=False, flatten=True, imsize=3, suptitle=None, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None)>,\n",
       " 'clip_remove_empty': <function fastai.vision.data.clip_remove_empty(bbox, label)>,\n",
       " 'bb_pad': <function fastai.vision.data.bb_pad(samples, pad_idx=0)>,\n",
       " 'ImageBlock': <function fastai.vision.data.ImageBlock(cls=<class 'fastai.vision.core.PILImage'>)>,\n",
       " 'MaskBlock': <function fastai.vision.data.MaskBlock(codes=None)>,\n",
       " 'PointBlock': <fastai.data.block.TransformBlock at 0x7f34b7020410>,\n",
       " 'BBoxBlock': <fastai.data.block.TransformBlock at 0x7f34b7093850>,\n",
       " 'BBoxLblBlock': <function fastai.vision.data.BBoxLblBlock(vocab=None, add_na=True)>,\n",
       " 'ImageDataLoaders': fastai.vision.data.ImageDataLoaders,\n",
       " 'SegmentationDataLoaders': fastai.vision.data.SegmentationDataLoaders,\n",
       " 'init_cnn': <function fastai.vision.models.xresnet.init_cnn(m)>,\n",
       " 'XResNet': fastai.vision.models.xresnet.XResNet,\n",
       " 'xresnet18': <function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>,\n",
       " 'xresnet34': <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>,\n",
       " 'xresnet50': <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>,\n",
       " 'xresnet101': <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>,\n",
       " 'xresnet152': <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>,\n",
       " 'xresnet18_deep': <function fastai.vision.models.xresnet.xresnet18_deep(pretrained=False, **kwargs)>,\n",
       " 'xresnet34_deep': <function fastai.vision.models.xresnet.xresnet34_deep(pretrained=False, **kwargs)>,\n",
       " 'xresnet50_deep': <function fastai.vision.models.xresnet.xresnet50_deep(pretrained=False, **kwargs)>,\n",
       " 'xresnet18_deeper': <function fastai.vision.models.xresnet.xresnet18_deeper(pretrained=False, **kwargs)>,\n",
       " 'xresnet34_deeper': <function fastai.vision.models.xresnet.xresnet34_deeper(pretrained=False, **kwargs)>,\n",
       " 'xresnet50_deeper': <function fastai.vision.models.xresnet.xresnet50_deeper(pretrained=False, **kwargs)>,\n",
       " 'se_kwargs1': {'groups': 1, 'reduction': 16},\n",
       " 'se_kwargs2': {'groups': 32, 'reduction': 16},\n",
       " 'se_kwargs3': {'groups': 32, 'reduction': 0},\n",
       " 'g0': [2, 2, 2, 2],\n",
       " 'g1': [3, 4, 6, 3],\n",
       " 'g2': [3, 4, 23, 3],\n",
       " 'g3': [3, 8, 36, 3],\n",
       " 'xse_resnet18': <function fastai.vision.models.xresnet.xse_resnet18(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext18': <function fastai.vision.models.xresnet.xse_resnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext18': <function fastai.vision.models.xresnet.xresnext18(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet34': <function fastai.vision.models.xresnet.xse_resnet34(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext34': <function fastai.vision.models.xresnet.xse_resnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext34': <function fastai.vision.models.xresnet.xresnext34(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet50': <function fastai.vision.models.xresnet.xse_resnet50(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext50': <function fastai.vision.models.xresnet.xse_resnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext50': <function fastai.vision.models.xresnet.xresnext50(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet101': <function fastai.vision.models.xresnet.xse_resnet101(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext101': <function fastai.vision.models.xresnet.xse_resnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xresnext101': <function fastai.vision.models.xresnet.xresnext101(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnet152': <function fastai.vision.models.xresnet.xse_resnet152(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xsenet154': <function fastai.vision.models.xresnet.xsenet154(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext18_deep': <function fastai.vision.models.xresnet.xse_resnext18_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext34_deep': <function fastai.vision.models.xresnet.xse_resnext34_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext50_deep': <function fastai.vision.models.xresnet.xse_resnext50_deep(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext18_deeper': <function fastai.vision.models.xresnet.xse_resnext18_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext34_deeper': <function fastai.vision.models.xresnet.xse_resnext34_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'xse_resnext50_deeper': <function fastai.vision.models.xresnet.xse_resnext50_deeper(n_out=1000, pretrained=False, **kwargs)>,\n",
       " 'UnetBlock': fastai.vision.models.unet.UnetBlock,\n",
       " 'ResizeToOrig': fastai.vision.models.unet.ResizeToOrig,\n",
       " 'DynamicUnet': fastai.vision.models.unet.DynamicUnet,\n",
       " 'ResNet': torchvision.models.resnet.ResNet,\n",
       " 'resnet18': <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet34': <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet50': <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet101': <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'resnet152': <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>,\n",
       " 'SqueezeNet': torchvision.models.squeezenet.SqueezeNet,\n",
       " 'squeezenet1_0': <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       " 'squeezenet1_1': <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>,\n",
       " 'densenet121': <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet169': <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet201': <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'densenet161': <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>,\n",
       " 'vgg11_bn': <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg13_bn': <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg16_bn': <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'vgg19_bn': <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>,\n",
       " 'alexnet': <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>,\n",
       " 'has_pool_type': <function fastai.vision.learner.has_pool_type(m)>,\n",
       " 'create_body': <function fastai.vision.learner.create_body(arch, n_in=3, pretrained=True, cut=None)>,\n",
       " 'create_head': <function fastai.vision.learner.create_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       " 'default_split': <function fastai.vision.learner.default_split(m)>,\n",
       " 'model_meta': {<function fastai.vision.models.xresnet.xresnet18(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet34(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet50(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet101(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function fastai.vision.models.xresnet.xresnet152(pretrained=False, **kwargs)>: {'cut': -4,\n",
       "   'split': <function fastai.vision.learner._xresnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.resnet.resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.resnet.ResNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.squeezenet.squeezenet1_0(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.squeezenet.squeezenet1_1(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.squeezenet.SqueezeNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._squeezenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.densenet.densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.densenet.DenseNet>: {'cut': -1,\n",
       "   'split': <function fastai.vision.learner._densenet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.vgg.vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.vgg.VGG>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._vgg_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])},\n",
       "  <function torchvision.models.alexnet.alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> torchvision.models.alexnet.AlexNet>: {'cut': -2,\n",
       "   'split': <function fastai.vision.learner._alexnet_split(m: torch.nn.modules.module.Module)>,\n",
       "   'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])}},\n",
       " 'create_cnn_model': <function fastai.vision.learner.create_cnn_model(arch, n_out, pretrained=True, cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       " 'cnn_learner': <function fastai.vision.learner.cnn_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, init=<function kaiming_normal_ at 0x7f34c94c9710>, custom_head=None, concat_pool=True, lin_ftrs=None, ps=0.5, first_bn=True, bn_final=False, lin_first=False, y_range=None)>,\n",
       " 'create_unet_model': <function fastai.vision.learner.create_unet_model(arch, n_out, img_size, pretrained=True, cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       " 'unet_learner': <function fastai.vision.learner.unet_learner(dls, arch, normalize=True, n_out=None, pretrained=True, config=None, loss_func=None, opt_func=<function Adam at 0x7f34b7146170>, lr=0.001, splitter=None, cbs=None, metrics=None, path=None, model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95, 0.85, 0.95), cut=None, n_in=3, blur=False, blur_final=True, self_attention=False, y_range=None, last_cross=True, bottle=False, act_cls=<class 'torch.nn.modules.activation.ReLU'>, init=<function kaiming_normal_ at 0x7f34c94c9710>, norm_type=None)>,\n",
       " 'download_images': <function fastai.vision.utils.download_images(dest, url_file=None, urls=None, max_pics=1000, n_workers=8, timeout=4, preserve_filename=False)>,\n",
       " 'resize_to': <function fastai.vision.utils.resize_to(img, targ_sz, use_min=False)>,\n",
       " 'verify_image': <function fastai.vision.utils.verify_image(fn)>,\n",
       " 'verify_images': <function fastai.vision.utils.verify_images(fns)>,\n",
       " 'resize_image': <function fastai.vision.utils.resize_image(file, dest, max_size=None, n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=False, **kwargs)>,\n",
       " 'resize_images': <function fastai.vision.utils.resize_images(path, max_workers=4, max_size=None, recurse=False, dest=Path('.'), n_channels=3, ext=None, img_format=None, resample=<Resampling.BILINEAR: 2>, resume=None, **kwargs)>,\n",
       " 'transforms': <module 'torchaudio.transforms' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/transforms.py'>,\n",
       " 'make_dataclass': <function dataclasses.make_dataclass(cls_name, fields, *, bases=(), namespace=None, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False)>,\n",
       " 'signature': <function inspect.signature(obj, *, follow_wrapped=True)>,\n",
       " 'save_audio': <function torchaudio.backend.sox_io_backend.save(filepath: str, src: torch.Tensor, sample_rate: int, channels_first: bool = True, compression: Union[float, NoneType] = None, format: Union[str, NoneType] = None, encoding: Union[str, NoneType] = None, bits_per_sample: Union[int, NoneType] = None)>,\n",
       " 'Resample': fastaudio.augment.preprocess.Resample,\n",
       " 'DownmixMono': fastaudio.augment.signal.DownmixMono,\n",
       " 'ResizeSignal': fastaudio.augment.signal.ResizeSignal,\n",
       " 'AudioTensor': fastaudio.core.signal.AudioTensor,\n",
       " 'get_audio_files': <function fastaudio.core.signal.get_audio_files(path, recurse=True, folders=None)>,\n",
       " 'audio_item_tfms': <function fastaudio.core.config.audio_item_tfms(sample_rate=16000, force_mono=True, crop_signal_to=None)>,\n",
       " 'PreprocessAudio': fastaudio.core.config.PreprocessAudio,\n",
       " 'preprocess_audio_folder': <function fastaudio.core.config.preprocess_audio_folder(path, folders=None, output_dir=None, sample_rate=16000, force_mono=True, crop_signal_to=None, **kwargs)>,\n",
       " 'AudioBlock': fastaudio.core.config.AudioBlock,\n",
       " 'config_from_func': <function fastaudio.core.config.config_from_func(func, name, **kwargs)>,\n",
       " 'AudioConfig': fastaudio.core.config.AudioConfig,\n",
       " 'torchaudio': <module 'torchaudio' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/site-packages/torchaudio/__init__.py'>,\n",
       " 'Audio': IPython.lib.display.Audio,\n",
       " 'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
       " 'waveplot': <function librosa.display.waveplot(y, sr=22050, max_points=50000.0, x_axis='time', offset=0.0, max_sr=1000, ax=None, **kwargs)>,\n",
       " 'path': <module 'posixpath' from '/home/mizoru/miniconda3/envs/fastaudio/lib/python3.7/posixpath.py'>,\n",
       " 'audio_extensions': ('.m3u',\n",
       "  '.ram',\n",
       "  '.au',\n",
       "  '.snd',\n",
       "  '.mp3',\n",
       "  '.mp2',\n",
       "  '.aif',\n",
       "  '.aifc',\n",
       "  '.aiff',\n",
       "  '.ra',\n",
       "  '.wav',\n",
       "  '.amr',\n",
       "  '.awb',\n",
       "  '.axa',\n",
       "  '.csd',\n",
       "  '.orc',\n",
       "  '.sco',\n",
       "  '.flac',\n",
       "  '.mid',\n",
       "  '.midi',\n",
       "  '.kar',\n",
       "  '.mpga',\n",
       "  '.mpega',\n",
       "  '.m4a',\n",
       "  '.oga',\n",
       "  '.ogg',\n",
       "  '.opus',\n",
       "  '.spx',\n",
       "  '.sid',\n",
       "  '.gsm',\n",
       "  '.wma',\n",
       "  '.wax',\n",
       "  '.rm',\n",
       "  '.pls',\n",
       "  '.sd2'),\n",
       " 'AudioGetter': <function fastaudio.core.signal.AudioGetter(suf='', recurse=True, folders=None)>,\n",
       " 'tar_extract_at_filename': <function fastaudio.core.signal.tar_extract_at_filename(fname, dest)>,\n",
       " 'show_audio_signal': <function fastaudio.core.signal.show_audio_signal(ai, ctx, ax=None, title='', **kwargs)>,\n",
       " 'OpenAudio': fastaudio.core.signal.OpenAudio,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06aa8e7a52381d2363927eefeded396dbf834941da313f484c402cae656620b8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('fastaudio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
